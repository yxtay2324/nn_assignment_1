{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn9rJ_QxUwQT"
   },
   "source": [
    "# Part A: Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6svEX4UE2txX"
   },
   "source": [
    "# Use [markdown](https://www.markdownguide.org/basic-syntax/) to label each (sub)question neatly.\n",
    "\n",
    "This notebook serves as your report. All your answers should be presented within it. \n",
    "\n",
    "You can submit multiple notebooks (e.g. 1 notebook per part / question).\n",
    "\n",
    "Before submission, remember to tidy up the notebook and retain only relevant parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vr3BLitFduby"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint,LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YM8unKH7nSIM"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "import random \n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmTBl3xoqA9g"
   },
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "An4b9d12p8u2",
    "outputId": "334f6d89-94dd-4d23-edf8-ded755dd3f66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>tempo</th>\n",
       "      <th>total_beats</th>\n",
       "      <th>average_beats</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>chroma_cq_mean</th>\n",
       "      <th>chroma_cq_var</th>\n",
       "      <th>chroma_cens_mean</th>\n",
       "      <th>chroma_cens_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc15_mean</th>\n",
       "      <th>mfcc15_var</th>\n",
       "      <th>mfcc16_mean</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_3001_4001_phnd_neg_0000.wav</td>\n",
       "      <td>184.570312</td>\n",
       "      <td>623</td>\n",
       "      <td>69.222222</td>\n",
       "      <td>0.515281</td>\n",
       "      <td>0.093347</td>\n",
       "      <td>0.443441</td>\n",
       "      <td>0.082742</td>\n",
       "      <td>0.249143</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.669799</td>\n",
       "      <td>63.340282</td>\n",
       "      <td>1.811605</td>\n",
       "      <td>58.117188</td>\n",
       "      <td>-3.286546</td>\n",
       "      <td>54.268448</td>\n",
       "      <td>-2.719069</td>\n",
       "      <td>59.548176</td>\n",
       "      <td>-4.559987</td>\n",
       "      <td>70.774803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_3001_4001_phnd_neg_0001.wav</td>\n",
       "      <td>151.999081</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "      <td>0.487201</td>\n",
       "      <td>0.094461</td>\n",
       "      <td>0.542182</td>\n",
       "      <td>0.073359</td>\n",
       "      <td>0.274423</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.666375</td>\n",
       "      <td>90.256195</td>\n",
       "      <td>1.573594</td>\n",
       "      <td>105.070496</td>\n",
       "      <td>-0.742024</td>\n",
       "      <td>82.417496</td>\n",
       "      <td>-1.961745</td>\n",
       "      <td>119.312355</td>\n",
       "      <td>1.513660</td>\n",
       "      <td>101.014572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_3001_4001_phnd_neg_0002.wav</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>1614</td>\n",
       "      <td>146.727273</td>\n",
       "      <td>0.444244</td>\n",
       "      <td>0.099268</td>\n",
       "      <td>0.442014</td>\n",
       "      <td>0.083224</td>\n",
       "      <td>0.264430</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.502390</td>\n",
       "      <td>73.079750</td>\n",
       "      <td>0.202623</td>\n",
       "      <td>72.040550</td>\n",
       "      <td>-4.021009</td>\n",
       "      <td>73.844353</td>\n",
       "      <td>-5.916223</td>\n",
       "      <td>103.834824</td>\n",
       "      <td>-2.939086</td>\n",
       "      <td>113.598824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>app_3001_4001_phnd_neg_0003.wav</td>\n",
       "      <td>107.666016</td>\n",
       "      <td>2060</td>\n",
       "      <td>158.461538</td>\n",
       "      <td>0.454156</td>\n",
       "      <td>0.100834</td>\n",
       "      <td>0.424370</td>\n",
       "      <td>0.084435</td>\n",
       "      <td>0.257672</td>\n",
       "      <td>0.016938</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.812989</td>\n",
       "      <td>93.791893</td>\n",
       "      <td>-0.429413</td>\n",
       "      <td>60.002579</td>\n",
       "      <td>-4.013513</td>\n",
       "      <td>82.544540</td>\n",
       "      <td>-5.858006</td>\n",
       "      <td>84.402092</td>\n",
       "      <td>0.686969</td>\n",
       "      <td>90.126389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>app_3001_4001_phnd_neg_0004.wav</td>\n",
       "      <td>75.999540</td>\n",
       "      <td>66</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.478780</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.414859</td>\n",
       "      <td>0.089313</td>\n",
       "      <td>0.252143</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.584204</td>\n",
       "      <td>64.973305</td>\n",
       "      <td>0.744403</td>\n",
       "      <td>68.908516</td>\n",
       "      <td>-6.354805</td>\n",
       "      <td>66.414391</td>\n",
       "      <td>-6.555534</td>\n",
       "      <td>47.852840</td>\n",
       "      <td>-4.809713</td>\n",
       "      <td>73.033966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182249</th>\n",
       "      <td>app_3773_5546_phnd_pos_0054.wav</td>\n",
       "      <td>172.265625</td>\n",
       "      <td>1198</td>\n",
       "      <td>99.833333</td>\n",
       "      <td>0.620618</td>\n",
       "      <td>0.070292</td>\n",
       "      <td>0.381610</td>\n",
       "      <td>0.081022</td>\n",
       "      <td>0.239084</td>\n",
       "      <td>0.026172</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.338770</td>\n",
       "      <td>81.940697</td>\n",
       "      <td>-5.307585</td>\n",
       "      <td>102.843636</td>\n",
       "      <td>2.587634</td>\n",
       "      <td>59.694859</td>\n",
       "      <td>-6.465442</td>\n",
       "      <td>90.452126</td>\n",
       "      <td>-5.180311</td>\n",
       "      <td>69.693237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182250</th>\n",
       "      <td>app_3773_5546_phnd_pos_0055.wav</td>\n",
       "      <td>78.302557</td>\n",
       "      <td>306</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>0.612606</td>\n",
       "      <td>0.070161</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.081770</td>\n",
       "      <td>0.242212</td>\n",
       "      <td>0.024667</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.690513</td>\n",
       "      <td>108.272583</td>\n",
       "      <td>-5.633468</td>\n",
       "      <td>85.068466</td>\n",
       "      <td>3.843521</td>\n",
       "      <td>61.155022</td>\n",
       "      <td>-6.021213</td>\n",
       "      <td>80.570854</td>\n",
       "      <td>-3.540390</td>\n",
       "      <td>73.617676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182251</th>\n",
       "      <td>app_3773_5546_phnd_pos_0056.wav</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>1380</td>\n",
       "      <td>125.454545</td>\n",
       "      <td>0.635446</td>\n",
       "      <td>0.060374</td>\n",
       "      <td>0.389387</td>\n",
       "      <td>0.085514</td>\n",
       "      <td>0.236210</td>\n",
       "      <td>0.027538</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.048096</td>\n",
       "      <td>96.782806</td>\n",
       "      <td>-5.787949</td>\n",
       "      <td>78.352753</td>\n",
       "      <td>-1.718377</td>\n",
       "      <td>59.865887</td>\n",
       "      <td>-5.130420</td>\n",
       "      <td>64.361443</td>\n",
       "      <td>-3.386290</td>\n",
       "      <td>50.095055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182252</th>\n",
       "      <td>app_3773_5546_phnd_pos_0057.wav</td>\n",
       "      <td>198.768029</td>\n",
       "      <td>2364</td>\n",
       "      <td>118.200000</td>\n",
       "      <td>0.627674</td>\n",
       "      <td>0.065552</td>\n",
       "      <td>0.396143</td>\n",
       "      <td>0.079859</td>\n",
       "      <td>0.244746</td>\n",
       "      <td>0.023433</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.338559</td>\n",
       "      <td>100.234261</td>\n",
       "      <td>-5.238555</td>\n",
       "      <td>83.026726</td>\n",
       "      <td>-3.655035</td>\n",
       "      <td>84.823341</td>\n",
       "      <td>-5.556218</td>\n",
       "      <td>57.476173</td>\n",
       "      <td>-0.247402</td>\n",
       "      <td>50.155182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182253</th>\n",
       "      <td>app_3773_5546_phnd_pos_0058.wav</td>\n",
       "      <td>89.102909</td>\n",
       "      <td>230</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>0.572914</td>\n",
       "      <td>0.084075</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.099075</td>\n",
       "      <td>0.241772</td>\n",
       "      <td>0.024880</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.618259</td>\n",
       "      <td>127.961243</td>\n",
       "      <td>-10.674469</td>\n",
       "      <td>117.830101</td>\n",
       "      <td>-4.390059</td>\n",
       "      <td>84.200218</td>\n",
       "      <td>-5.606098</td>\n",
       "      <td>69.405533</td>\n",
       "      <td>-2.391726</td>\n",
       "      <td>58.814247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182254 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               filename       tempo  total_beats  \\\n",
       "0       app_3001_4001_phnd_neg_0000.wav  184.570312          623   \n",
       "1       app_3001_4001_phnd_neg_0001.wav  151.999081          521   \n",
       "2       app_3001_4001_phnd_neg_0002.wav  112.347147         1614   \n",
       "3       app_3001_4001_phnd_neg_0003.wav  107.666016         2060   \n",
       "4       app_3001_4001_phnd_neg_0004.wav   75.999540           66   \n",
       "...                                 ...         ...          ...   \n",
       "182249  app_3773_5546_phnd_pos_0054.wav  172.265625         1198   \n",
       "182250  app_3773_5546_phnd_pos_0055.wav   78.302557          306   \n",
       "182251  app_3773_5546_phnd_pos_0056.wav  112.347147         1380   \n",
       "182252  app_3773_5546_phnd_pos_0057.wav  198.768029         2364   \n",
       "182253  app_3773_5546_phnd_pos_0058.wav   89.102909          230   \n",
       "\n",
       "        average_beats  chroma_stft_mean  chroma_stft_var  chroma_cq_mean  \\\n",
       "0           69.222222          0.515281         0.093347        0.443441   \n",
       "1           74.428571          0.487201         0.094461        0.542182   \n",
       "2          146.727273          0.444244         0.099268        0.442014   \n",
       "3          158.461538          0.454156         0.100834        0.424370   \n",
       "4           33.000000          0.478780         0.100000        0.414859   \n",
       "...               ...               ...              ...             ...   \n",
       "182249      99.833333          0.620618         0.070292        0.381610   \n",
       "182250      76.500000          0.612606         0.070161        0.402439   \n",
       "182251     125.454545          0.635446         0.060374        0.389387   \n",
       "182252     118.200000          0.627674         0.065552        0.396143   \n",
       "182253      57.500000          0.572914         0.084075        0.368750   \n",
       "\n",
       "        chroma_cq_var  chroma_cens_mean  chroma_cens_var  ...  mfcc15_mean  \\\n",
       "0            0.082742          0.249143         0.021261  ...   -10.669799   \n",
       "1            0.073359          0.274423         0.008025  ...    -5.666375   \n",
       "2            0.083224          0.264430         0.013410  ...    -5.502390   \n",
       "3            0.084435          0.257672         0.016938  ...    -8.812989   \n",
       "4            0.089313          0.252143         0.019757  ...    -6.584204   \n",
       "...               ...               ...              ...  ...          ...   \n",
       "182249       0.081022          0.239084         0.026172  ...    -5.338770   \n",
       "182250       0.081770          0.242212         0.024667  ...    -6.690513   \n",
       "182251       0.085514          0.236210         0.027538  ...    -7.048096   \n",
       "182252       0.079859          0.244746         0.023433  ...    -8.338559   \n",
       "182253       0.099075          0.241772         0.024880  ...    -6.618259   \n",
       "\n",
       "        mfcc15_var  mfcc16_mean  mfcc16_var  mfcc17_mean  mfcc17_var  \\\n",
       "0        63.340282     1.811605   58.117188    -3.286546   54.268448   \n",
       "1        90.256195     1.573594  105.070496    -0.742024   82.417496   \n",
       "2        73.079750     0.202623   72.040550    -4.021009   73.844353   \n",
       "3        93.791893    -0.429413   60.002579    -4.013513   82.544540   \n",
       "4        64.973305     0.744403   68.908516    -6.354805   66.414391   \n",
       "...            ...          ...         ...          ...         ...   \n",
       "182249   81.940697    -5.307585  102.843636     2.587634   59.694859   \n",
       "182250  108.272583    -5.633468   85.068466     3.843521   61.155022   \n",
       "182251   96.782806    -5.787949   78.352753    -1.718377   59.865887   \n",
       "182252  100.234261    -5.238555   83.026726    -3.655035   84.823341   \n",
       "182253  127.961243   -10.674469  117.830101    -4.390059   84.200218   \n",
       "\n",
       "        mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \n",
       "0         -2.719069   59.548176    -4.559987   70.774803  \n",
       "1         -1.961745  119.312355     1.513660  101.014572  \n",
       "2         -5.916223  103.834824    -2.939086  113.598824  \n",
       "3         -5.858006   84.402092     0.686969   90.126389  \n",
       "4         -6.555534   47.852840    -4.809713   73.033966  \n",
       "...             ...         ...          ...         ...  \n",
       "182249    -6.465442   90.452126    -5.180311   69.693237  \n",
       "182250    -6.021213   80.570854    -3.540390   73.617676  \n",
       "182251    -5.130420   64.361443    -3.386290   50.095055  \n",
       "182252    -5.556218   57.476173    -0.247402   50.155182  \n",
       "182253    -5.606098   69.405533    -2.391726   58.814247  \n",
       "\n",
       "[182254 rows x 78 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./full.csv') \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6AI_2ZahhQtk"
   },
   "outputs": [],
   "source": [
    "df['label'] = df['filename'].str.split('_').str[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHZQbQVzqGIA",
    "outputId": "df038bb0-95fc-4c32-a528-39d87edf8fc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    92826\n",
       "neg    89428\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zp_RDMgqL9Z"
   },
   "source": [
    "Split and scale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2fNTd9t7qHCI"
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['label','filename']\n",
    "\n",
    "def split_dataset(df, columns_to_drop, test_size, random_state):\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "  df_train, df_test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "\n",
    "  df_train2 = df_train.drop(columns_to_drop,axis=1)\n",
    "  y_train2 = df_train['label'].to_numpy()\n",
    "\n",
    "  df_test2 = df_test.drop(columns_to_drop,axis=1)\n",
    "  y_test2 = df_test['label'].to_numpy() \n",
    "\n",
    "  return df_train2, y_train2, df_test2, y_test2\n",
    "\n",
    "def preprocess_dataset(df_train, df_test):\n",
    "\n",
    "  standard_scaler = preprocessing.StandardScaler()\n",
    "  df_train_scaled = standard_scaler.fit_transform(df_train)\n",
    "\n",
    "  df_test_scaled = standard_scaler.transform(df_test)\n",
    "\n",
    "  return df_train_scaled, df_test_scaled\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, columns_to_drop, test_size=0.3, random_state=0) # positive labels being encoded as 1\n",
    "\n",
    "X_train_scaled, X_test_scaled = preprocess_dataset(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RrHwuvPBYfo",
    "outputId": "9d396e4e-b657-4973-e6d9-b695b1748344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127577, 77) (127577,)\n",
      "(54677, 77) (54677,)\n",
      "(127577, 77) (54677, 77)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_train_scaled.shape, X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnSbVYQBU6ir"
   },
   "source": [
    "## Question 1\n",
    "\n",
    "Design a feedforward deep neural network (DNN) which consists of an input layer, three hidden layers of 128 neurons each with ReLU activation function, and an output layer with sigmoid activation function. Use a mini-batch gradient descent with ‘adam’ optimizer with learning rate of 0.001, and batch size = 256. Apply dropout of probability 0.2 to each of the hidden layers.\n",
    "\n",
    "Divide the dataset into a 70:30 ratio for training and testing. Use appropriate scaling of input features. We solely assume that there are only two datasets here: training & test. We would look into validation in Question 2 onwards. (Note that we make the simplifying assumption here that each data sample is independent, hence a random split is performed.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKaYGhcpVCSO"
   },
   "source": [
    "### Part a\n",
    "\n",
    "Use the training dataset to train the model for 100 epochs. Implement early\n",
    "stopping with patience of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pdKThBya5hdJ"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "no_epochs = 100\n",
    "batch_size = 256\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Oy0uuUw6hVOc"
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TFUflvICjwD2"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer= opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPMWNS3hjwcE",
    "outputId": "b1e8fb6f-91eb-47fb-d64b-37e2945a81f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "499/499 - 2s - loss: 0.6897 - accuracy: 0.5362 - val_loss: 0.6845 - val_accuracy: 0.5547 - 2s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "499/499 - 1s - loss: 0.6834 - accuracy: 0.5520 - val_loss: 0.6810 - val_accuracy: 0.5583 - 1s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "499/499 - 1s - loss: 0.6800 - accuracy: 0.5606 - val_loss: 0.6799 - val_accuracy: 0.5618 - 1s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "499/499 - 2s - loss: 0.6770 - accuracy: 0.5656 - val_loss: 0.6767 - val_accuracy: 0.5681 - 2s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "499/499 - 1s - loss: 0.6738 - accuracy: 0.5737 - val_loss: 0.6728 - val_accuracy: 0.5760 - 1s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "499/499 - 1s - loss: 0.6705 - accuracy: 0.5792 - val_loss: 0.6703 - val_accuracy: 0.5808 - 1s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "499/499 - 1s - loss: 0.6667 - accuracy: 0.5851 - val_loss: 0.6674 - val_accuracy: 0.5895 - 1s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "499/499 - 1s - loss: 0.6627 - accuracy: 0.5909 - val_loss: 0.6640 - val_accuracy: 0.5887 - 1s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "499/499 - 1s - loss: 0.6595 - accuracy: 0.5958 - val_loss: 0.6602 - val_accuracy: 0.5990 - 1s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "499/499 - 1s - loss: 0.6570 - accuracy: 0.5979 - val_loss: 0.6584 - val_accuracy: 0.5997 - 1s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "499/499 - 1s - loss: 0.6529 - accuracy: 0.6056 - val_loss: 0.6541 - val_accuracy: 0.6076 - 1s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "499/499 - 1s - loss: 0.6497 - accuracy: 0.6091 - val_loss: 0.6516 - val_accuracy: 0.6081 - 1s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "499/499 - 1s - loss: 0.6466 - accuracy: 0.6134 - val_loss: 0.6478 - val_accuracy: 0.6130 - 1s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "499/499 - 1s - loss: 0.6421 - accuracy: 0.6181 - val_loss: 0.6453 - val_accuracy: 0.6147 - 1s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "499/499 - 1s - loss: 0.6396 - accuracy: 0.6230 - val_loss: 0.6427 - val_accuracy: 0.6183 - 1s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "499/499 - 1s - loss: 0.6384 - accuracy: 0.6243 - val_loss: 0.6407 - val_accuracy: 0.6230 - 1s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "499/499 - 2s - loss: 0.6347 - accuracy: 0.6282 - val_loss: 0.6381 - val_accuracy: 0.6259 - 2s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "499/499 - 1s - loss: 0.6320 - accuracy: 0.6311 - val_loss: 0.6351 - val_accuracy: 0.6277 - 1s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "499/499 - 1s - loss: 0.6297 - accuracy: 0.6328 - val_loss: 0.6338 - val_accuracy: 0.6285 - 1s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "499/499 - 1s - loss: 0.6275 - accuracy: 0.6358 - val_loss: 0.6322 - val_accuracy: 0.6296 - 1s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "499/499 - 1s - loss: 0.6256 - accuracy: 0.6386 - val_loss: 0.6303 - val_accuracy: 0.6333 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "499/499 - 1s - loss: 0.6241 - accuracy: 0.6402 - val_loss: 0.6269 - val_accuracy: 0.6374 - 1s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "499/499 - 1s - loss: 0.6208 - accuracy: 0.6441 - val_loss: 0.6278 - val_accuracy: 0.6345 - 1s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "499/499 - 1s - loss: 0.6200 - accuracy: 0.6443 - val_loss: 0.6251 - val_accuracy: 0.6382 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "499/499 - 1s - loss: 0.6178 - accuracy: 0.6464 - val_loss: 0.6246 - val_accuracy: 0.6394 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "499/499 - 1s - loss: 0.6164 - accuracy: 0.6472 - val_loss: 0.6219 - val_accuracy: 0.6411 - 1s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "499/499 - 1s - loss: 0.6142 - accuracy: 0.6483 - val_loss: 0.6220 - val_accuracy: 0.6439 - 1s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "499/499 - 1s - loss: 0.6125 - accuracy: 0.6517 - val_loss: 0.6197 - val_accuracy: 0.6458 - 1s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "499/499 - 1s - loss: 0.6118 - accuracy: 0.6513 - val_loss: 0.6181 - val_accuracy: 0.6457 - 1s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "499/499 - 1s - loss: 0.6087 - accuracy: 0.6547 - val_loss: 0.6170 - val_accuracy: 0.6475 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "499/499 - 1s - loss: 0.6094 - accuracy: 0.6539 - val_loss: 0.6147 - val_accuracy: 0.6499 - 1s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "499/499 - 1s - loss: 0.6074 - accuracy: 0.6573 - val_loss: 0.6158 - val_accuracy: 0.6490 - 1s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "499/499 - 1s - loss: 0.6067 - accuracy: 0.6568 - val_loss: 0.6146 - val_accuracy: 0.6514 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "499/499 - 1s - loss: 0.6052 - accuracy: 0.6594 - val_loss: 0.6144 - val_accuracy: 0.6519 - 1s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "499/499 - 1s - loss: 0.6035 - accuracy: 0.6585 - val_loss: 0.6134 - val_accuracy: 0.6502 - 1s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "499/499 - 1s - loss: 0.6031 - accuracy: 0.6608 - val_loss: 0.6121 - val_accuracy: 0.6517 - 1s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "499/499 - 1s - loss: 0.6010 - accuracy: 0.6620 - val_loss: 0.6104 - val_accuracy: 0.6533 - 1s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "499/499 - 1s - loss: 0.6000 - accuracy: 0.6637 - val_loss: 0.6099 - val_accuracy: 0.6542 - 1s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "499/499 - 1s - loss: 0.5995 - accuracy: 0.6646 - val_loss: 0.6094 - val_accuracy: 0.6574 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "499/499 - 1s - loss: 0.5977 - accuracy: 0.6657 - val_loss: 0.6085 - val_accuracy: 0.6579 - 1s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "499/499 - 1s - loss: 0.5981 - accuracy: 0.6642 - val_loss: 0.6086 - val_accuracy: 0.6572 - 1s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "499/499 - 2s - loss: 0.5961 - accuracy: 0.6655 - val_loss: 0.6073 - val_accuracy: 0.6600 - 2s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "499/499 - 1s - loss: 0.5963 - accuracy: 0.6678 - val_loss: 0.6071 - val_accuracy: 0.6575 - 1s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "499/499 - 1s - loss: 0.5942 - accuracy: 0.6695 - val_loss: 0.6070 - val_accuracy: 0.6601 - 1s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "499/499 - 1s - loss: 0.5926 - accuracy: 0.6724 - val_loss: 0.6064 - val_accuracy: 0.6577 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "499/499 - 1s - loss: 0.5936 - accuracy: 0.6698 - val_loss: 0.6065 - val_accuracy: 0.6583 - 1s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "499/499 - 1s - loss: 0.5906 - accuracy: 0.6702 - val_loss: 0.6049 - val_accuracy: 0.6611 - 1s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "499/499 - 1s - loss: 0.5918 - accuracy: 0.6707 - val_loss: 0.6057 - val_accuracy: 0.6599 - 1s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "499/499 - 1s - loss: 0.5914 - accuracy: 0.6702 - val_loss: 0.6033 - val_accuracy: 0.6597 - 1s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "499/499 - 1s - loss: 0.5900 - accuracy: 0.6748 - val_loss: 0.6031 - val_accuracy: 0.6600 - 1s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "499/499 - 1s - loss: 0.5895 - accuracy: 0.6725 - val_loss: 0.6025 - val_accuracy: 0.6636 - 1s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "499/499 - 1s - loss: 0.5896 - accuracy: 0.6734 - val_loss: 0.6029 - val_accuracy: 0.6634 - 1s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "499/499 - 1s - loss: 0.5857 - accuracy: 0.6767 - val_loss: 0.6024 - val_accuracy: 0.6628 - 1s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "499/499 - 2s - loss: 0.5872 - accuracy: 0.6758 - val_loss: 0.6013 - val_accuracy: 0.6636 - 2s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "499/499 - 1s - loss: 0.5858 - accuracy: 0.6767 - val_loss: 0.5993 - val_accuracy: 0.6668 - 1s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "499/499 - 1s - loss: 0.5854 - accuracy: 0.6767 - val_loss: 0.5970 - val_accuracy: 0.6682 - 1s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "499/499 - 1s - loss: 0.5844 - accuracy: 0.6783 - val_loss: 0.5983 - val_accuracy: 0.6666 - 1s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "499/499 - 1s - loss: 0.5839 - accuracy: 0.6798 - val_loss: 0.5986 - val_accuracy: 0.6661 - 1s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "499/499 - 1s - loss: 0.5855 - accuracy: 0.6760 - val_loss: 0.5967 - val_accuracy: 0.6689 - 1s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "499/499 - 1s - loss: 0.5859 - accuracy: 0.6765 - val_loss: 0.5988 - val_accuracy: 0.6661 - 1s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "499/499 - 1s - loss: 0.5830 - accuracy: 0.6797 - val_loss: 0.5967 - val_accuracy: 0.6677 - 1s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "499/499 - 1s - loss: 0.5825 - accuracy: 0.6798 - val_loss: 0.5964 - val_accuracy: 0.6673 - 1s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "499/499 - 1s - loss: 0.5820 - accuracy: 0.6804 - val_loss: 0.5971 - val_accuracy: 0.6683 - 1s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "499/499 - 1s - loss: 0.5811 - accuracy: 0.6808 - val_loss: 0.5959 - val_accuracy: 0.6696 - 1s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "499/499 - 1s - loss: 0.5813 - accuracy: 0.6798 - val_loss: 0.5949 - val_accuracy: 0.6698 - 1s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "499/499 - 1s - loss: 0.5817 - accuracy: 0.6797 - val_loss: 0.5959 - val_accuracy: 0.6685 - 1s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "499/499 - 1s - loss: 0.5801 - accuracy: 0.6838 - val_loss: 0.5953 - val_accuracy: 0.6680 - 1s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "499/499 - 1s - loss: 0.5811 - accuracy: 0.6821 - val_loss: 0.5955 - val_accuracy: 0.6692 - 1s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = model.fit(X_train_scaled, y_train, \n",
    "                    epochs=no_epochs, \n",
    "                    batch_size=batch_size , \n",
    "                    verbose = 2, \n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[early_stop],\n",
    "                    validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFvEJmpPVGan"
   },
   "source": [
    "### Part b\n",
    "\n",
    "Plot train and test accuracies and losses on training and test data against training epochs and comment on the line plots. Explain the use of early stopping in this\n",
    "question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "zxdgofsxVJoT",
    "outputId": "8c2fb768-d3e2-42c2-9bdd-46ee0d3678b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x225b8dc6520>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABFo0lEQVR4nO3dd3iUVfbA8e9JTyAQSqgJvfcSQECUqlhQEQuIBQvY0HV/ltV1V11dt1jWVZddZVFALKCggKyKWFApQkKXIL0k1CRASCH9/P54BxxiygSYTMr5PM88mfe+Zc6EYU7uve+9V1QVY4wxxhN+vg7AGGNM5WFJwxhjjMcsaRhjjPGYJQ1jjDEes6RhjDHGY5Y0jDHGeMyShqn2RKSFiKiIBHhw7AQRWVYecRlTEVnSMJWKiOwRkRwRqV+ofJ3ri7+Fj0IzplqwpGEqo93AuFMbItIVCPNdOBWDJzUlY86VJQ1TGc0CbnXbvg14x/0AEaktIu+ISJKI7BWRP4iIn2ufv4i8JCLJIrILuKKIc98SkYMisl9E/iwi/p4EJiIficghEUkVke9FpLPbvlARedkVT6qILBORUNe+C0VkhYgcF5EEEZngKl8qIne5XeOM5jFX7ep+EdkObHeVveq6xgkRWSMig9yO9xeR34vIThFJc+2PFpEpIvJyofeyUER+68n7NtWHJQ1TGf0I1BKRjq4v87HAu4WOeR2oDbQCLsZJMre79k0ErgR6AjHAdYXOnQHkAW1cx1wC3IVnPgfaAg2AtcB7bvteAnoDA4C6wGNAgYg0d533OhAJ9ADWe/h6ANcA/YBOru1Y1zXqAu8DH4lIiGvf/+HU0i4HagF3AJnATGCcW2KtDwx3nW/ML1TVHvaoNA9gD86X2R+AvwIjgSVAAKBAC8AfyAE6uZ13N7DU9fwb4B63fZe4zg0AGgLZQKjb/nHAt67nE4BlHsYa4bpubZw/0E4C3Ys47gngk2KusRS4y237jNd3XX9oKXEcO/W6wFbg6mKO2wKMcD2fDHzm639ve1S8h7WBmspqFvA90JJCTVNAfSAQ2OtWthdo6nreBEgotO+U5q5zD4rIqTK/QscXyVXreR64HqfGUOAWTzAQAuws4tToYso9dUZsIvIIcCfO+1ScGsWpGwdKeq2ZwM04Sfhm4NVziMlUUdY8ZSolVd2L0yF+OfBxod3JQC5OAjilGbDf9fwgzpen+75TEnBqGvVVNcL1qKWqnSndTcDVODWh2ji1HgBxxZQFtC7ivIRiygEyOLOTv1ERx5yeqtrVf/EYcANQR1UjgFRXDKW91rvA1SLSHegIzC/mOFONWdIwldmdOE0zGe6FqpoPfAg8LyLhrj6D/+OXfo8PgQdFJEpE6gCPu517EPgSeFlEaomIn4i0FpGLPYgnHCfhpOB80f/F7boFwNvAP0SkiatDur+IBOP0ewwXkRtEJEBE6olID9ep64FrRSRMRNq43nNpMeQBSUCAiDyFU9M4ZRrwnIi0FUc3EannijERpz9kFjBPVU968J5NNWNJw1RaqrpTVeOK2f0Azl/pu4BlOB26b7v2/RdYDGzA6awuXFO5FQgC4nH6A+YCjT0I6R2cpq79rnN/LLT/EWATzhfzUeDvgJ+q7sOpMT3sKl8PdHed8wpO/8xhnOaj9yjZYuALYJsrlizObL76B07S/BI4AbwFhLrtnwl0xUkcxvyKqNoiTMYYh4hchFMja6725WCKYDUNYwwAIhII/AaYZgnDFMeShjEGEekIHMdphvunT4MxFZo1TxljjPGY1TSMMcZ4rMoM7qtfv762aNHC12EYY0ylsmbNmmRVjfT0+CqTNFq0aEFcXHF3XxpjjCmKiOwt/ahfWPOUMcYYj1nSMMYY4zFLGsYYYzxWZfo0ipKbm0tiYiJZWVm+DsV4ICQkhKioKAIDA30dijGmGFU6aSQmJhIeHk6LFi1wm+baVECqSkpKComJibRs2dLX4RhjilGlm6eysrKoV6+eJYxKQESoV6+e1QqNqeCqdNIALGFUIvZvZUzFV+WThjHGVBUZ2XnMXLGH/cd9t9SJJQ0vSklJoUePHvTo0YNGjRrRtGnT09s5OTklnhsXF8eDDz5YTpEaYyq6ggLloTnreXrhZga/+C1/mL+JAz5IHlW6I9zX6tWrx/r16wF45plnqFmzJo888sjp/Xl5eQQEFP1PEBMTQ0xMTHmEWWYlxW2M8Y5XvtrGkvjDPDS8LUlp2cyJTWBObAI39onmvsFtaBIRWvpFzgOv1jREZKSIbBWRHSLyeDHH3CAi8SKyWUTedyt/wVW2RURekyrS4D1hwgTuuece+vXrx2OPPcbq1avp378/PXv2ZMCAAWzduhWApUuXcuWVVwJOwrnjjjsYPHgwrVq14rXXXivy2vfeey8xMTF07tyZp59++nR5bGwsAwYMoHv37vTt25e0tDTy8/N55JFH6NKlC926deP1118HnOlYkpOTAae2M3jw4NMx3HLLLQwcOJBbbrmFPXv2MGjQIHr16kWvXr1YsWLF6df7+9//TteuXenevTuPP/44O3fupFevXqf3b9++/YxtY0zJPt1wgNe/2cHYPtH8Zlhbnh/dlaWPDuGGmGjmxCZw69urKa8Zy73256KI+ANTgBFAIhArIgtVNd7tmLbAE8BAVT0mIg1c5QOAgUA316HLgIuBpWcbz58+3Uz8gRNne3qROjWpxdOjOpf5vMTERFasWIG/vz8nTpzghx9+ICAggK+++orf//73zJs371fn/Pzzz3z77bekpaXRvn177r333l+NZ3j++eepW7cu+fn5DBs2jI0bN9KhQwduvPFG5syZQ58+fThx4gShoaFMnTqVPXv2sH79egICAjh69GipccfHx7Ns2TJCQ0PJzMxkyZIlhISEsH37dsaNG0dcXByff/45CxYsYNWqVYSFhXH06FHq1q1L7dq1Wb9+PT169GD69OncfvvtZf69GVOZqSpH0rLZk5zB3qOZJBzNpHHtUIZ3akCD8JBiz9uUmMqjczfQp0Udnr26y+kbRppGhPL86K7cO7g1h1Kzyu1GEm+2MfQFdqjqLgARmQ1cjbN28ikTgSmqegxAVY+4yhUIwVmnWYBAnDWSq4Trr78ef39/AFJTU7ntttvYvn07IkJubm6R51xxxRUEBwcTHBxMgwYNOHz4MFFRUWcc8+GHHzJ16lTy8vI4ePAg8fHxiAiNGzemT58+ANSqVQuAr776invuued0M1PdunVLjfuqq64iNNSpAufm5jJ58mTWr1+Pv78/27ZtO33d22+/nbCwsDOue9dddzF9+nT+8Y9/MGfOHFavXl2m35kx3qaqJB47SVSd0DJ/ARcUKDn5Bc4jr4Cs3Hz2pmSy5eAJth5K4+dDaew4ks7J3PzT54iAKjw5H3pERzCiU0MubhdJ3RpBhAb6ExLoz4msXCbNiqNuWBD/ubk3QQG/bhyKqhNGVJ2wc337HvNm0mjKmQvaJwL9Ch3TDkBElgP+wDOq+oWqrhSRb4GDOEnjX6q6pfALiMgkYBJAs2bNSgzmbGoE3lKjRo3Tz//4xz8yZMgQPvnkE/bs2XO6Oaiw4ODg08/9/f3Jy8s7Y//u3bt56aWXiI2NpU6dOkyYMOGsxjwEBARQUFAA8Kvz3eN+5ZVXaNiwIRs2bKCgoICQkOL/UgIYM2YMf/rTnxg6dCi9e/emXr16ZY7NGG/Iyy/gi82H+O8Pu9mQcJwJA1rw9KhOHiWOggLl2UXxvLNyDwXFtA7VrxlMx8bhjOvbjJb1w2herwbN64XRJCKUnUnpLNl8mCVbDvPCF1t54Yutvzo/NNCfuff2p37N4CKuXv583ZsZALQFBgNRwPci0hWoD3R0lQEsEZFBqvqD+8mqOhWYChATE1MplyBMTU2ladOmAMyYMeOsr3PixAlq1KhB7dq1OXz4MJ9//jmDBw+mffv2HDx4kNjYWPr06UNaWhqhoaGMGDGCN998kyFDhpxunqpbty4tWrRgzZo1XHbZZUU2k7nHHRUVhZ+fHzNnziQ/3/kLasSIETz77LOMHz/+jOapkJAQLr30Uu69917eeuuts36fxpwv6dl5zIlNYPry3SQeO0mLemGM6NSQGSv20Lh2CHdf3LrE8/PyC3hs7kY+Xref0T2b0qZBTYID/AgO8CMowI+oOmG0bxRe4pd9h0a16NCoFg8Ma8vB1JPE7jlGZnYeJ3PzOZmbT1ZOPhe3b0DnJrXP99s/a95MGvuBaLftKFeZu0RglarmArtFZBu/JJEfVTUdQEQ+B/oDP1DFPPbYY9x22238+c9/5oorrjjr63Tv3p2ePXvSoUMHoqOjGThwIABBQUHMmTOHBx54gJMnTxIaGspXX33FXXfdxbZt2+jWrRuBgYFMnDiRyZMn8/TTT3PnnXfyxz/+sdhaD8B9993HmDFjeOeddxg5cuTpWsjIkSNZv349MTExBAUFcfnll/OXv/wFgPHjx/PJJ59wySWXnPX7NOZcpZ7MZeaKPby9fDfHM3Pp26IuT13ZiWEdGyLAA7PX8dfPf6ZR7RCu7tG0yGtk5+Xz4AfrWLz5MI9c0o77h7Q55z6FxrVDuap7+dwBdS68tka4iAQA24BhOMkiFrhJVTe7HTMSGKeqt4lIfWAd0AMYjtPfMRKneeoL4J+q+mlxrxcTE6OFF2HasmULHTt2PJ9vy5yDl156idTUVJ577rlij7F/M3M+qCqq4Of3yxf58cwc3l62m+nL95CWncfwjg2ZPLQNPaIjzjg3Oy+f295ezZq9x5hxe18Gtql/xv7MnDzunrWGH7Yn8/SoTtw+sHLPlSYia1TV4/v7vVbTUNU8EZkMLMbpr3hbVTeLyLNAnKoudO27RETigXzgUVVNEZG5wFBgE06n+BclJQxT8Y0ePZqdO3fyzTff+DoUU4mlpGfzm9nrSU7PZmCb+gxsU4++LetRMziA5PRsftiexA/bkvl+ezLJ6dn4CQT4+eHvJ+TmF5BXoFzWpRGTh7YptsknOMCfN2+J4YY3VnL3rDVMGd+LAlUSjmayLyWT5TtT2HroBC9c140bYqKLvEZV5rWaRnmzmkbVYP9mpjiHT2QxftoqEo5m0rNZBGv3HScnr4AAPyG6bhi7kzMAqFsjiAvb1KdVZA3yC5S8AiW/QPETYXTPprRvFO7R6x1MPcm1/17BwdRfbggJDvCjeb0wfju8HZd1beyV91neKkxNwxhjSpKUlk3cnqNc2rnRGc1IRUk4msn4aatISc9m5h19uaBVPbJy81mz9xjLdiSz/XAa1/WOYlDb+nRpUrvU63mice1QPrlvIKt2pxBVJ5ToOmFEhgdX+4k1LWkYY8pdTl4Bd82MZUNiKjHN6/DCdd1oFVmzyGN3JqVz87RVZGTn8e5d/ejZrA4AIYH+riaq+kWedz6U1BleXdmEhcaYcvfSl1vZkJjKhAEt2HY4jcte/YFpP+wi3zXYQVXZdjiN6ct3c+ObK8nJK2D2pP6nE4bxHatpGGNKtDclg2Z1w85bs8zSrUeY+v0uxvdrxjNXdebewa35/ceb+PP/tvDZpoM0r1eDZTuSSUrLBqBdw5r8e3xv2jQouiZiypclDS9KSUlh2LBhABw6dAh/f38iIyMBWL16NUFBQSWev3TpUoKCghgwYIDXYzWmsLz8Av70aTyzftzLiE4NefmG7tQKObf124+cyOLhDzfQvmE4f7yyEwANa4Uw7bYY5q/fz7OfxrM3JZMBbepzYZt6DGhdn+i65TdFhimdJQ0vKm1q9NIsXbqUmjVr+jxp5Ofnn54ry1QPqZm53P/+WpbtSGZ4x4Z8+/MRrnp9Gf+5uTcdG9c6q2sWFCj/9+EGMnLymH3TBYQE/vKZEhFG94ziqu5NETgvHdnGO6xPo5ytWbOGiy++mN69e3PppZdy8OBBAF577TU6depEt27dGDt2LHv27OGNN97glVdeoUePHvzww5mD4YubUr24Kc+Lmh59xowZTJ48+fQ1r7zySpYuXQpAzZo1efjhh+nevTsrV67k2WefpU+fPnTp0oVJkyadnoZ5x44dDB8+nO7du9OrVy927tzJrbfeyvz5809fd/z48SxYsMBbv1Jznu1OzmD0f5azancKL1zXjWm3xTB70gWczM1n9L+XM29N4uljs/Py2Z2cwQ/bk5j1416eWxTPXTNjGfbyUgb89Wtu+u+P/GH+JqYv382f/7eFZTuSeXpUZ9o2LPq2V38/sYRRwVWfmsbnj8OhTef3mo26wmV/8/hwVeWBBx5gwYIFREZGMmfOHJ588knefvtt/va3v7F7926Cg4M5fvw4ERER3HPPPcXWTjp06FDklOpFTXmek5NT5PToJcnIyKBfv368/PLLAHTq1ImnnnoKgFtuuYVFixYxatQoxo8fz+OPP87o0aPJysqioKCAO++8k1deeYVrrrmG1NRUVqxYwcyZM8vwizW+oKos3ZrEQ3PW4yfw3l0X0LelM0txTIu6LHpgEA98sJaHP9rAtGW7OZqRzZG0bNyHeoUE+tGiXg3aNKhJWFAAu5IzWLD+AGlZzgSbV3RrzNg+1W9A3K+kH4GNc+DYHshOhxzXQ/yg0zXQZQwEe9iHowqZR6FG+UwCWn2SRgWQnZ3NTz/9xIgRIwCnVtC4sTNAqFu3bowfP55rrrmGa665ptRrFTelelFTnm/atKnI6dFL4u/vz5gxY05vf/vtt7zwwgtkZmZy9OhROnfuzODBg9m/fz+jR48GOD3T7cUXX8x9991HUlIS8+bNY8yYMbbSXwW3alcKLy/ZxurdR2nboCZv3daHZvXO7EuIDA/m3Tv78fo3O4jdc5TOTWoRVSeUqDphNI0IpUX9MBqGh/yqpqCqJKfnsO9oJp2b1Kpc4xy2L4Gkn+GC+8DvHJtoVWHPMoh7G7Z8CgW5EFrXSQ5B4RBUA04eg08fhMW/h67XQ+8J0KRH0dc7tgc2zIYNH0DtaJiw6Nzi81D1+Z9chhqBt6gqnTt3ZuXKlb/a97///Y/vv/+eTz/9lOeff55Nm0quFXk6pXpJ3KdBhzOnQg8JCTndj5GVlcV9991HXFwc0dHRPPPMM6VOu37rrbfy7rvvMnv2bKZPn17m2Ez5WLP3GK8s2cayHclEhgfzzKhOjO3b7Iz+BncB/n78dkS7Mr2GiBAZHkxkuI+m9j71Zb1rKbS/DKI8GPysCstfha+eART2roBr/+v5X/+n5OdCwmrY+Q3EL4CU7RASAX0nOQkhstDvUhUSY2HNDCchrJkO4Y2hbmuo2xLqtoLgcNg8H/YuAwRaXgQ9xpctrnNQfZJGBRAcHExSUhIrV66kf//+5Obmsm3bNjp27EhCQgJDhgzhwgsvZPbs2aSnpxMeHs6JE0WvNljclOpFTXle3PToLVq04N///jcFBQXs37+/2IWRTiWI+vXrk56ezty5c7nuuusIDw8nKiqK+fPnc80115CdnU1+fj5hYWFMmDCBvn370qhRIzp16nR+f5HmnKVl5fLnRVuYE5dAvRpB/OGKjozv15zQoCp0w0P6EVj/Pqx9B47udMp+eAmaXwgXPgRthjsrIRWWlwP/+y2sexc6j4aovvDlkzB9JIybA7XdBvvtXQnf/R32/QjhjSAi2vmrP7wxHImH3d+7mp38odkFMOhh6HwNBBbTPCwC0X2dx6V/gU0fwf61cHQXbFsMGa516uq2hqF/gG5jndcsR5Y0ypGfnx9z587lwQcfJDU1lby8PB566CHatWvHzTffTGpqKqrKgw8+SEREBKNGjeK6665jwYIFvP766wwaNOj0tYqbUr24Kc+Lmh594MCBtGzZkk6dOtGxY8di1+2OiIhg4sSJdOnShUaNGp1u5gKYNWsWd999N0899RSBgYF89NFHtGrVioYNG9KxY0ePmtpM+fpxVwqPfLSBA8dPcvfFrXhwaFtqBFehr4L8PPjiceev9II8aNYfLnrUSRKbPoSVU+C966BBZ+h5MzToAPXbQa2mTvPQh7fCnh/gosdg8BPg5wf12sDc22HaMBg3G3Iy4Lu/OUmhRqRznZNHITURdn4LaQchohl0uwFaD3VqAyFlXBMjNAL6TjyzLDsNMpKhTouiE145sAkLjVdkZmbStWtX1q5dS+3anv9nsX+zsssvUDYmHqdJRCgNaxW/gmJWbj4vLt7K28t306xuGP+4oTu9m5e+zG+lkp8LH0+CzR9D79vhgnshsv2Zx+TlwE9zYflrkOS2IGhgDQgIchLCVf+C7jeeed6hn+D9G52EoPlQowEM/A3E3AFBhcaSFOSfex9IObEJC43PffXVV9x555389re/LVPCMJ7LyStgxc5kFm8+xJebD5OSkUOAn3BV9ybcNagVnZr8crPDvpRM5q5J4KM1iRxMzeKWC5rzxOUdCAuqYv/983Kc2sDPi2DEs84XelECgqDHTdB9nNOElbzN9djuJIQL7nWakgpr1AUmfg2Ln4SmvZ0+icLJ4pRKkjDORhX71JiKYPjw4ezdu9fXYVQ5iccy+WF7Msu2J/P99iTSsvKoEeTP0I4NGd6xAesTjjMnNoGP1+1nUNv6DOvQgC/jD7NiZwoicFHbSF66vrtXJ/jzmdwsp1lp+2IY+Xe44J7SzxGB8IbOo+Wg0o8Hp9/iuuq9XHGVTxqqWrlu8avGqkpT6fl04PhJ3l62m29+PsIu13oRjWqFcFmXRlzauRED29Q/fafT1T2a8tCwdry3ei8zlu/hh+3JRNcN5eER7RjTO4omERV/KVH2roTUBAiq6dwlFBwOoXWgdlTRf73nZTvNRt88B7u+hStfcZqLjNdU6aQREhJCSkoK9erVs8RRwakqKSkpp8d6VHf7j5/k39/u4KO4RApUGdimPuMvaM5FbevTpkHNYj/PtcMCuW9wG+68sCV7UzJpE1mz8oywXvceLLiv6H3+wU5ndP22Tqf1yWOwf40zYLcg1xkUd/UUp0PaeFWVThpRUVEkJiaSlJTk61CMB0JCQoiKivJ1GD6140gaby3bw9w1CQDcEBPNvYNbE1WnbJP2BQf4066YqToqpM2fwMLJ0GoIXPbCLyOks9MgIwlSdjh9Doc2wpaFEBgGTXpC//ud/oWoPlCraqykV9F5NWmIyEjgVZw1wqep6q9G2InIDcAzOGuBb1DVm1zlzYBpQLRr3+Wquqcsrx8YGEjLlpV70XdT9R1MPcnC9QdYsP4A8QdPEOTvx9g+zbh3cOvK0aQEzqC0s63Nb1sM8+6C6H4w9j1nZHRJ8nKcpqoq3NlckXktaYiIPzAFGAEkArEislBV492OaQs8AQxU1WMi0sDtEu8Az6vqEhGpCRRgTBWy40gazyyMZ/nOZFShe3QET4/qxJXdmvhu9PTZ2DAHPnsEIppDp6udR+GRzsXZ9R3MuQUadoGb5pSeMMC5+8n4jDdrGn2BHaq6C0BEZgNXA/Fux0wEpqjqMQBVPeI6thMQoKpLXOXpXozTmHJVUKC8vXw3LyzeSo0gf34zrC1X92hKy/oefGGe/YvCqjcgrC50u7HoWkF+Hiz/pzMg7sL/K/3LuSAfvnoaVrzujJoWP/j2z84jsiO0HuIMfAurC2H1nOkzcjOd5qaMJEhPcqbLqNsKbv647IPfjE94M2k0BRLcthOBfoWOaQcgIstxmrCeUdUvXOXHReRjoCXwFfC4qua7nywik4BJAM2aNfPGezDmrMQfOMGrX2+jce1Q+rasS9+WdalfM5h9KZk8MncDq3cfZXjHBvzl2q40CPdy539OBnxytzNJHsCOr527jNznUUo7DPPudEZCgzPW4dppzmjpopw87hy/4yvoMxFG/hX8A+HEAdiyCOLnOxPz5ZUwR1lAqDNT9I2zym2GVnPufN0RHgC0BQYDUcD3ItLVVT4I6AnsA+YAE4AzbpBW1anAVHBGhJdX0MaU5MO4BP44/ydCAv3JyStgxoo9ALSOrMHB1Cz8RXjxum5c1zvK+3f1pe6HD8bC4Z/gkuch9yQs/QscWAfXz3AGrO1ZDnPvgKxUuOY/To1g4QMw9WIY/idncj0/19I7GclwYD188Ts4thdGveoMcjulVhPoN8l5AORkOtNrZB51fgbVhBr1nRqIJ01RpsLxZtLYj9OJfUqUq8xdIrBKVXOB3SKyDSeJJALr3Zq25gMXUChpGFORZOXm89SCn/gwLpEBrevx6tie1A4NZNP+VFbvPsqq3Sm0bxTOk1d0oum5dnAf2wOH451J8Y5sgaStEFbH6UyO7ufM5JqyC2aPc764x82Gdpc65za7wKklTBsGXa5zptau0wJu+RgadnaOiYqBBZOd5BC/wBn5fOgnSD/k7A+rD7d9Cs37lxxnUJjzqF2974qrSrw295SIBADbgGE4ySIWuElVN7sdMxIYp6q3iUh9YB3QAzgOrAWGq2qSiEwH4lR1SnGvV9TcU8Z4w8INB/jj/J+oHRpI60hnwaEW9Wvw7o/72HLwBA8MbcNDw9vh743xEfl5sOg3zgysp9Ru5syvlHHE+WI/1Yor/s6MrOPmQMNCMw2nH4GPJzrThXe6Bq56HUIKrbOi6jQxffd3Z56lRl2cDutGXaBJr18fbyqlCjP3lKrmichkYDFOf8XbqrpZRJ7FSQALXfsuEZF4IB94VFVTAETkEeBrcerva4D/eitWYzz16YYDPDR7HV2jIoiuE8rOpAxW7EwhO6+AiLBApt/ehyHtG5R+obORm+XUEH5eBP0nO1/2ke3P/PLOTocDayFhldMkNOhhpzmosJoNnM7nI/FOIiiqmUwE+tzpPIxxqdKz3BpzPi3aeIDfzF5P7+Z1mHF7n9MT/uUXKAeOn6R2WCC1QgK98+LZafDBOKej+rIXoN/d3nkdU+1UmJqGMZXR8cwcPtt0iBb1w+gRHXE6Mfxv40EnYTSrw/QJfc6YIdbfT4iuW7YR22WSkQLvjYGDG53V47rd4L3XMqYUljSMcTmWkcNN01ax5aCzWqK/n9CpcS06NArn43X76dUsgum39ymfBYuyUp27mnZ/59wqm5kCY9+H9iO9/9rGlMCShjE4CWP8tFXsTErnzVt6ExTgx5o9x4jbe5RFGw9yQau6vHlLjHcTRk4mrH8PNn7oTMan+c5Yhub94eLfFb3GgzHlzJKGqfaOZ+Zw81ur2JGUzn9vjeHidpEApzu0CwrUuzPFnjwGsdPgxzcgMxkad4cLfwutBjtrRQdUoilFTJVnScNUGwlHM5m/bj+R4cE0r1eD5vXCCA3055a3V7H9SDpTb+l9OmG48yhh5GU74yWO7nI9djtjGjpe5awQV9SUHKmJztQecdOdGV3bXuIki2b9fbb+szGlsaRhqoW9KRnc+OaPHDrx62ktgvz9ePPW3gw+21tlE9c4t8Ie2/1LWc2GzvTdnz4I378IFz4EPW9xag2Ja2Dlv5xBcyh0vtbZ36jr2b2+MeXIkoap8hKOZjJu6o9k5+Wz6IELqR0ayL6jmexJySDx2EmGtG9A35Z1S75IUVN/FxQ4E/x9+zzUbOTc2dSgkzO6Orimc86Or53Bcf97GL5/yRkZnRgLwbWctaj73Q0RNm+aqTwsaZgqLeFoJmOn/khGTj7vT+xH5ybOTKrRdcM8Wys7MQ4W3O/MudTyIqefodVg8A+CTybB7u+dqcBHveosS+pOBNoOhzbDnLugvn/JGYk98m/OCnPBlWiRJGNcLGmYKmv/8ZPcNO1H0rJyeX/iBacThkfyc50v+e9fhPDG0HqokyA2f+zs9wt0ZnUd9Rr0urXkPgiRX5KNMZWcJQ1TpRQUKGv3HePznw6xYP0BsvPyeffOfnRpWoaEkbwdPp7kTMfRbSxc9ncIjXCam5K2OrWG5G3Q927PFxsypoqwpGEqvZT0bNbtO86yHcl8/tNBDp/IJsjfj4vaRfLQ8LaeJ4ysVFg5BZa/BoEhztThnUf/sl/EWV+iuDUmjKkGLGmYSicvv4CP1+1n5c4U1u47xt6UTACCA/wY3D6Sy7s2ZmiHBoR7Og9UTgasehOWvwpZx50+ipF/h1qNvfcmjKmkLGmYSmVDwnGe+HgT8QdPUL9mML2aRTCubzN6NatD16a1CQ3yL/7k/WudFeW0ABBnedL8XNj0obP8aNtLYcjvoUmPcno3xlQ+ljRMpZCRncfLX25jxord1K8ZzH/G92Jkl0aerXyXmghfPwsb5/zSga0FTh8F6gymG/IkNCu8GrExpjBLGqZCUVW+25bE/uMnyczOJyMnj8ycfBZtOMDBE1mM79eMx0Z28GwK8uw0WPZPZyCdqrO2xMCHbPEgY86BJQ1Tofzrmx28vGTbGWXBAX60axjO6zf1pHfzUgbhnZIYB3NugbQD0PV6GPaUDaIz5jywpGEqjHlrEnl5yTau7dmU313WgbAgf8KCAsq+bOq692DRQ874iju/gug+XonXmOrIkoapEJbvSOZ38zYyoHU9/jamG0EBfmW/SH4ufPkHZxLAlhfB9TMhzMOaiTHGI2fxP9NzIjJSRLaKyA4RebyYY24QkXgR2Swi7xfaV0tEEkXkX96M0/jWz4dOcM+sNbSOrMkbrrUsyiztMMwa7SSMC+6Dmz+xhGGMF3itpiEi/sAUYASQCMSKyEJVjXc7pi3wBDBQVY+JSOFpRp8DvvdWjMb3DqVmcfv0WMKC/Zl+e5+yr7GddtgZXxH3tnNH1DVvQI9x3gnWGOPV5qm+wA5V3QUgIrOBq4F4t2MmAlNU9RiAqh45tUNEegMNgS8Ajxc9N5VDWlYuM5bvYdqy3eQXKB/e3Z8mEaFluMAh586oNdOdZqluN8BFj0K91l6L2Rjj3aTRFEhw204ECt8I3w5ARJYD/sAzqvqFiPgBLwM3A8OLewERmQRMAmjWzO6MqQxOuJLFW8t2k3oyl+EdG/DwJe3p2NiD22Dzc2H7l7D+fdi22KlZdB/r3EprycKYcuHrjvAAoC0wGIgCvheRrjjJ4jNVTSxp8JaqTgWmAsTExKjXozXnZEn8YR75aIMrWTTkN8Pa0jXKg3mhjic4c0Jt+shZDrVGJPSdBH3vgrqtvB+4MeY0byaN/UC023aUq8xdIrBKVXOB3SKyDSeJ9AcGich9QE0gSETSVbXIznRTsakq/166k5e+3EqXJrX567Vdf5lEMGUnZJ+AJj2LPvl4Arw9EjKOQPvLoPtNzvoU/mXs+zDGnBfeTBqxQFsRaYmTLMYCNxU6Zj4wDpguIvVxmqt2qer4UweIyAQgxhJG5ZSVm89jczeycMMBrurehBeu60ZIoGt+qOP74K1L4OQxuPwF6HPXmSenJ8Gsa5yR3Xd9DY27lXv8xpgzeS1pqGqeiEwGFuP0V7ytqptF5FkgTlUXuvZdIiLxQD7wqKqmeCsmU74OpWYx8Z04fjqQyqOXtue+wa1/mSsqJwNm3wT5OdBykLMc6tHdMOJZ8PN3pil/91pI3Q+3zreEYUwFIapVoysgJiZG4+LifB2GcYk/cILbZ6wmPSuPf47tyYhODX/ZqQpzb4fN8+GmD51V8Rb/Hla/Ce2vgKtehzk3O2tpj5vtLJlqjPEKEVmjqh7foerrjnBTBS3bnsw9766hZnAAc+8d8Os7o354GTZ/AsOfgXaXOGWXv+B0ai9+Av7ZBXJPwnVvWcIwpoLx6ohwU/18vDaRCdNXE1UnlE/uLyJhbP0cvvmzM4ngwIfO3HfBPTD2AwipDaNehS5jyi1uY4xnrKZhzotTd0i9uHgrA1rX441bev96dPehTTBvorPI0VWvO8unFtZ+JLT/uVxiNsaUnSUNc04KCpQlWw7zr292sGl/KqN7NuXvRU04mLITZl3rrGVx43sQWIbR38aYCsOShjkr+QXKZ5sOMuXbHfx8KI3m9cJ44bpuXN876ter6Z044Nw6q/lwy/+gdlOfxGyMOXeWNEyZnbqVdtP+VFpH1uCVG7szqlsTAvyL6CLLPOrMPpt5FG77FCLblX/AxpjzxpKGKZP4Aye4Y0Ys6dl5vDq2B1d2a1L8IknZ6fDe9c74i5vnQtNe5RusMea8s6RhPPbtz0eY/P5aaoUG8tE9/YueZFAVjsRD/EL4aa6TMG6c5SyKZIyp9CxpGI/M+nEvTy/4iY6Na/H2hD40rBXyy87sdGcg3u7vnGRxdCcg0Kw/jHgOOlzus7iNMeeXJQ1Tqje/28lfP/+ZYR0a8Nq4ntQI8odd3znTk+9bAQc3Op3c4u9MCdL/fuhwJYQ3LP3ixphKxZKGKdGnGw7w189/5spujXl1bE/8D66Fr56B3d+DfzBExcCFv4Xm/SGqr3NLrTGmyrKkYYoVu+coD3+0gT4t6vDysJr4z7vdmf4jrB5c9gL0ug0CQ0q/kDGmyrCkYYq0OzmDie/EEVU7hJkdVhP85nNOzeLi30H/yVajMKaasqRhfiUlPZsJ01cTSAELWs4jbOks6DgKLn/Z+imMqeZKTRoiMgr4n6oWlEM8xoeycvP54qdD/GfpTtJSj/Jt8xmE//S902cx9Cnws/ktjanuPKlp3Aj8U0Tm4SykZLPJVTHxB04wJ3Yfn6zbz4msPGIiMphX7yVqHtzpTCzY61Zfh2iMqSBKTRqqerOI1MJZlnWGiCgwHfhAVdO8HaDxrinf7uDFxVsJCvDjsi6NGN+lBn2+vAbJSoPxc6H1EF+HaIypQDzq01DVEyIyFwgFHgJGA4+KyGuq+roX4zNetHbfMf6xZBtXdG3M86O7EBEa6CzBmpEEdyy2aT+MMb9SaiO1iFwlIp8AS4FAoK+qXgZ0Bx4u5dyRIrJVRHaIyOPFHHODiMSLyGYRed9V1kNEVrrKNorIjWV9Y6ZkGdl5/HbOehrVCuGvY7oSERYEsdNg62fOinqWMIwxRfCkpjEGeEVVv3cvVNVMEbmzuJNExB+YAowAEoFYEVmoqvFux7QFngAGquoxEWng2pUJ3Kqq20WkCbBGRBar6vGyvDlTvOcWxbPvaCZzJvV3Fks6HA9f/gFaD4N+9/o6PGNMBeXJ7TDPAKtPbYhIqIi0AFDVr0s4ry+wQ1V3qWoOMBu4utAxE4EpqnrMdb0jrp/bVHW76/kB4AgQ6ckbMqVbEn+Y2bEJ3HNxa/q2rOusxz3vTggOh9Fv2F1SxphiefLt8BHgfrttvqusNE2BBLftRFeZu3ZAOxFZLiI/isjIwhcRkb5AELCziH2TRCROROKSkpI8CMkcScvid/M20rlJLX473LW2xZd/dGamveYNqNmg5AsYY6o1T5JGgKumAIDredB5ev0AoC0wGOfurP+KSMSpnSLSGJgF3F7UOBFVnaqqMaoaExlpFZHSqCqPz9tERnYe/7yxh7Mk6+b5EPtfuOB+aDvc1yEaYyo4T5JGkohcdWpDRK4Gkj04bz8Q7bYd5SpzlwgsVNVcVd0NbMNJIrhu8/0f8KSq/ujB65lSvLNyL9/8fIQnLutA24bhsOMr+HgiRPWB4U/7OjxjTCXgSdK4B/i9iOwTkQTgd8DdHpwXC7QVkZYiEgSMBRYWOmY+Ti0DEamP01y1y3X8J8A7qjrXkzdiSrbl4Ame/2wLQzs04LYBLWDPcph9M0S2h/EfQUCwr0M0xlQCngzu2wlcICI1XdvpnlxYVfNEZDKwGPDHGU2+WUSeBeJUdaFr3yUiEo/TV/KoqqaIyM3ARUA9EZnguuQEVV1ftrdnAE7m5PPgB+uoHRrIi9d1Q/avhfdvgIhmcMt8CK3j6xCNMZWEqGrpB4lcAXQGTs+DrarPejGuMouJidG4uDhfh1EhPfnJJt5btY9Zd/ZlUPghmHGFkyhu/xxqNfF1eMYYHxKRNaoa4+nxngzuewNn/qkHAAGuB5qfdYSmXH3x0yHeW7WP+wc2YdCRD2DGlRAUDrcutIRhjCkzTwb3DVDVbiKyUVX/JCIvA597OzBz7g6mnuSP89bweL0fuHvrJ5B+yBm8d8VLUMfyvjGm7DxJGlmun5mu0dkpQGPvhWTOh9z8At6cMYMFBS/RJCMZmg+E66dD8wG+Ds0YU4l5kjQ+dY2deBFYCyjwX28GZc7dvxau4IGjzxMcXg+umQqth4KIr8MyxlRyJSYNEfEDvnbN+TRPRBYBIaqaWh7BmbPz2cYDdFn7R2oHZBNw6xxo0MHXIRljqogSO8Jdo7CnuG1nW8Ko2HYmpfPj3FcY4b8WRvzJEoYx5rzyZHDf1yIyRsTaNiq6zJw8np25iMf93iE7ehABF9zj65CMMVWMJ0njbpwJCrNF5ISIpInICS/HZcpIVXly3noeOPEyQYGBBF9ns9UaY84/T0aEh5dHIObsqSp/+2wLTX56k5jAbTBqGtSO8nVYxpgqqNSkISIXFVVeeFEmU86St8OaGXBsD8n7tvJARgI1A7PQztciXa/zdXTGmCrKk1tuH3V7HoKzuNIaYKhXIjKlU4UPb4WUHRwNjmJDWm1CGoxiQN9++PW8yW6tNcZ4jSfNU6Pct0UkGvintwIyHtizDI7E813HZ7htXTuu6dGEl2/ogZ+fJQtjjHedTU9pItDxfAdiymDVG2QHRjBpXQsu79qIl67vjr8lDGNMOfCkT+N1nFHg4CSZHjgjw40vHNuLbv2M9+UaujZvyD9v7EmAv90lZYwpH570abjPN54HfKCqy70UjylN7DQUYWrmEP42rK2zZKsxxpQTT5LGXCBLVfMBRMRfRMJUNdO7oZlfyclA185keUB/ajZozkVt6/s6ImNMNePRiHAg1G07FPjKO+GYEm38EMlK5dX0odw1qCU2SN8YU948SRoh7ku8up6HeXJxERkpIltFZIeIPF7MMTeISLyIbBaR993KbxOR7a7HbZ68XpWmCqveZG9QG3aHduXqHk19HZExphrypHkqQ0R6qepaABHpDZws7SQR8ceZ7HAEzh1XsSKyUFXj3Y5pCzwBDFTVYyLSwFVeF3gaiMHphF/jOvdY2d5eFbL7e0jawr9yJ3Hz4BaEBPr7OiJjTDXkSdJ4CPhIRA7gLPfaCGf519L0BXao6i4AEZkNXA3Eux0zEZhyKhmo6hFX+aXAElU96jp3CTAS+MCD162aVr1Jhn8En+ddyLcX2Kp7xhjf8GRwX6yIdADau4q2qmquB9duCiS4bScC/Qod0w5ARJYD/sAzqvpFMedWr/aYzKNwYB3sXwv716DbvmBWwdVc0aMlkeHBvo7OGFNNeTJO437gPVX9ybVdR0TGqeq/z9PrtwUGA1HA9yLS1dOTRWQSMAmgWbNm5yGcCmLxk7DyX79s129HfKOr+feey/nowpa+i8sYU+150hE+0bVyHwCupqSJHpy3H4h2245ylblLBBaqaq6q7ga24SQRT85FVaeqaoyqxkRGRnoQUiWQnQ6x06DtJXDrQnh8H2l3reD2lFvo3rYF7RvZpMPGGN/xJGn4uy/A5OrgDvLgvFigrYi0FJEgYCywsNAx83FqGYhIfZzmql3AYuASV62mDnCJq6zq2/4l5GXBwIfQlhfx+fZMhv/jO5LSs7l3cGtfR2eMqeY86Qj/ApgjIm+6tu8GPi/tJFXNE5HJOF/2/sDbqrpZRJ4F4lR1Ib8kh3ggH3hUVVMAROQ5nMQD8OypTvEqL34B1GhAQs1uPD0zjm9+PkLHxrV44+be9GxWx9fRGWOqOVHVkg8Q8cPpNxjmKtoINFLV+70cW5nExMRoXFxc6QdWZDmZ8GJrdjQZxahd1wLw8CXtmDCghc0vZYzxChFZo6oxnh7vyd1TBSKyCmgN3ADUB+adfYimWDu+gtxMntnRhh7NI3jphu40jQgt/TxjjCknxSYNEWkHjHM9koE5AKo6pHxCq37yN88nTWqxM7Q7n9/ci4gwT7qOjDGm/JRU0/gZ+AG4UlV3AIjIb8slquooN4u8LZ/zWW4//jK2pyUMY0yFVFJD+bXAQeBbEfmviAzDGRFuvGD7ygUEF2SS1XYUQ9o38HU4xhhTpGKThqrOV9WxQAfgW5zpRBqIyH9E5JJyiq9ayMjOY+d373OCmtxw/U2+DscYY4pV6i05qpqhqu+71gqPAtYBv/N6ZNXI3xZtYEDearLbXEbNMOv4NsZUXGW6j1NVj7lGYQ8r/WjjiRU7kklY8zm1JJPIvjf4OhxjjCmR3fxf3k4eg/QkAHLzC3hq4WauD12LBteCVhf7ODhjjCmZJyPCzflSUABvXQLJ26BeW3YEd6NzckMuqRmHtL8cAmz2WmNMxWZJozztXeYkjG43kp1+lKY7P+fVoEzIATpd7evojDGmVJY0ytPadyC4Nox6lSfnb+PTvAS+Hl+fKA5Du5G+js4YY0plSaO8ZB6F+IXQ61bWHsxi7ppE7r64NVGdOvo6MmOM8Zh1hJeXTR9BfjYFPW/hmYWbaRAezAND2/o6KmOMKRNLGuVBFdbMhMY9+DCxDhsTU/n95R2pGWwVPWNM5WJJozwcWAtHNnOy23heXLyVPi3qcHWPJr6Oyhhjysz+1C0Pa2dBQChTjvTgaGYSM0f1xW0xRGOMqTSspuFtORmwaS5pbUbx5upkru8dRZemtX0dlTHGnBVLGt62eT7kpDEldQDBAf48cml7X0dkjDFnzatJQ0RGishWEdkhIo8XsX+CiCSJyHrX4y63fS+IyGYR2SIir0llbc9Z+w6ZtVrxxu5I7h/ShgbhIb6OyBhjzprX+jRExB+YAowAEoFYEVmoqvGFDp2jqpMLnTsAGAh0cxUtAy4GlnorXq848jMk/Mh7IRNoVrcGd1zYwtcRGWPMOfFmTaMvsENVd6lqDjAb8HSuDAVCgCAgGAgEDnslSm8pyIf/PUyufxhvHO/H7y/vSHCAv6+jMsaYc+LNpNEUSHDbTnSVFTZGRDaKyFwRiQZQ1ZU4Cz8ddD0Wq+qWwieKyCQRiRORuKSkpPP/Ds7Fyn/B3mX8uWACbVu15NLODX0dkTHGnDNfd4R/CrRQ1W7AEmAmgIi0ATriLPrUFBgqIoMKn+xa2yNGVWMiIyPLMexSHNoEXz9HfO2LmJU1kKeu7Gy32BpjqgRvJo39QLTbdpSr7DRVTVHVbNfmNKC36/lo4EdVTVfVdOBzoL8XYz1/crNg3kRygyO4+chN3Nq/JZ2a1PJ1VMYYc154M2nEAm1FpKWIBAFjgYXuB4hIY7fNq4BTTVD7gItFJEBEAnE6wX/VPFUhff0sJG3h+cDJ+NeM5P8uaefriIwx5rzx2t1TqponIpOBxYA/8LaqbhaRZ4E4VV0IPCgiVwF5wFFgguv0ucBQYBNOp/gXqvqpt2I9b3YthR+nsDX6RmZsb8tr4zpRKyTQ11EZY8x5I6rq6xjOi5iYGI2Li/NdAPm58Fov8vyC6H/sadpFNeDdO/tZX4YxpkITkTWqGuPp8b7uCK86fl4EqfuYUeMOUnMDefbqLpYwjDFVjiWN82XVm2TVbMZfdjTj7otb0Tqypq8jMsaY886SxvlwYD3sW8mMvBE0rVuD+4e08XVExhjjFZY0zofVU8kPCOPfxy/g/0a0IyTQRn4bY6omW0/jXKUnwaaP+C5sJIFah8u7Ni79HGOMqaSspnGu1s6A/Bz+kjKIcX2b2fxSxpgqzZLGucjPhdi32FW7H7uJ4qZ+zXwdkTHGeJUljXOxZSGkHeSVE0MY0bEhTSJCfR2RMcZ4lSWNc7HqTdLCmrHoZBduHdDc19EYY4zXWdI4W/vXQsIq3mckbRrUon+rer6OyBhjvM6Sxtn6/kXyA8N5/Whfbu3f3EZ/G2OqBUsaZ2Pfj7D1M76IuBGCazG6V5SvIzLGmHJhSaOsVOGrZ8iv0YDfH7iQ63pHUTPYhrsYY6oHSxpltW0x7FvJF/VuIzU/iJsvsA5wY0z1YUmjLAry4es/kVWrBQ9t78pN/ZrRpoFNTGiMqT4saZTFpo/gSDx/zbqORnXCefLyjr6OyBhjypU1xnsqLxu+eZ79oe2ZdbwHH0zsTg3ryzDGVDNW0/BU3NuQuo/fpV7L7QNb08/GZRhjqiGvJg0RGSkiW0Vkh4g8XsT+CSKSJCLrXY+73PY1E5EvRWSLiMSLSAtvxlqipG0ULP07sdKNA/Uu4NFL2/ssFGOM8SWvta+IiD8wBRgBJAKxIrJQVeMLHTpHVScXcYl3gOdVdYmI1AQKvBVriVJ2wsxRpOcJj2ffxj/u6GHrZRhjqi1v1jT6AjtUdZeq5gCzgas9OVFEOgEBqroEQFXTVTXTe6EW4+humDmK/PxcxmQ8zvBBA+kRHVHuYRhjTEXhzaTRFEhw2050lRU2RkQ2ishcEYl2lbUDjovIxyKyTkRedNVcziAik0QkTkTikpKSzm/0x/bCzFGQe5IZbV5ll0Rzx8CW5/c1jDGmkvF1R/inQAtV7QYsAWa6ygOAQcAjQB+gFTCh8MmqOlVVY1Q1JjIy8vxFlZoIM6+E7DRyb57Pf7aEMqR9AxrWCjl/r2GMMZWQN5PGfiDabTvKVXaaqqaoarZrcxrQ2/U8EVjvatrKA+YDvbwY6y/Sj8DMq+BkKtw6n6+PNSQ5PZuxfaJLP9cYY6o4byaNWKCtiLQUkSBgLLDQ/QARcV9Q+ypgi9u5ESJyqvowFCjcgX7+nTwGs0ZD2kEY/xE06cmc2H00rBXM4PbnsSZjjDGVlNfunlLVPBGZDCwG/IG3VXWziDwLxKnqQuBBEbkKyAOO4mqCUtV8EXkE+FqcOcfXAP/1VqwAZKfDe9dD8ja4aQ4068eB4yf5blsS9w1uQ4C/r1vyjDHG97w6pFlVPwM+K1T2lNvzJ4Anijl3CdDNm/GdlpsFs29yFla6YSa0HgrAR3GJFCjcaE1TxhgD2DQikJ8Lc++A3d/BNW9Ax1FOcYHyYVwCF7apT3TdMB8HaYwxFYO1uRzfBwk/wuUvQY9xp4uX7Uhm//GTjO1rtQxjjDnFahr1WsPkOAire0bxnNh91AkLZESnhj4KzBhjKh6racCvEkZyejZL4g8zplcUwQE2ZYgxxpxiSaMI89ftJzdfrQPcGGMKsaRRhB93pdAqsgZtG4b7OhRjjKlQLGkUoqqs23ecntF1fB2KMcZUOJY0Ckk8dpKUjBx6NIvwdSjGGFPhWNIoZF3CcQB62hToxhjzK5Y0Clm/7zghgX50aGT9GcYYU5gljULWJRyja9PaNteUMcYUwb4Z3eTkFbD5wAlbnc8YY4phScPNloMnyMkroGczu3PKGGOKYknDzXpXJ7jVNIwxpmiWNNys23eMBuHBNK5ty7oaY0xRLGm4WZ9wnB7RETjrPhljjCnMkobLsYwc9qRkWn+GMcaUwJKGy/rE44D1ZxhjTEm8mjREZKSIbBWRHSLyeBH7J4hIkoisdz3uKrS/logkisi/vBknOIP6/AS6RdX29ksZY0yl5bVFmETEH5gCjAASgVgRWaiq8YUOnaOqk4u5zHPA996K0d26hOO0axhOjWBbl8oYY4rjzZpGX2CHqu5S1RxgNnC1pyeLSG+gIfCll+I7TVXZkHCcnjZJoTHGlMibSaMpkOC2negqK2yMiGwUkbkiEg0gIn7Ay8AjJb2AiEwSkTgRiUtKSjrrQHcnZ5B6Mtf6M4wxphS+7gj/FGihqt2AJcBMV/l9wGeqmljSyao6VVVjVDUmMjLyrIP4ZVCf3TlljDEl8WYD/n7Afb3UKFfZaaqa4rY5DXjB9bw/MEhE7gNqAkEikq6qv+pMPx/W7TtOjSB/2jSo6Y3LG2NMleHNpBELtBWRljjJYixwk/sBItJYVQ+6Nq8CtgCo6ni3YyYAMd5KGODUNLpHR+DvZ4P6jDGmJF5rnlLVPGAysBgnGXyoqptF5FkRucp12IMisllENgAPAhO8FU9xsnLz2XLQZrY1xhhPiKr6OobzIiYmRuPi4sp8XlJaNs8tiufGPtEMbFPfC5EZY0zFJSJrVDXG0+Or/aCEyPBgXhvX09dhGGNMpeDru6eMMcZUIpY0jDHGeMyShjHGGI9Z0jDGGOMxSxrGGGM8ZknDGGOMxyxpGGOM8ZglDWOMMR6rMiPCRSQJ2HsOl6gPJJ+ncMpLZYwZKmfcFnP5qYxxV8aYwYm7hqp6PE14lUka50pE4soylL4iqIwxQ+WM22IuP5Ux7soYM5xd3NY8ZYwxxmOWNIwxxnjMksYvpvo6gLNQGWOGyhm3xVx+KmPclTFmOIu4rU/DGGOMx6ymYYwxxmOWNIwxxnis2icNERkpIltFZIeIeG0d8nMlIm+LyBER+cmtrK6ILBGR7a6fdXwZY2EiEi0i34pIvGtZ39+4yits3CISIiKrRWSDK+Y/ucpbisgq1+dkjogE+TrWooiIv4isE5FFru0KHbeI7BGRTSKyXkTiXGUV9vNxiohEiMhcEflZRLaISP+KHLeItHf9jk89TojIQ2cTc7VOGiLiD0wBLgM6AeNEpJNvoyrWDGBkobLHga9VtS3wtWu7IskDHlbVTsAFwP2u329FjjsbGKqq3YEewEgRuQD4O/CKqrYBjgF3+i7EEv0G2OK2XRniHqKqPdzGC1Tkz8cprwJfqGoHoDvO77zCxq2qW12/4x5AbyAT+ISziVlVq+0D6A8sdtt+AnjC13GVEG8L4Ce37a1AY9fzxsBWX8dYSvwLgBGVJW4gDFgL9MMZ7RtQ1OemojyAKNd//KHAIkAqetzAHqB+obIK/fkAagO7cd1IVFnidovzEmD52cZcrWsaQFMgwW070VVWWTRU1YOu54eAhr4MpiQi0gLoCayigsftauJZDxwBlgA7geOqmuc6pKJ+Tv4JPAYUuLbrUfHjVuBLEVkjIpNcZRX68wG0BJKA6a6mwGkiUoOKH/cpY4EPXM/LHHN1TxpVhjp/KlTI+6dFpCYwD3hIVU+476uIcatqvjrV+CigL9DBtxGVTkSuBI6o6hpfx1JGF6pqL5wm4vtF5CL3nRXx8wEEAL2A/6hqTyCDQs06FTRuXH1aVwEfFd7naczVPWnsB6LdtqNcZZXFYRFpDOD6ecTH8fyKiATiJIz3VPVjV3GFjxtAVY8D3+I060SISIBrV0X8nAwErhKRPcBsnCaqV6ngcavqftfPIzht7H2p+J+PRCBRVVe5tufiJJGKHjc4yXmtqh52bZc55uqeNGKBtq47TIJwqm0LfRxTWSwEbnM9vw2nz6DCEBEB3gK2qOo/3HZV2LhFJFJEIlzPQ3H6YLbgJI/rXIdVqJgBVPUJVY1S1RY4n+NvVHU8FThuEakhIuGnnuO0tf9EBf58AKjqISBBRNq7ioYB8VTwuF3G8UvTFJxNzL7ulPH1A7gc2IbTbv2kr+MpIc4PgINALs5fOnfitFl/DWwHvgLq+jrOQjFfiFPd3Qisdz0ur8hxA92Ada6YfwKecpW3AlYDO3Cq9sG+jrWE9zAYWFTR43bFtsH12Hzq/19F/ny4xd4DiHN9TuYDdSp63EANIAWo7VZW5phtGhFjjDEeq+7NU8YYY8rAkoYxxhiPWdIwxhjjMUsaxhhjPGZJwxhjjMcsaRhTBiKSX2i20PM2KZ2ItHCfxdiYiiig9EOMMW5OqjPFiDHVktU0jDkPXOtCvOBaG2K1iLRxlbcQkW9EZKOIfC0izVzlDUXkE9e6HRtEZIDrUv4i8l/XWh5fukalG1NhWNIwpmxCCzVP3ei2L1VVuwL/wplxFuB1YKaqdgPeA15zlb8GfKfOuh29cEZEA7QFpqhqZ+A4MMar78aYMrIR4caUgYikq2rNIsr34CzetMs1SeMhVa0nIsk46xXkusoPqmp9EUkColQ12+0aLYAl6iyIg4j8DghU1T+Xw1szxiNW0zDm/NFinpdFttvzfKzf0VQwljSMOX9udPu50vV8Bc6sswDjgR9cz78G7oXTiz7VLq8gjTkX9leMMWUT6lrV75QvVPXUbbd1RGQjTm1hnKvsAZwV3h7FWe3tdlf5b4CpInInTo3iXpxZjI2p0KxPw5jzwNWnEaOqyb6OxRhvsuYpY4wxHrOahjHGGI9ZTcMYY4zHLGkYY4zxmCUNY4wxHrOkYYwxxmOWNIwxxnjs/wG6y8HFzDjqxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test accuracies\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train accuracy', 'Test accuracy'], loc='upper left')\n",
    "\n",
    "#plt.savefig('Q1(b)accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "m1B2Duvtn_fR",
    "outputId": "a923f73a-48a0-48a8-bba2-e21e599ec2b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x225b8e096d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test losses\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "#plt.savefig('Q1(b)loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "brxAKl_z1i8Q"
   },
   "outputs": [],
   "source": [
    "# comment on line plots\n",
    "\n",
    "# explain use of early stopping \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT0dZVbqoIrf"
   },
   "source": [
    "## Question 2\n",
    "\n",
    "In this question, we will determine the optimal batch size for mini-batch gradient descent. Find the optimal batch size for mini-batch gradient descent by training the neural network and evaluating the performances for different batch sizes. Note: Use 5-fold cross-validation on training partition to perform hyperparameter selection.\n",
    "\n",
    "You will have to reconsider the scaling of the dataset during the 5-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLQIjdwKopy7"
   },
   "source": [
    "### Part a\n",
    "\n",
    "Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch sizes {128, 256, 512, 1024}. This might take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NWeIlkr7omrj"
   },
   "outputs": [],
   "source": [
    "batch_size = [128, 256, 512, 1024]\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "no_epochs = 100\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "no_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "W9S6X0mc-1cK"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class TimingCallback(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "        \n",
    "timing_callback = TimingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WKpRkG7Y6Fvs"
   },
   "outputs": [],
   "source": [
    "# 5-fold cross-validation on training partition\n",
    "kfold = KFold(n_splits=no_folds, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsJJ18ir6Fzm",
    "outputId": "325e026a-c420-452d-ddc5-cd6c427e2f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- Batch Size: 128 -------\n",
      "\n",
      "Training for Fold 1 ...\n",
      "Epoch 1/100\n",
      "798/798 - 2s - loss: 0.6904 - accuracy: 0.5363 - val_loss: 0.6845 - val_accuracy: 0.5509 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6837 - accuracy: 0.5504 - val_loss: 0.6832 - val_accuracy: 0.5534 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6811 - accuracy: 0.5585 - val_loss: 0.6806 - val_accuracy: 0.5611 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6780 - accuracy: 0.5648 - val_loss: 0.6776 - val_accuracy: 0.5653 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6747 - accuracy: 0.5697 - val_loss: 0.6773 - val_accuracy: 0.5648 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6722 - accuracy: 0.5744 - val_loss: 0.6726 - val_accuracy: 0.5714 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6683 - accuracy: 0.5802 - val_loss: 0.6717 - val_accuracy: 0.5755 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6641 - accuracy: 0.5861 - val_loss: 0.6670 - val_accuracy: 0.5846 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6609 - accuracy: 0.5920 - val_loss: 0.6647 - val_accuracy: 0.5872 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6566 - accuracy: 0.5978 - val_loss: 0.6618 - val_accuracy: 0.5904 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6538 - accuracy: 0.6014 - val_loss: 0.6605 - val_accuracy: 0.5935 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6505 - accuracy: 0.6065 - val_loss: 0.6560 - val_accuracy: 0.6009 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6472 - accuracy: 0.6106 - val_loss: 0.6555 - val_accuracy: 0.6015 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6435 - accuracy: 0.6137 - val_loss: 0.6526 - val_accuracy: 0.6046 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6412 - accuracy: 0.6192 - val_loss: 0.6483 - val_accuracy: 0.6112 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6384 - accuracy: 0.6207 - val_loss: 0.6474 - val_accuracy: 0.6109 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6354 - accuracy: 0.6221 - val_loss: 0.6457 - val_accuracy: 0.6137 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6332 - accuracy: 0.6265 - val_loss: 0.6436 - val_accuracy: 0.6142 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6309 - accuracy: 0.6290 - val_loss: 0.6437 - val_accuracy: 0.6157 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6279 - accuracy: 0.6327 - val_loss: 0.6407 - val_accuracy: 0.6191 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6255 - accuracy: 0.6359 - val_loss: 0.6399 - val_accuracy: 0.6190 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6231 - accuracy: 0.6379 - val_loss: 0.6373 - val_accuracy: 0.6199 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6217 - accuracy: 0.6397 - val_loss: 0.6358 - val_accuracy: 0.6232 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6185 - accuracy: 0.6425 - val_loss: 0.6335 - val_accuracy: 0.6263 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6171 - accuracy: 0.6451 - val_loss: 0.6326 - val_accuracy: 0.6275 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6159 - accuracy: 0.6458 - val_loss: 0.6308 - val_accuracy: 0.6303 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6120 - accuracy: 0.6486 - val_loss: 0.6314 - val_accuracy: 0.6291 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6125 - accuracy: 0.6481 - val_loss: 0.6292 - val_accuracy: 0.6345 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6100 - accuracy: 0.6508 - val_loss: 0.6273 - val_accuracy: 0.6336 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6087 - accuracy: 0.6543 - val_loss: 0.6279 - val_accuracy: 0.6334 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6068 - accuracy: 0.6556 - val_loss: 0.6258 - val_accuracy: 0.6362 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6068 - accuracy: 0.6562 - val_loss: 0.6245 - val_accuracy: 0.6385 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6039 - accuracy: 0.6589 - val_loss: 0.6237 - val_accuracy: 0.6379 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6050 - accuracy: 0.6567 - val_loss: 0.6229 - val_accuracy: 0.6400 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6017 - accuracy: 0.6600 - val_loss: 0.6219 - val_accuracy: 0.6381 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6001 - accuracy: 0.6620 - val_loss: 0.6214 - val_accuracy: 0.6433 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.6007 - accuracy: 0.6627 - val_loss: 0.6213 - val_accuracy: 0.6421 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.5990 - accuracy: 0.6625 - val_loss: 0.6194 - val_accuracy: 0.6416 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5974 - accuracy: 0.6640 - val_loss: 0.6194 - val_accuracy: 0.6456 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5967 - accuracy: 0.6653 - val_loss: 0.6195 - val_accuracy: 0.6451 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5959 - accuracy: 0.6666 - val_loss: 0.6169 - val_accuracy: 0.6454 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5944 - accuracy: 0.6674 - val_loss: 0.6169 - val_accuracy: 0.6442 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5930 - accuracy: 0.6676 - val_loss: 0.6171 - val_accuracy: 0.6437 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.5930 - accuracy: 0.6684 - val_loss: 0.6173 - val_accuracy: 0.6483 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.5909 - accuracy: 0.6705 - val_loss: 0.6162 - val_accuracy: 0.6471 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5898 - accuracy: 0.6727 - val_loss: 0.6152 - val_accuracy: 0.6473 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.5884 - accuracy: 0.6716 - val_loss: 0.6154 - val_accuracy: 0.6474 - 2s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.5892 - accuracy: 0.6717 - val_loss: 0.6144 - val_accuracy: 0.6488 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5883 - accuracy: 0.6730 - val_loss: 0.6134 - val_accuracy: 0.6504 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.5857 - accuracy: 0.6753 - val_loss: 0.6135 - val_accuracy: 0.6505 - 2s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 2s - loss: 0.5867 - accuracy: 0.6733 - val_loss: 0.6127 - val_accuracy: 0.6483 - 2s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "798/798 - 2s - loss: 0.5867 - accuracy: 0.6747 - val_loss: 0.6145 - val_accuracy: 0.6474 - 2s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "798/798 - 2s - loss: 0.5872 - accuracy: 0.6736 - val_loss: 0.6133 - val_accuracy: 0.6518 - 2s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "798/798 - 2s - loss: 0.5835 - accuracy: 0.6769 - val_loss: 0.6110 - val_accuracy: 0.6531 - 2s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "798/798 - 2s - loss: 0.5840 - accuracy: 0.6775 - val_loss: 0.6133 - val_accuracy: 0.6504 - 2s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "798/798 - 2s - loss: 0.5833 - accuracy: 0.6744 - val_loss: 0.6119 - val_accuracy: 0.6537 - 2s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "798/798 - 2s - loss: 0.5832 - accuracy: 0.6778 - val_loss: 0.6106 - val_accuracy: 0.6519 - 2s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "798/798 - 2s - loss: 0.5805 - accuracy: 0.6792 - val_loss: 0.6114 - val_accuracy: 0.6530 - 2s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "798/798 - 2s - loss: 0.5800 - accuracy: 0.6797 - val_loss: 0.6101 - val_accuracy: 0.6522 - 2s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "798/798 - 2s - loss: 0.5799 - accuracy: 0.6798 - val_loss: 0.6113 - val_accuracy: 0.6505 - 2s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "798/798 - 2s - loss: 0.5789 - accuracy: 0.6810 - val_loss: 0.6109 - val_accuracy: 0.6517 - 2s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "798/798 - 2s - loss: 0.5793 - accuracy: 0.6824 - val_loss: 0.6103 - val_accuracy: 0.6531 - 2s/epoch - 2ms/step\n",
      "\n",
      "Training for Fold 2 ...\n",
      "Epoch 1/100\n",
      "798/798 - 2s - loss: 0.6882 - accuracy: 0.5405 - val_loss: 0.6849 - val_accuracy: 0.5475 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6830 - accuracy: 0.5518 - val_loss: 0.6826 - val_accuracy: 0.5497 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6799 - accuracy: 0.5596 - val_loss: 0.6801 - val_accuracy: 0.5568 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6772 - accuracy: 0.5631 - val_loss: 0.6786 - val_accuracy: 0.5621 - 2s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6742 - accuracy: 0.5713 - val_loss: 0.6755 - val_accuracy: 0.5688 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6701 - accuracy: 0.5774 - val_loss: 0.6722 - val_accuracy: 0.5728 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6668 - accuracy: 0.5826 - val_loss: 0.6695 - val_accuracy: 0.5803 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6637 - accuracy: 0.5899 - val_loss: 0.6671 - val_accuracy: 0.5838 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6599 - accuracy: 0.5936 - val_loss: 0.6642 - val_accuracy: 0.5894 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6555 - accuracy: 0.6005 - val_loss: 0.6618 - val_accuracy: 0.5914 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6524 - accuracy: 0.6047 - val_loss: 0.6592 - val_accuracy: 0.5972 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6490 - accuracy: 0.6083 - val_loss: 0.6570 - val_accuracy: 0.6008 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6457 - accuracy: 0.6118 - val_loss: 0.6530 - val_accuracy: 0.6037 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6437 - accuracy: 0.6149 - val_loss: 0.6508 - val_accuracy: 0.6067 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6405 - accuracy: 0.6176 - val_loss: 0.6497 - val_accuracy: 0.6058 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6372 - accuracy: 0.6215 - val_loss: 0.6464 - val_accuracy: 0.6130 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6344 - accuracy: 0.6256 - val_loss: 0.6454 - val_accuracy: 0.6131 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6328 - accuracy: 0.6268 - val_loss: 0.6442 - val_accuracy: 0.6148 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6305 - accuracy: 0.6302 - val_loss: 0.6414 - val_accuracy: 0.6181 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6273 - accuracy: 0.6322 - val_loss: 0.6393 - val_accuracy: 0.6198 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6250 - accuracy: 0.6367 - val_loss: 0.6377 - val_accuracy: 0.6236 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6236 - accuracy: 0.6392 - val_loss: 0.6362 - val_accuracy: 0.6236 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6210 - accuracy: 0.6402 - val_loss: 0.6355 - val_accuracy: 0.6260 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6192 - accuracy: 0.6424 - val_loss: 0.6337 - val_accuracy: 0.6249 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6189 - accuracy: 0.6434 - val_loss: 0.6343 - val_accuracy: 0.6281 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6155 - accuracy: 0.6473 - val_loss: 0.6335 - val_accuracy: 0.6280 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6136 - accuracy: 0.6477 - val_loss: 0.6300 - val_accuracy: 0.6314 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6117 - accuracy: 0.6504 - val_loss: 0.6316 - val_accuracy: 0.6283 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6107 - accuracy: 0.6496 - val_loss: 0.6288 - val_accuracy: 0.6323 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6084 - accuracy: 0.6530 - val_loss: 0.6280 - val_accuracy: 0.6352 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6087 - accuracy: 0.6536 - val_loss: 0.6262 - val_accuracy: 0.6371 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6067 - accuracy: 0.6574 - val_loss: 0.6260 - val_accuracy: 0.6369 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6037 - accuracy: 0.6576 - val_loss: 0.6246 - val_accuracy: 0.6391 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6028 - accuracy: 0.6598 - val_loss: 0.6229 - val_accuracy: 0.6416 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6026 - accuracy: 0.6594 - val_loss: 0.6226 - val_accuracy: 0.6421 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6008 - accuracy: 0.6614 - val_loss: 0.6220 - val_accuracy: 0.6439 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.6005 - accuracy: 0.6622 - val_loss: 0.6217 - val_accuracy: 0.6433 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.5990 - accuracy: 0.6626 - val_loss: 0.6196 - val_accuracy: 0.6451 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5982 - accuracy: 0.6631 - val_loss: 0.6211 - val_accuracy: 0.6431 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5969 - accuracy: 0.6662 - val_loss: 0.6202 - val_accuracy: 0.6425 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5955 - accuracy: 0.6647 - val_loss: 0.6204 - val_accuracy: 0.6430 - 2s/epoch - 2ms/step\n",
      "\n",
      "Training for Fold 3 ...\n",
      "Epoch 1/100\n",
      "798/798 - 2s - loss: 0.6880 - accuracy: 0.5429 - val_loss: 0.6839 - val_accuracy: 0.5505 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6820 - accuracy: 0.5554 - val_loss: 0.6820 - val_accuracy: 0.5572 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6794 - accuracy: 0.5614 - val_loss: 0.6794 - val_accuracy: 0.5614 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6760 - accuracy: 0.5695 - val_loss: 0.6773 - val_accuracy: 0.5691 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6724 - accuracy: 0.5752 - val_loss: 0.6737 - val_accuracy: 0.5727 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6698 - accuracy: 0.5806 - val_loss: 0.6709 - val_accuracy: 0.5775 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6660 - accuracy: 0.5868 - val_loss: 0.6688 - val_accuracy: 0.5825 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6622 - accuracy: 0.5929 - val_loss: 0.6652 - val_accuracy: 0.5897 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6591 - accuracy: 0.5972 - val_loss: 0.6627 - val_accuracy: 0.5904 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6555 - accuracy: 0.6028 - val_loss: 0.6593 - val_accuracy: 0.5966 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6525 - accuracy: 0.6062 - val_loss: 0.6587 - val_accuracy: 0.5961 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6498 - accuracy: 0.6097 - val_loss: 0.6553 - val_accuracy: 0.6043 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6462 - accuracy: 0.6155 - val_loss: 0.6519 - val_accuracy: 0.6083 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6433 - accuracy: 0.6182 - val_loss: 0.6493 - val_accuracy: 0.6118 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6396 - accuracy: 0.6221 - val_loss: 0.6476 - val_accuracy: 0.6135 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6366 - accuracy: 0.6244 - val_loss: 0.6448 - val_accuracy: 0.6175 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6345 - accuracy: 0.6286 - val_loss: 0.6442 - val_accuracy: 0.6214 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6316 - accuracy: 0.6310 - val_loss: 0.6419 - val_accuracy: 0.6217 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6300 - accuracy: 0.6334 - val_loss: 0.6402 - val_accuracy: 0.6228 - 2s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6261 - accuracy: 0.6377 - val_loss: 0.6382 - val_accuracy: 0.6227 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6248 - accuracy: 0.6393 - val_loss: 0.6363 - val_accuracy: 0.6306 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6215 - accuracy: 0.6447 - val_loss: 0.6346 - val_accuracy: 0.6287 - 2s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6202 - accuracy: 0.6449 - val_loss: 0.6354 - val_accuracy: 0.6278 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6185 - accuracy: 0.6474 - val_loss: 0.6320 - val_accuracy: 0.6311 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6175 - accuracy: 0.6469 - val_loss: 0.6315 - val_accuracy: 0.6330 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6155 - accuracy: 0.6473 - val_loss: 0.6305 - val_accuracy: 0.6354 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6134 - accuracy: 0.6512 - val_loss: 0.6285 - val_accuracy: 0.6355 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6120 - accuracy: 0.6522 - val_loss: 0.6274 - val_accuracy: 0.6374 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6101 - accuracy: 0.6535 - val_loss: 0.6275 - val_accuracy: 0.6386 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 4s - loss: 0.6084 - accuracy: 0.6552 - val_loss: 0.6254 - val_accuracy: 0.6394 - 4s/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 4s - loss: 0.6076 - accuracy: 0.6569 - val_loss: 0.6236 - val_accuracy: 0.6394 - 4s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 4s - loss: 0.6060 - accuracy: 0.6586 - val_loss: 0.6255 - val_accuracy: 0.6396 - 4s/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 4s - loss: 0.6027 - accuracy: 0.6620 - val_loss: 0.6232 - val_accuracy: 0.6423 - 4s/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6021 - accuracy: 0.6647 - val_loss: 0.6214 - val_accuracy: 0.6431 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.5994 - accuracy: 0.6650 - val_loss: 0.6215 - val_accuracy: 0.6419 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6016 - accuracy: 0.6647 - val_loss: 0.6209 - val_accuracy: 0.6422 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.5980 - accuracy: 0.6673 - val_loss: 0.6194 - val_accuracy: 0.6448 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.5989 - accuracy: 0.6647 - val_loss: 0.6181 - val_accuracy: 0.6463 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5967 - accuracy: 0.6668 - val_loss: 0.6180 - val_accuracy: 0.6489 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5966 - accuracy: 0.6682 - val_loss: 0.6164 - val_accuracy: 0.6520 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5949 - accuracy: 0.6684 - val_loss: 0.6173 - val_accuracy: 0.6495 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5939 - accuracy: 0.6688 - val_loss: 0.6177 - val_accuracy: 0.6480 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5916 - accuracy: 0.6724 - val_loss: 0.6159 - val_accuracy: 0.6497 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.5898 - accuracy: 0.6738 - val_loss: 0.6146 - val_accuracy: 0.6501 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.5893 - accuracy: 0.6747 - val_loss: 0.6137 - val_accuracy: 0.6505 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5883 - accuracy: 0.6753 - val_loss: 0.6133 - val_accuracy: 0.6521 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.5876 - accuracy: 0.6742 - val_loss: 0.6154 - val_accuracy: 0.6503 - 2s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.5875 - accuracy: 0.6755 - val_loss: 0.6129 - val_accuracy: 0.6520 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5861 - accuracy: 0.6762 - val_loss: 0.6140 - val_accuracy: 0.6512 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.5875 - accuracy: 0.6766 - val_loss: 0.6130 - val_accuracy: 0.6526 - 2s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 2s - loss: 0.5849 - accuracy: 0.6794 - val_loss: 0.6130 - val_accuracy: 0.6526 - 2s/epoch - 2ms/step\n",
      "\n",
      "Training for Fold 4 ...\n",
      "Epoch 1/100\n",
      "798/798 - 2s - loss: 0.6888 - accuracy: 0.5386 - val_loss: 0.6847 - val_accuracy: 0.5484 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6829 - accuracy: 0.5533 - val_loss: 0.6832 - val_accuracy: 0.5529 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6806 - accuracy: 0.5599 - val_loss: 0.6799 - val_accuracy: 0.5612 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6776 - accuracy: 0.5654 - val_loss: 0.6786 - val_accuracy: 0.5656 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6740 - accuracy: 0.5715 - val_loss: 0.6747 - val_accuracy: 0.5728 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6706 - accuracy: 0.5795 - val_loss: 0.6717 - val_accuracy: 0.5782 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6665 - accuracy: 0.5834 - val_loss: 0.6688 - val_accuracy: 0.5847 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6627 - accuracy: 0.5907 - val_loss: 0.6657 - val_accuracy: 0.5907 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6592 - accuracy: 0.5970 - val_loss: 0.6623 - val_accuracy: 0.5909 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6551 - accuracy: 0.6041 - val_loss: 0.6597 - val_accuracy: 0.6007 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6529 - accuracy: 0.6059 - val_loss: 0.6582 - val_accuracy: 0.6004 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6484 - accuracy: 0.6104 - val_loss: 0.6561 - val_accuracy: 0.6024 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6452 - accuracy: 0.6154 - val_loss: 0.6537 - val_accuracy: 0.6055 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6422 - accuracy: 0.6182 - val_loss: 0.6520 - val_accuracy: 0.6063 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6401 - accuracy: 0.6229 - val_loss: 0.6488 - val_accuracy: 0.6112 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6360 - accuracy: 0.6278 - val_loss: 0.6466 - val_accuracy: 0.6146 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6336 - accuracy: 0.6294 - val_loss: 0.6457 - val_accuracy: 0.6143 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6323 - accuracy: 0.6323 - val_loss: 0.6423 - val_accuracy: 0.6195 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6294 - accuracy: 0.6368 - val_loss: 0.6426 - val_accuracy: 0.6186 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6279 - accuracy: 0.6361 - val_loss: 0.6409 - val_accuracy: 0.6214 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6258 - accuracy: 0.6384 - val_loss: 0.6388 - val_accuracy: 0.6215 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6237 - accuracy: 0.6390 - val_loss: 0.6384 - val_accuracy: 0.6236 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6208 - accuracy: 0.6431 - val_loss: 0.6368 - val_accuracy: 0.6252 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6185 - accuracy: 0.6466 - val_loss: 0.6347 - val_accuracy: 0.6282 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6181 - accuracy: 0.6465 - val_loss: 0.6335 - val_accuracy: 0.6298 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6172 - accuracy: 0.6475 - val_loss: 0.6333 - val_accuracy: 0.6300 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6140 - accuracy: 0.6515 - val_loss: 0.6313 - val_accuracy: 0.6319 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6123 - accuracy: 0.6534 - val_loss: 0.6315 - val_accuracy: 0.6330 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6104 - accuracy: 0.6562 - val_loss: 0.6294 - val_accuracy: 0.6340 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6089 - accuracy: 0.6548 - val_loss: 0.6282 - val_accuracy: 0.6346 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6083 - accuracy: 0.6555 - val_loss: 0.6276 - val_accuracy: 0.6377 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6060 - accuracy: 0.6591 - val_loss: 0.6257 - val_accuracy: 0.6397 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6044 - accuracy: 0.6602 - val_loss: 0.6251 - val_accuracy: 0.6384 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6037 - accuracy: 0.6615 - val_loss: 0.6251 - val_accuracy: 0.6400 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6031 - accuracy: 0.6612 - val_loss: 0.6227 - val_accuracy: 0.6413 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.5996 - accuracy: 0.6655 - val_loss: 0.6216 - val_accuracy: 0.6432 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.6001 - accuracy: 0.6649 - val_loss: 0.6223 - val_accuracy: 0.6413 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.5983 - accuracy: 0.6657 - val_loss: 0.6216 - val_accuracy: 0.6434 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5987 - accuracy: 0.6663 - val_loss: 0.6195 - val_accuracy: 0.6449 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5953 - accuracy: 0.6679 - val_loss: 0.6210 - val_accuracy: 0.6436 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5952 - accuracy: 0.6701 - val_loss: 0.6202 - val_accuracy: 0.6441 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5922 - accuracy: 0.6711 - val_loss: 0.6186 - val_accuracy: 0.6463 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5926 - accuracy: 0.6729 - val_loss: 0.6205 - val_accuracy: 0.6429 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.5906 - accuracy: 0.6732 - val_loss: 0.6164 - val_accuracy: 0.6470 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.5918 - accuracy: 0.6722 - val_loss: 0.6179 - val_accuracy: 0.6476 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5898 - accuracy: 0.6732 - val_loss: 0.6153 - val_accuracy: 0.6481 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.5900 - accuracy: 0.6739 - val_loss: 0.6151 - val_accuracy: 0.6476 - 2s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.5887 - accuracy: 0.6753 - val_loss: 0.6151 - val_accuracy: 0.6483 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5852 - accuracy: 0.6788 - val_loss: 0.6146 - val_accuracy: 0.6520 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.5852 - accuracy: 0.6781 - val_loss: 0.6129 - val_accuracy: 0.6501 - 2s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 2s - loss: 0.5856 - accuracy: 0.6787 - val_loss: 0.6128 - val_accuracy: 0.6523 - 2s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "798/798 - 2s - loss: 0.5845 - accuracy: 0.6790 - val_loss: 0.6129 - val_accuracy: 0.6534 - 2s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "798/798 - 2s - loss: 0.5844 - accuracy: 0.6793 - val_loss: 0.6120 - val_accuracy: 0.6542 - 2s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "798/798 - 2s - loss: 0.5822 - accuracy: 0.6798 - val_loss: 0.6101 - val_accuracy: 0.6561 - 2s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "798/798 - 2s - loss: 0.5825 - accuracy: 0.6818 - val_loss: 0.6101 - val_accuracy: 0.6552 - 2s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "798/798 - 3s - loss: 0.5827 - accuracy: 0.6827 - val_loss: 0.6108 - val_accuracy: 0.6528 - 3s/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "798/798 - 3s - loss: 0.5813 - accuracy: 0.6827 - val_loss: 0.6095 - val_accuracy: 0.6561 - 3s/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "798/798 - 5s - loss: 0.5802 - accuracy: 0.6827 - val_loss: 0.6097 - val_accuracy: 0.6555 - 5s/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "798/798 - 3s - loss: 0.5806 - accuracy: 0.6828 - val_loss: 0.6087 - val_accuracy: 0.6551 - 3s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "798/798 - 2s - loss: 0.5785 - accuracy: 0.6849 - val_loss: 0.6088 - val_accuracy: 0.6551 - 2s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "798/798 - 2s - loss: 0.5780 - accuracy: 0.6858 - val_loss: 0.6081 - val_accuracy: 0.6575 - 2s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "798/798 - 2s - loss: 0.5778 - accuracy: 0.6853 - val_loss: 0.6103 - val_accuracy: 0.6528 - 2s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "798/798 - 2s - loss: 0.5767 - accuracy: 0.6847 - val_loss: 0.6088 - val_accuracy: 0.6543 - 2s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "798/798 - 2s - loss: 0.5754 - accuracy: 0.6879 - val_loss: 0.6074 - val_accuracy: 0.6559 - 2s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "798/798 - 2s - loss: 0.5757 - accuracy: 0.6883 - val_loss: 0.6061 - val_accuracy: 0.6578 - 2s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "798/798 - 2s - loss: 0.5748 - accuracy: 0.6861 - val_loss: 0.6074 - val_accuracy: 0.6556 - 2s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "798/798 - 2s - loss: 0.5758 - accuracy: 0.6890 - val_loss: 0.6065 - val_accuracy: 0.6544 - 2s/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "798/798 - 2s - loss: 0.5740 - accuracy: 0.6877 - val_loss: 0.6072 - val_accuracy: 0.6557 - 2s/epoch - 2ms/step\n",
      "\n",
      "Training for Fold 5 ...\n",
      "Epoch 1/100\n",
      "798/798 - 2s - loss: 0.6884 - accuracy: 0.5415 - val_loss: 0.6852 - val_accuracy: 0.5465 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6823 - accuracy: 0.5548 - val_loss: 0.6833 - val_accuracy: 0.5509 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6803 - accuracy: 0.5602 - val_loss: 0.6805 - val_accuracy: 0.5597 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6768 - accuracy: 0.5666 - val_loss: 0.6779 - val_accuracy: 0.5638 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6738 - accuracy: 0.5718 - val_loss: 0.6749 - val_accuracy: 0.5692 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6704 - accuracy: 0.5767 - val_loss: 0.6731 - val_accuracy: 0.5738 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6671 - accuracy: 0.5837 - val_loss: 0.6695 - val_accuracy: 0.5804 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6634 - accuracy: 0.5900 - val_loss: 0.6670 - val_accuracy: 0.5799 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6598 - accuracy: 0.5945 - val_loss: 0.6649 - val_accuracy: 0.5892 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6557 - accuracy: 0.5979 - val_loss: 0.6604 - val_accuracy: 0.5922 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6529 - accuracy: 0.6031 - val_loss: 0.6580 - val_accuracy: 0.5947 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6502 - accuracy: 0.6078 - val_loss: 0.6554 - val_accuracy: 0.5995 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6469 - accuracy: 0.6106 - val_loss: 0.6534 - val_accuracy: 0.6013 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6454 - accuracy: 0.6152 - val_loss: 0.6522 - val_accuracy: 0.6023 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6414 - accuracy: 0.6191 - val_loss: 0.6473 - val_accuracy: 0.6106 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6381 - accuracy: 0.6227 - val_loss: 0.6479 - val_accuracy: 0.6135 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6363 - accuracy: 0.6253 - val_loss: 0.6434 - val_accuracy: 0.6147 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6326 - accuracy: 0.6292 - val_loss: 0.6420 - val_accuracy: 0.6170 - 2s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6311 - accuracy: 0.6294 - val_loss: 0.6402 - val_accuracy: 0.6200 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6281 - accuracy: 0.6337 - val_loss: 0.6388 - val_accuracy: 0.6198 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6257 - accuracy: 0.6369 - val_loss: 0.6383 - val_accuracy: 0.6223 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6249 - accuracy: 0.6379 - val_loss: 0.6357 - val_accuracy: 0.6247 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6221 - accuracy: 0.6409 - val_loss: 0.6370 - val_accuracy: 0.6264 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6214 - accuracy: 0.6409 - val_loss: 0.6336 - val_accuracy: 0.6278 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6175 - accuracy: 0.6441 - val_loss: 0.6322 - val_accuracy: 0.6296 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6166 - accuracy: 0.6473 - val_loss: 0.6312 - val_accuracy: 0.6328 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6159 - accuracy: 0.6462 - val_loss: 0.6311 - val_accuracy: 0.6309 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6142 - accuracy: 0.6485 - val_loss: 0.6301 - val_accuracy: 0.6311 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6115 - accuracy: 0.6505 - val_loss: 0.6282 - val_accuracy: 0.6356 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6105 - accuracy: 0.6522 - val_loss: 0.6277 - val_accuracy: 0.6347 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6077 - accuracy: 0.6556 - val_loss: 0.6269 - val_accuracy: 0.6358 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6071 - accuracy: 0.6559 - val_loss: 0.6267 - val_accuracy: 0.6371 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6070 - accuracy: 0.6568 - val_loss: 0.6240 - val_accuracy: 0.6381 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6049 - accuracy: 0.6575 - val_loss: 0.6237 - val_accuracy: 0.6393 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6032 - accuracy: 0.6603 - val_loss: 0.6227 - val_accuracy: 0.6419 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6024 - accuracy: 0.6617 - val_loss: 0.6240 - val_accuracy: 0.6392 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.6015 - accuracy: 0.6618 - val_loss: 0.6218 - val_accuracy: 0.6388 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.6001 - accuracy: 0.6626 - val_loss: 0.6215 - val_accuracy: 0.6417 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5993 - accuracy: 0.6638 - val_loss: 0.6200 - val_accuracy: 0.6449 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5985 - accuracy: 0.6646 - val_loss: 0.6188 - val_accuracy: 0.6424 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5980 - accuracy: 0.6644 - val_loss: 0.6192 - val_accuracy: 0.6448 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5960 - accuracy: 0.6671 - val_loss: 0.6182 - val_accuracy: 0.6443 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5943 - accuracy: 0.6678 - val_loss: 0.6172 - val_accuracy: 0.6471 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.5947 - accuracy: 0.6679 - val_loss: 0.6157 - val_accuracy: 0.6484 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.5931 - accuracy: 0.6700 - val_loss: 0.6168 - val_accuracy: 0.6477 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5922 - accuracy: 0.6704 - val_loss: 0.6166 - val_accuracy: 0.6490 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.5907 - accuracy: 0.6707 - val_loss: 0.6157 - val_accuracy: 0.6479 - 2s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.5899 - accuracy: 0.6728 - val_loss: 0.6159 - val_accuracy: 0.6501 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5899 - accuracy: 0.6717 - val_loss: 0.6146 - val_accuracy: 0.6516 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.5885 - accuracy: 0.6745 - val_loss: 0.6139 - val_accuracy: 0.6504 - 2s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 2s - loss: 0.5892 - accuracy: 0.6730 - val_loss: 0.6134 - val_accuracy: 0.6489 - 2s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "798/798 - 2s - loss: 0.5862 - accuracy: 0.6757 - val_loss: 0.6122 - val_accuracy: 0.6532 - 2s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "798/798 - 2s - loss: 0.5878 - accuracy: 0.6758 - val_loss: 0.6123 - val_accuracy: 0.6528 - 2s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "798/798 - 2s - loss: 0.5866 - accuracy: 0.6758 - val_loss: 0.6104 - val_accuracy: 0.6538 - 2s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "798/798 - 2s - loss: 0.5850 - accuracy: 0.6763 - val_loss: 0.6111 - val_accuracy: 0.6530 - 2s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "798/798 - 2s - loss: 0.5844 - accuracy: 0.6773 - val_loss: 0.6098 - val_accuracy: 0.6544 - 2s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "798/798 - 2s - loss: 0.5842 - accuracy: 0.6783 - val_loss: 0.6070 - val_accuracy: 0.6570 - 2s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "798/798 - 2s - loss: 0.5829 - accuracy: 0.6802 - val_loss: 0.6101 - val_accuracy: 0.6559 - 2s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "798/798 - 2s - loss: 0.5824 - accuracy: 0.6794 - val_loss: 0.6081 - val_accuracy: 0.6549 - 2s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "798/798 - 2s - loss: 0.5796 - accuracy: 0.6813 - val_loss: 0.6070 - val_accuracy: 0.6575 - 2s/epoch - 2ms/step\n",
      "\n",
      "------- Batch Size: 256 -------\n",
      "\n",
      "Training for Fold 1 ...\n",
      "Epoch 1/100\n",
      "399/399 - 2s - loss: 0.6885 - accuracy: 0.5407 - val_loss: 0.6842 - val_accuracy: 0.5472 - 2s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "399/399 - 1s - loss: 0.6824 - accuracy: 0.5559 - val_loss: 0.6820 - val_accuracy: 0.5532 - 1s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "399/399 - 1s - loss: 0.6796 - accuracy: 0.5616 - val_loss: 0.6798 - val_accuracy: 0.5584 - 1s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "399/399 - 1s - loss: 0.6760 - accuracy: 0.5700 - val_loss: 0.6774 - val_accuracy: 0.5616 - 1s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "399/399 - 1s - loss: 0.6728 - accuracy: 0.5743 - val_loss: 0.6741 - val_accuracy: 0.5742 - 1s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "399/399 - 1s - loss: 0.6693 - accuracy: 0.5802 - val_loss: 0.6726 - val_accuracy: 0.5757 - 1s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "399/399 - 1s - loss: 0.6659 - accuracy: 0.5869 - val_loss: 0.6693 - val_accuracy: 0.5815 - 1s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "399/399 - 1s - loss: 0.6620 - accuracy: 0.5914 - val_loss: 0.6660 - val_accuracy: 0.5885 - 1s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "399/399 - 1s - loss: 0.6583 - accuracy: 0.5985 - val_loss: 0.6634 - val_accuracy: 0.5941 - 1s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "399/399 - 1s - loss: 0.6553 - accuracy: 0.6021 - val_loss: 0.6619 - val_accuracy: 0.5957 - 1s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "399/399 - 1s - loss: 0.6518 - accuracy: 0.6068 - val_loss: 0.6601 - val_accuracy: 0.5968 - 1s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "399/399 - 1s - loss: 0.6481 - accuracy: 0.6124 - val_loss: 0.6573 - val_accuracy: 0.6010 - 1s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "399/399 - 1s - loss: 0.6468 - accuracy: 0.6132 - val_loss: 0.6551 - val_accuracy: 0.6044 - 1s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "399/399 - 1s - loss: 0.6418 - accuracy: 0.6179 - val_loss: 0.6528 - val_accuracy: 0.6068 - 1s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "399/399 - 1s - loss: 0.6396 - accuracy: 0.6231 - val_loss: 0.6502 - val_accuracy: 0.6111 - 1s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "399/399 - 1s - loss: 0.6391 - accuracy: 0.6233 - val_loss: 0.6482 - val_accuracy: 0.6124 - 1s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "399/399 - 1s - loss: 0.6346 - accuracy: 0.6267 - val_loss: 0.6477 - val_accuracy: 0.6146 - 1s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "399/399 - 1s - loss: 0.6332 - accuracy: 0.6301 - val_loss: 0.6453 - val_accuracy: 0.6176 - 1s/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "399/399 - 1s - loss: 0.6297 - accuracy: 0.6352 - val_loss: 0.6429 - val_accuracy: 0.6195 - 1s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "399/399 - 1s - loss: 0.6281 - accuracy: 0.6352 - val_loss: 0.6420 - val_accuracy: 0.6212 - 1s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "399/399 - 1s - loss: 0.6256 - accuracy: 0.6366 - val_loss: 0.6398 - val_accuracy: 0.6238 - 1s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "399/399 - 1s - loss: 0.6239 - accuracy: 0.6390 - val_loss: 0.6379 - val_accuracy: 0.6263 - 1s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "399/399 - 1s - loss: 0.6219 - accuracy: 0.6430 - val_loss: 0.6367 - val_accuracy: 0.6277 - 1s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "399/399 - 1s - loss: 0.6203 - accuracy: 0.6428 - val_loss: 0.6356 - val_accuracy: 0.6254 - 1s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "399/399 - 1s - loss: 0.6192 - accuracy: 0.6449 - val_loss: 0.6345 - val_accuracy: 0.6292 - 1s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "399/399 - 1s - loss: 0.6167 - accuracy: 0.6476 - val_loss: 0.6329 - val_accuracy: 0.6304 - 1s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "399/399 - 1s - loss: 0.6143 - accuracy: 0.6499 - val_loss: 0.6322 - val_accuracy: 0.6311 - 1s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "399/399 - 1s - loss: 0.6135 - accuracy: 0.6516 - val_loss: 0.6310 - val_accuracy: 0.6345 - 1s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "399/399 - 1s - loss: 0.6121 - accuracy: 0.6517 - val_loss: 0.6288 - val_accuracy: 0.6354 - 1s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "399/399 - 1s - loss: 0.6109 - accuracy: 0.6539 - val_loss: 0.6278 - val_accuracy: 0.6382 - 1s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "399/399 - 1s - loss: 0.6092 - accuracy: 0.6565 - val_loss: 0.6279 - val_accuracy: 0.6357 - 1s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "399/399 - 1s - loss: 0.6065 - accuracy: 0.6577 - val_loss: 0.6262 - val_accuracy: 0.6364 - 1s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "399/399 - 1s - loss: 0.6074 - accuracy: 0.6595 - val_loss: 0.6268 - val_accuracy: 0.6390 - 1s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "399/399 - 1s - loss: 0.6058 - accuracy: 0.6572 - val_loss: 0.6249 - val_accuracy: 0.6417 - 1s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "399/399 - 1s - loss: 0.6047 - accuracy: 0.6594 - val_loss: 0.6249 - val_accuracy: 0.6373 - 1s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "399/399 - 1s - loss: 0.6018 - accuracy: 0.6632 - val_loss: 0.6231 - val_accuracy: 0.6410 - 1s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "399/399 - 1s - loss: 0.6009 - accuracy: 0.6635 - val_loss: 0.6233 - val_accuracy: 0.6405 - 1s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "399/399 - 1s - loss: 0.5999 - accuracy: 0.6636 - val_loss: 0.6222 - val_accuracy: 0.6407 - 1s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "399/399 - 1s - loss: 0.5979 - accuracy: 0.6672 - val_loss: 0.6201 - val_accuracy: 0.6435 - 1s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "399/399 - 1s - loss: 0.5969 - accuracy: 0.6674 - val_loss: 0.6218 - val_accuracy: 0.6439 - 1s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "399/399 - 1s - loss: 0.5975 - accuracy: 0.6662 - val_loss: 0.6191 - val_accuracy: 0.6470 - 1s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "399/399 - 1s - loss: 0.5950 - accuracy: 0.6686 - val_loss: 0.6166 - val_accuracy: 0.6469 - 1s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "399/399 - 1s - loss: 0.5949 - accuracy: 0.6691 - val_loss: 0.6185 - val_accuracy: 0.6464 - 1s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "399/399 - 1s - loss: 0.5922 - accuracy: 0.6705 - val_loss: 0.6174 - val_accuracy: 0.6473 - 1s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "399/399 - 1s - loss: 0.5916 - accuracy: 0.6721 - val_loss: 0.6170 - val_accuracy: 0.6460 - 1s/epoch - 3ms/step\n",
      "\n",
      "Training for Fold 2 ...\n",
      "Epoch 1/100\n",
      "399/399 - 2s - loss: 0.6882 - accuracy: 0.5418 - val_loss: 0.6842 - val_accuracy: 0.5498 - 2s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "399/399 - 1s - loss: 0.6822 - accuracy: 0.5558 - val_loss: 0.6818 - val_accuracy: 0.5550 - 1s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "399/399 - 1s - loss: 0.6793 - accuracy: 0.5632 - val_loss: 0.6788 - val_accuracy: 0.5589 - 1s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "399/399 - 1s - loss: 0.6761 - accuracy: 0.5681 - val_loss: 0.6775 - val_accuracy: 0.5642 - 1s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "399/399 - 1s - loss: 0.6730 - accuracy: 0.5737 - val_loss: 0.6745 - val_accuracy: 0.5698 - 1s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "399/399 - 1s - loss: 0.6694 - accuracy: 0.5800 - val_loss: 0.6716 - val_accuracy: 0.5775 - 1s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "399/399 - 1s - loss: 0.6654 - accuracy: 0.5856 - val_loss: 0.6678 - val_accuracy: 0.5831 - 1s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "399/399 - 1s - loss: 0.6622 - accuracy: 0.5910 - val_loss: 0.6657 - val_accuracy: 0.5864 - 1s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "399/399 - 1s - loss: 0.6583 - accuracy: 0.5994 - val_loss: 0.6630 - val_accuracy: 0.5890 - 1s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "399/399 - 1s - loss: 0.6544 - accuracy: 0.6051 - val_loss: 0.6614 - val_accuracy: 0.5935 - 1s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "399/399 - 1s - loss: 0.6522 - accuracy: 0.6071 - val_loss: 0.6593 - val_accuracy: 0.5955 - 1s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "399/399 - 1s - loss: 0.6494 - accuracy: 0.6071 - val_loss: 0.6574 - val_accuracy: 0.5979 - 1s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "399/399 - 1s - loss: 0.6463 - accuracy: 0.6129 - val_loss: 0.6529 - val_accuracy: 0.6031 - 1s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "399/399 - 1s - loss: 0.6446 - accuracy: 0.6161 - val_loss: 0.6527 - val_accuracy: 0.6028 - 1s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "399/399 - 1s - loss: 0.6406 - accuracy: 0.6212 - val_loss: 0.6488 - val_accuracy: 0.6072 - 1s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "399/399 - 1s - loss: 0.6377 - accuracy: 0.6240 - val_loss: 0.6465 - val_accuracy: 0.6120 - 1s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "399/399 - 1s - loss: 0.6359 - accuracy: 0.6263 - val_loss: 0.6475 - val_accuracy: 0.6111 - 1s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "399/399 - 1s - loss: 0.6338 - accuracy: 0.6266 - val_loss: 0.6442 - val_accuracy: 0.6147 - 1s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "399/399 - 1s - loss: 0.6310 - accuracy: 0.6328 - val_loss: 0.6414 - val_accuracy: 0.6163 - 1s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "399/399 - 1s - loss: 0.6295 - accuracy: 0.6329 - val_loss: 0.6410 - val_accuracy: 0.6202 - 1s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "399/399 - 1s - loss: 0.6268 - accuracy: 0.6365 - val_loss: 0.6393 - val_accuracy: 0.6207 - 1s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "399/399 - 1s - loss: 0.6258 - accuracy: 0.6363 - val_loss: 0.6373 - val_accuracy: 0.6214 - 1s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "399/399 - 1s - loss: 0.6229 - accuracy: 0.6398 - val_loss: 0.6388 - val_accuracy: 0.6227 - 1s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "399/399 - 1s - loss: 0.6210 - accuracy: 0.6442 - val_loss: 0.6350 - val_accuracy: 0.6269 - 1s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "399/399 - 1s - loss: 0.6171 - accuracy: 0.6462 - val_loss: 0.6339 - val_accuracy: 0.6291 - 1s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "399/399 - 1s - loss: 0.6180 - accuracy: 0.6470 - val_loss: 0.6321 - val_accuracy: 0.6287 - 1s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "399/399 - 1s - loss: 0.6145 - accuracy: 0.6494 - val_loss: 0.6306 - val_accuracy: 0.6322 - 1s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "399/399 - 1s - loss: 0.6133 - accuracy: 0.6498 - val_loss: 0.6290 - val_accuracy: 0.6335 - 1s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "399/399 - 1s - loss: 0.6112 - accuracy: 0.6533 - val_loss: 0.6283 - val_accuracy: 0.6336 - 1s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "399/399 - 1s - loss: 0.6102 - accuracy: 0.6536 - val_loss: 0.6272 - val_accuracy: 0.6358 - 1s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "399/399 - 1s - loss: 0.6072 - accuracy: 0.6574 - val_loss: 0.6283 - val_accuracy: 0.6335 - 1s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "399/399 - 1s - loss: 0.6067 - accuracy: 0.6570 - val_loss: 0.6257 - val_accuracy: 0.6379 - 1s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "399/399 - 1s - loss: 0.6050 - accuracy: 0.6601 - val_loss: 0.6245 - val_accuracy: 0.6391 - 1s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "399/399 - 1s - loss: 0.6038 - accuracy: 0.6599 - val_loss: 0.6243 - val_accuracy: 0.6388 - 1s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "399/399 - 1s - loss: 0.6024 - accuracy: 0.6634 - val_loss: 0.6230 - val_accuracy: 0.6401 - 1s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "399/399 - 1s - loss: 0.6007 - accuracy: 0.6624 - val_loss: 0.6229 - val_accuracy: 0.6392 - 1s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "399/399 - 1s - loss: 0.6006 - accuracy: 0.6640 - val_loss: 0.6208 - val_accuracy: 0.6420 - 1s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "399/399 - 1s - loss: 0.6000 - accuracy: 0.6655 - val_loss: 0.6206 - val_accuracy: 0.6456 - 1s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "399/399 - 1s - loss: 0.5988 - accuracy: 0.6652 - val_loss: 0.6204 - val_accuracy: 0.6440 - 1s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "399/399 - 1s - loss: 0.5961 - accuracy: 0.6665 - val_loss: 0.6192 - val_accuracy: 0.6438 - 1s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "399/399 - 1s - loss: 0.5969 - accuracy: 0.6655 - val_loss: 0.6189 - val_accuracy: 0.6459 - 1s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "399/399 - 1s - loss: 0.5950 - accuracy: 0.6694 - val_loss: 0.6167 - val_accuracy: 0.6460 - 1s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "399/399 - 1s - loss: 0.5954 - accuracy: 0.6669 - val_loss: 0.6153 - val_accuracy: 0.6484 - 1s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "399/399 - 1s - loss: 0.5941 - accuracy: 0.6673 - val_loss: 0.6164 - val_accuracy: 0.6485 - 1s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "399/399 - 1s - loss: 0.5921 - accuracy: 0.6724 - val_loss: 0.6176 - val_accuracy: 0.6455 - 1s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "399/399 - 1s - loss: 0.5913 - accuracy: 0.6720 - val_loss: 0.6159 - val_accuracy: 0.6499 - 1s/epoch - 3ms/step\n",
      "\n",
      "Training for Fold 3 ...\n",
      "Epoch 1/100\n",
      "399/399 - 2s - loss: 0.6889 - accuracy: 0.5401 - val_loss: 0.6839 - val_accuracy: 0.5486 - 2s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "399/399 - 1s - loss: 0.6830 - accuracy: 0.5531 - val_loss: 0.6833 - val_accuracy: 0.5509 - 1s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "399/399 - 1s - loss: 0.6799 - accuracy: 0.5594 - val_loss: 0.6795 - val_accuracy: 0.5572 - 1s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "399/399 - 1s - loss: 0.6773 - accuracy: 0.5620 - val_loss: 0.6780 - val_accuracy: 0.5615 - 1s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "399/399 - 1s - loss: 0.6744 - accuracy: 0.5691 - val_loss: 0.6760 - val_accuracy: 0.5670 - 1s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "399/399 - 1s - loss: 0.6710 - accuracy: 0.5735 - val_loss: 0.6732 - val_accuracy: 0.5731 - 1s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "399/399 - 1s - loss: 0.6679 - accuracy: 0.5816 - val_loss: 0.6700 - val_accuracy: 0.5780 - 1s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "399/399 - 1s - loss: 0.6644 - accuracy: 0.5858 - val_loss: 0.6677 - val_accuracy: 0.5813 - 1s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "399/399 - 1s - loss: 0.6615 - accuracy: 0.5892 - val_loss: 0.6666 - val_accuracy: 0.5826 - 1s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "399/399 - 1s - loss: 0.6590 - accuracy: 0.5951 - val_loss: 0.6633 - val_accuracy: 0.5897 - 1s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "399/399 - 1s - loss: 0.6554 - accuracy: 0.5985 - val_loss: 0.6622 - val_accuracy: 0.5902 - 1s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "399/399 - 1s - loss: 0.6530 - accuracy: 0.6037 - val_loss: 0.6596 - val_accuracy: 0.5983 - 1s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "399/399 - 1s - loss: 0.6497 - accuracy: 0.6072 - val_loss: 0.6579 - val_accuracy: 0.5952 - 1s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "399/399 - 1s - loss: 0.6471 - accuracy: 0.6097 - val_loss: 0.6554 - val_accuracy: 0.6009 - 1s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "399/399 - 1s - loss: 0.6437 - accuracy: 0.6147 - val_loss: 0.6527 - val_accuracy: 0.6046 - 1s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "399/399 - 1s - loss: 0.6414 - accuracy: 0.6179 - val_loss: 0.6515 - val_accuracy: 0.6055 - 1s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "399/399 - 1s - loss: 0.6382 - accuracy: 0.6217 - val_loss: 0.6496 - val_accuracy: 0.6095 - 1s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "399/399 - 1s - loss: 0.6372 - accuracy: 0.6213 - val_loss: 0.6491 - val_accuracy: 0.6117 - 1s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "399/399 - 1s - loss: 0.6339 - accuracy: 0.6252 - val_loss: 0.6453 - val_accuracy: 0.6138 - 1s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "399/399 - 1s - loss: 0.6319 - accuracy: 0.6280 - val_loss: 0.6454 - val_accuracy: 0.6140 - 1s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "399/399 - 1s - loss: 0.6291 - accuracy: 0.6311 - val_loss: 0.6437 - val_accuracy: 0.6197 - 1s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "399/399 - 1s - loss: 0.6270 - accuracy: 0.6323 - val_loss: 0.6410 - val_accuracy: 0.6198 - 1s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "399/399 - 1s - loss: 0.6252 - accuracy: 0.6352 - val_loss: 0.6404 - val_accuracy: 0.6216 - 1s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "399/399 - 1s - loss: 0.6231 - accuracy: 0.6370 - val_loss: 0.6407 - val_accuracy: 0.6203 - 1s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "399/399 - 1s - loss: 0.6209 - accuracy: 0.6414 - val_loss: 0.6366 - val_accuracy: 0.6251 - 1s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "399/399 - 1s - loss: 0.6203 - accuracy: 0.6399 - val_loss: 0.6364 - val_accuracy: 0.6253 - 1s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "399/399 - 1s - loss: 0.6173 - accuracy: 0.6442 - val_loss: 0.6351 - val_accuracy: 0.6273 - 1s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "399/399 - 1s - loss: 0.6158 - accuracy: 0.6467 - val_loss: 0.6347 - val_accuracy: 0.6281 - 1s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "399/399 - 1s - loss: 0.6150 - accuracy: 0.6461 - val_loss: 0.6331 - val_accuracy: 0.6311 - 1s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "399/399 - 1s - loss: 0.6132 - accuracy: 0.6488 - val_loss: 0.6320 - val_accuracy: 0.6300 - 1s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "399/399 - 1s - loss: 0.6125 - accuracy: 0.6492 - val_loss: 0.6319 - val_accuracy: 0.6311 - 1s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "399/399 - 1s - loss: 0.6109 - accuracy: 0.6512 - val_loss: 0.6310 - val_accuracy: 0.6327 - 1s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "399/399 - 1s - loss: 0.6095 - accuracy: 0.6508 - val_loss: 0.6292 - val_accuracy: 0.6348 - 1s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "399/399 - 1s - loss: 0.6080 - accuracy: 0.6533 - val_loss: 0.6273 - val_accuracy: 0.6366 - 1s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "399/399 - 1s - loss: 0.6057 - accuracy: 0.6558 - val_loss: 0.6282 - val_accuracy: 0.6353 - 1s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "399/399 - 1s - loss: 0.6052 - accuracy: 0.6575 - val_loss: 0.6266 - val_accuracy: 0.6362 - 1s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "399/399 - 1s - loss: 0.6034 - accuracy: 0.6565 - val_loss: 0.6265 - val_accuracy: 0.6351 - 1s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "399/399 - 1s - loss: 0.6018 - accuracy: 0.6597 - val_loss: 0.6250 - val_accuracy: 0.6398 - 1s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "399/399 - 1s - loss: 0.6011 - accuracy: 0.6610 - val_loss: 0.6237 - val_accuracy: 0.6404 - 1s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "399/399 - 1s - loss: 0.6001 - accuracy: 0.6625 - val_loss: 0.6235 - val_accuracy: 0.6410 - 1s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "399/399 - 1s - loss: 0.5978 - accuracy: 0.6640 - val_loss: 0.6236 - val_accuracy: 0.6407 - 1s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "399/399 - 1s - loss: 0.5987 - accuracy: 0.6625 - val_loss: 0.6231 - val_accuracy: 0.6426 - 1s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "399/399 - 1s - loss: 0.5966 - accuracy: 0.6639 - val_loss: 0.6227 - val_accuracy: 0.6403 - 1s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "399/399 - 1s - loss: 0.5960 - accuracy: 0.6655 - val_loss: 0.6224 - val_accuracy: 0.6430 - 1s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "399/399 - 1s - loss: 0.5948 - accuracy: 0.6679 - val_loss: 0.6209 - val_accuracy: 0.6450 - 1s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "399/399 - 1s - loss: 0.5934 - accuracy: 0.6696 - val_loss: 0.6216 - val_accuracy: 0.6405 - 1s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "399/399 - 1s - loss: 0.5924 - accuracy: 0.6693 - val_loss: 0.6196 - val_accuracy: 0.6446 - 1s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "399/399 - 1s - loss: 0.5925 - accuracy: 0.6704 - val_loss: 0.6196 - val_accuracy: 0.6437 - 1s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "399/399 - 1s - loss: 0.5914 - accuracy: 0.6702 - val_loss: 0.6189 - val_accuracy: 0.6454 - 1s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "399/399 - 1s - loss: 0.5915 - accuracy: 0.6709 - val_loss: 0.6176 - val_accuracy: 0.6452 - 1s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "399/399 - 1s - loss: 0.5898 - accuracy: 0.6723 - val_loss: 0.6182 - val_accuracy: 0.6456 - 1s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "399/399 - 1s - loss: 0.5886 - accuracy: 0.6738 - val_loss: 0.6171 - val_accuracy: 0.6466 - 1s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "399/399 - 2s - loss: 0.5895 - accuracy: 0.6730 - val_loss: 0.6168 - val_accuracy: 0.6487 - 2s/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "399/399 - 2s - loss: 0.5877 - accuracy: 0.6742 - val_loss: 0.6153 - val_accuracy: 0.6484 - 2s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "399/399 - 2s - loss: 0.5880 - accuracy: 0.6742 - val_loss: 0.6158 - val_accuracy: 0.6461 - 2s/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "399/399 - 2s - loss: 0.5866 - accuracy: 0.6749 - val_loss: 0.6162 - val_accuracy: 0.6479 - 2s/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "399/399 - 2s - loss: 0.5844 - accuracy: 0.6764 - val_loss: 0.6151 - val_accuracy: 0.6485 - 2s/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "399/399 - 2s - loss: 0.5850 - accuracy: 0.6751 - val_loss: 0.6140 - val_accuracy: 0.6517 - 2s/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "399/399 - 2s - loss: 0.5845 - accuracy: 0.6770 - val_loss: 0.6146 - val_accuracy: 0.6507 - 2s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "399/399 - 2s - loss: 0.5835 - accuracy: 0.6778 - val_loss: 0.6140 - val_accuracy: 0.6487 - 2s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "399/399 - 2s - loss: 0.5826 - accuracy: 0.6790 - val_loss: 0.6126 - val_accuracy: 0.6510 - 2s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "399/399 - 2s - loss: 0.5813 - accuracy: 0.6796 - val_loss: 0.6122 - val_accuracy: 0.6518 - 2s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "399/399 - 2s - loss: 0.5804 - accuracy: 0.6807 - val_loss: 0.6139 - val_accuracy: 0.6517 - 2s/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "399/399 - 2s - loss: 0.5814 - accuracy: 0.6799 - val_loss: 0.6118 - val_accuracy: 0.6546 - 2s/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "399/399 - 1s - loss: 0.5804 - accuracy: 0.6805 - val_loss: 0.6118 - val_accuracy: 0.6510 - 1s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "399/399 - 1s - loss: 0.5799 - accuracy: 0.6812 - val_loss: 0.6115 - val_accuracy: 0.6526 - 1s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "399/399 - 1s - loss: 0.5786 - accuracy: 0.6817 - val_loss: 0.6118 - val_accuracy: 0.6491 - 1s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "399/399 - 1s - loss: 0.5787 - accuracy: 0.6820 - val_loss: 0.6118 - val_accuracy: 0.6524 - 1s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "399/399 - 1s - loss: 0.5772 - accuracy: 0.6850 - val_loss: 0.6113 - val_accuracy: 0.6505 - 1s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "399/399 - 1s - loss: 0.5774 - accuracy: 0.6841 - val_loss: 0.6105 - val_accuracy: 0.6524 - 1s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "399/399 - 1s - loss: 0.5771 - accuracy: 0.6836 - val_loss: 0.6103 - val_accuracy: 0.6522 - 1s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "399/399 - 1s - loss: 0.5755 - accuracy: 0.6834 - val_loss: 0.6100 - val_accuracy: 0.6542 - 1s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "399/399 - 1s - loss: 0.5731 - accuracy: 0.6855 - val_loss: 0.6093 - val_accuracy: 0.6565 - 1s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "399/399 - 1s - loss: 0.5742 - accuracy: 0.6867 - val_loss: 0.6104 - val_accuracy: 0.6518 - 1s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "399/399 - 1s - loss: 0.5758 - accuracy: 0.6836 - val_loss: 0.6118 - val_accuracy: 0.6537 - 1s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "399/399 - 1s - loss: 0.5747 - accuracy: 0.6852 - val_loss: 0.6085 - val_accuracy: 0.6540 - 1s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "399/399 - 1s - loss: 0.5726 - accuracy: 0.6861 - val_loss: 0.6086 - val_accuracy: 0.6567 - 1s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "399/399 - 1s - loss: 0.5742 - accuracy: 0.6857 - val_loss: 0.6091 - val_accuracy: 0.6572 - 1s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "399/399 - 1s - loss: 0.5715 - accuracy: 0.6886 - val_loss: 0.6083 - val_accuracy: 0.6564 - 1s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "399/399 - 1s - loss: 0.5717 - accuracy: 0.6882 - val_loss: 0.6076 - val_accuracy: 0.6569 - 1s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "399/399 - 1s - loss: 0.5725 - accuracy: 0.6866 - val_loss: 0.6088 - val_accuracy: 0.6538 - 1s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "399/399 - 1s - loss: 0.5716 - accuracy: 0.6879 - val_loss: 0.6092 - val_accuracy: 0.6548 - 1s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "399/399 - 1s - loss: 0.5715 - accuracy: 0.6890 - val_loss: 0.6074 - val_accuracy: 0.6562 - 1s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "399/399 - 1s - loss: 0.5706 - accuracy: 0.6892 - val_loss: 0.6073 - val_accuracy: 0.6581 - 1s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "399/399 - 1s - loss: 0.5698 - accuracy: 0.6902 - val_loss: 0.6064 - val_accuracy: 0.6595 - 1s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "399/399 - 1s - loss: 0.5693 - accuracy: 0.6909 - val_loss: 0.6062 - val_accuracy: 0.6585 - 1s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "399/399 - 1s - loss: 0.5692 - accuracy: 0.6904 - val_loss: 0.6053 - val_accuracy: 0.6582 - 1s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "399/399 - 1s - loss: 0.5686 - accuracy: 0.6924 - val_loss: 0.6060 - val_accuracy: 0.6580 - 1s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "399/399 - 1s - loss: 0.5685 - accuracy: 0.6906 - val_loss: 0.6052 - val_accuracy: 0.6572 - 1s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "399/399 - 1s - loss: 0.5672 - accuracy: 0.6923 - val_loss: 0.6063 - val_accuracy: 0.6576 - 1s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "399/399 - 1s - loss: 0.5669 - accuracy: 0.6936 - val_loss: 0.6053 - val_accuracy: 0.6584 - 1s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "399/399 - 1s - loss: 0.5667 - accuracy: 0.6920 - val_loss: 0.6061 - val_accuracy: 0.6574 - 1s/epoch - 3ms/step\n",
      "\n",
      "Training for Fold 4 ...\n",
      "Epoch 1/100\n",
      "399/399 - 2s - loss: 0.6888 - accuracy: 0.5381 - val_loss: 0.6850 - val_accuracy: 0.5456 - 2s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "399/399 - 1s - loss: 0.6828 - accuracy: 0.5551 - val_loss: 0.6832 - val_accuracy: 0.5497 - 1s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "399/399 - 1s - loss: 0.6804 - accuracy: 0.5599 - val_loss: 0.6801 - val_accuracy: 0.5596 - 1s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "399/399 - 1s - loss: 0.6769 - accuracy: 0.5636 - val_loss: 0.6776 - val_accuracy: 0.5642 - 1s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "399/399 - 1s - loss: 0.6737 - accuracy: 0.5726 - val_loss: 0.6746 - val_accuracy: 0.5693 - 1s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "399/399 - 1s - loss: 0.6696 - accuracy: 0.5793 - val_loss: 0.6712 - val_accuracy: 0.5758 - 1s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "399/399 - 1s - loss: 0.6667 - accuracy: 0.5849 - val_loss: 0.6702 - val_accuracy: 0.5780 - 1s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "399/399 - 1s - loss: 0.6640 - accuracy: 0.5882 - val_loss: 0.6667 - val_accuracy: 0.5842 - 1s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "399/399 - 1s - loss: 0.6605 - accuracy: 0.5946 - val_loss: 0.6639 - val_accuracy: 0.5886 - 1s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "399/399 - 1s - loss: 0.6568 - accuracy: 0.5994 - val_loss: 0.6628 - val_accuracy: 0.5901 - 1s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "399/399 - 1s - loss: 0.6545 - accuracy: 0.6031 - val_loss: 0.6598 - val_accuracy: 0.5947 - 1s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "399/399 - 1s - loss: 0.6515 - accuracy: 0.6072 - val_loss: 0.6580 - val_accuracy: 0.5964 - 1s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "399/399 - 1s - loss: 0.6472 - accuracy: 0.6110 - val_loss: 0.6547 - val_accuracy: 0.6022 - 1s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "399/399 - 1s - loss: 0.6439 - accuracy: 0.6160 - val_loss: 0.6531 - val_accuracy: 0.6029 - 1s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "399/399 - 1s - loss: 0.6416 - accuracy: 0.6176 - val_loss: 0.6508 - val_accuracy: 0.6086 - 1s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "399/399 - 1s - loss: 0.6393 - accuracy: 0.6204 - val_loss: 0.6482 - val_accuracy: 0.6098 - 1s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "399/399 - 1s - loss: 0.6373 - accuracy: 0.6220 - val_loss: 0.6471 - val_accuracy: 0.6096 - 1s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "399/399 - 1s - loss: 0.6358 - accuracy: 0.6258 - val_loss: 0.6455 - val_accuracy: 0.6140 - 1s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "399/399 - 1s - loss: 0.6320 - accuracy: 0.6305 - val_loss: 0.6447 - val_accuracy: 0.6157 - 1s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "399/399 - 1s - loss: 0.6310 - accuracy: 0.6318 - val_loss: 0.6449 - val_accuracy: 0.6156 - 1s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "399/399 - 1s - loss: 0.6296 - accuracy: 0.6334 - val_loss: 0.6415 - val_accuracy: 0.6198 - 1s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "399/399 - 1s - loss: 0.6260 - accuracy: 0.6360 - val_loss: 0.6406 - val_accuracy: 0.6221 - 1s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "399/399 - 1s - loss: 0.6238 - accuracy: 0.6381 - val_loss: 0.6401 - val_accuracy: 0.6224 - 1s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "399/399 - 1s - loss: 0.6215 - accuracy: 0.6399 - val_loss: 0.6381 - val_accuracy: 0.6211 - 1s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "399/399 - 1s - loss: 0.6214 - accuracy: 0.6415 - val_loss: 0.6371 - val_accuracy: 0.6263 - 1s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "399/399 - 1s - loss: 0.6175 - accuracy: 0.6437 - val_loss: 0.6344 - val_accuracy: 0.6276 - 1s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "399/399 - 1s - loss: 0.6180 - accuracy: 0.6450 - val_loss: 0.6343 - val_accuracy: 0.6283 - 1s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "399/399 - 1s - loss: 0.6160 - accuracy: 0.6456 - val_loss: 0.6333 - val_accuracy: 0.6289 - 1s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "399/399 - 1s - loss: 0.6141 - accuracy: 0.6481 - val_loss: 0.6310 - val_accuracy: 0.6308 - 1s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "399/399 - 1s - loss: 0.6126 - accuracy: 0.6502 - val_loss: 0.6305 - val_accuracy: 0.6313 - 1s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "399/399 - 1s - loss: 0.6119 - accuracy: 0.6489 - val_loss: 0.6297 - val_accuracy: 0.6321 - 1s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "399/399 - 1s - loss: 0.6098 - accuracy: 0.6527 - val_loss: 0.6282 - val_accuracy: 0.6337 - 1s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "399/399 - 1s - loss: 0.6106 - accuracy: 0.6517 - val_loss: 0.6275 - val_accuracy: 0.6345 - 1s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "399/399 - 1s - loss: 0.6075 - accuracy: 0.6550 - val_loss: 0.6256 - val_accuracy: 0.6362 - 1s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "399/399 - 1s - loss: 0.6054 - accuracy: 0.6559 - val_loss: 0.6255 - val_accuracy: 0.6390 - 1s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "399/399 - 1s - loss: 0.6039 - accuracy: 0.6600 - val_loss: 0.6246 - val_accuracy: 0.6356 - 1s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "399/399 - 1s - loss: 0.6030 - accuracy: 0.6573 - val_loss: 0.6235 - val_accuracy: 0.6377 - 1s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "399/399 - 1s - loss: 0.6035 - accuracy: 0.6576 - val_loss: 0.6238 - val_accuracy: 0.6390 - 1s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "399/399 - 1s - loss: 0.6006 - accuracy: 0.6616 - val_loss: 0.6239 - val_accuracy: 0.6375 - 1s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "399/399 - 1s - loss: 0.6002 - accuracy: 0.6610 - val_loss: 0.6221 - val_accuracy: 0.6403 - 1s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "399/399 - 1s - loss: 0.6004 - accuracy: 0.6607 - val_loss: 0.6218 - val_accuracy: 0.6393 - 1s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "399/399 - 1s - loss: 0.5975 - accuracy: 0.6633 - val_loss: 0.6214 - val_accuracy: 0.6415 - 1s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "399/399 - 1s - loss: 0.5968 - accuracy: 0.6657 - val_loss: 0.6220 - val_accuracy: 0.6409 - 1s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "399/399 - 1s - loss: 0.5941 - accuracy: 0.6668 - val_loss: 0.6205 - val_accuracy: 0.6412 - 1s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "399/399 - 1s - loss: 0.5942 - accuracy: 0.6675 - val_loss: 0.6188 - val_accuracy: 0.6434 - 1s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "399/399 - 1s - loss: 0.5954 - accuracy: 0.6659 - val_loss: 0.6204 - val_accuracy: 0.6432 - 1s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "399/399 - 1s - loss: 0.5919 - accuracy: 0.6672 - val_loss: 0.6198 - val_accuracy: 0.6429 - 1s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "399/399 - 1s - loss: 0.5917 - accuracy: 0.6690 - val_loss: 0.6178 - val_accuracy: 0.6465 - 1s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "399/399 - 1s - loss: 0.5914 - accuracy: 0.6699 - val_loss: 0.6185 - val_accuracy: 0.6444 - 1s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "399/399 - 1s - loss: 0.5910 - accuracy: 0.6690 - val_loss: 0.6177 - val_accuracy: 0.6448 - 1s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "399/399 - 1s - loss: 0.5880 - accuracy: 0.6716 - val_loss: 0.6157 - val_accuracy: 0.6454 - 1s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "399/399 - 1s - loss: 0.5893 - accuracy: 0.6710 - val_loss: 0.6172 - val_accuracy: 0.6456 - 1s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "399/399 - 1s - loss: 0.5880 - accuracy: 0.6728 - val_loss: 0.6155 - val_accuracy: 0.6473 - 1s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "399/399 - 1s - loss: 0.5889 - accuracy: 0.6695 - val_loss: 0.6150 - val_accuracy: 0.6476 - 1s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "399/399 - 1s - loss: 0.5878 - accuracy: 0.6726 - val_loss: 0.6165 - val_accuracy: 0.6442 - 1s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "399/399 - 1s - loss: 0.5858 - accuracy: 0.6742 - val_loss: 0.6143 - val_accuracy: 0.6475 - 1s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "399/399 - 1s - loss: 0.5854 - accuracy: 0.6767 - val_loss: 0.6140 - val_accuracy: 0.6479 - 1s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "399/399 - 1s - loss: 0.5842 - accuracy: 0.6757 - val_loss: 0.6146 - val_accuracy: 0.6486 - 1s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "399/399 - 1s - loss: 0.5851 - accuracy: 0.6752 - val_loss: 0.6127 - val_accuracy: 0.6503 - 1s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "399/399 - 1s - loss: 0.5842 - accuracy: 0.6766 - val_loss: 0.6133 - val_accuracy: 0.6493 - 1s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "399/399 - 1s - loss: 0.5836 - accuracy: 0.6761 - val_loss: 0.6132 - val_accuracy: 0.6507 - 1s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "399/399 - 1s - loss: 0.5838 - accuracy: 0.6785 - val_loss: 0.6130 - val_accuracy: 0.6490 - 1s/epoch - 3ms/step\n",
      "\n",
      "Training for Fold 5 ...\n",
      "Epoch 1/100\n",
      "399/399 - 2s - loss: 0.6884 - accuracy: 0.5407 - val_loss: 0.6849 - val_accuracy: 0.5490 - 2s/epoch - 6ms/step\n",
      "Epoch 2/100\n",
      "399/399 - 2s - loss: 0.6827 - accuracy: 0.5532 - val_loss: 0.6820 - val_accuracy: 0.5519 - 2s/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "399/399 - 2s - loss: 0.6797 - accuracy: 0.5609 - val_loss: 0.6793 - val_accuracy: 0.5619 - 2s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "399/399 - 2s - loss: 0.6764 - accuracy: 0.5688 - val_loss: 0.6768 - val_accuracy: 0.5651 - 2s/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "399/399 - 2s - loss: 0.6740 - accuracy: 0.5727 - val_loss: 0.6741 - val_accuracy: 0.5699 - 2s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "399/399 - 2s - loss: 0.6700 - accuracy: 0.5803 - val_loss: 0.6729 - val_accuracy: 0.5758 - 2s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "399/399 - 2s - loss: 0.6680 - accuracy: 0.5831 - val_loss: 0.6705 - val_accuracy: 0.5791 - 2s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "399/399 - 2s - loss: 0.6638 - accuracy: 0.5895 - val_loss: 0.6675 - val_accuracy: 0.5801 - 2s/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "399/399 - 2s - loss: 0.6612 - accuracy: 0.5951 - val_loss: 0.6661 - val_accuracy: 0.5845 - 2s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "399/399 - 2s - loss: 0.6564 - accuracy: 0.6003 - val_loss: 0.6610 - val_accuracy: 0.5918 - 2s/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "399/399 - 2s - loss: 0.6535 - accuracy: 0.6051 - val_loss: 0.6601 - val_accuracy: 0.5955 - 2s/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "399/399 - 2s - loss: 0.6507 - accuracy: 0.6080 - val_loss: 0.6567 - val_accuracy: 0.5978 - 2s/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "399/399 - 2s - loss: 0.6484 - accuracy: 0.6108 - val_loss: 0.6557 - val_accuracy: 0.5984 - 2s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "399/399 - 2s - loss: 0.6454 - accuracy: 0.6155 - val_loss: 0.6543 - val_accuracy: 0.6023 - 2s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "399/399 - 2s - loss: 0.6419 - accuracy: 0.6178 - val_loss: 0.6508 - val_accuracy: 0.6080 - 2s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "399/399 - 2s - loss: 0.6387 - accuracy: 0.6223 - val_loss: 0.6501 - val_accuracy: 0.6077 - 2s/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "399/399 - 2s - loss: 0.6367 - accuracy: 0.6249 - val_loss: 0.6489 - val_accuracy: 0.6083 - 2s/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "399/399 - 2s - loss: 0.6336 - accuracy: 0.6282 - val_loss: 0.6458 - val_accuracy: 0.6118 - 2s/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "399/399 - 2s - loss: 0.6312 - accuracy: 0.6316 - val_loss: 0.6449 - val_accuracy: 0.6131 - 2s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "399/399 - 2s - loss: 0.6313 - accuracy: 0.6320 - val_loss: 0.6434 - val_accuracy: 0.6151 - 2s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "399/399 - 2s - loss: 0.6269 - accuracy: 0.6372 - val_loss: 0.6417 - val_accuracy: 0.6189 - 2s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "399/399 - 2s - loss: 0.6260 - accuracy: 0.6373 - val_loss: 0.6389 - val_accuracy: 0.6212 - 2s/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "399/399 - 2s - loss: 0.6231 - accuracy: 0.6400 - val_loss: 0.6387 - val_accuracy: 0.6226 - 2s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "399/399 - 2s - loss: 0.6225 - accuracy: 0.6394 - val_loss: 0.6391 - val_accuracy: 0.6229 - 2s/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "399/399 - 2s - loss: 0.6197 - accuracy: 0.6420 - val_loss: 0.6346 - val_accuracy: 0.6261 - 2s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "399/399 - 2s - loss: 0.6188 - accuracy: 0.6447 - val_loss: 0.6348 - val_accuracy: 0.6275 - 2s/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "399/399 - 2s - loss: 0.6161 - accuracy: 0.6467 - val_loss: 0.6348 - val_accuracy: 0.6272 - 2s/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "399/399 - 2s - loss: 0.6162 - accuracy: 0.6469 - val_loss: 0.6325 - val_accuracy: 0.6290 - 2s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "399/399 - 2s - loss: 0.6129 - accuracy: 0.6515 - val_loss: 0.6313 - val_accuracy: 0.6317 - 2s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "399/399 - 2s - loss: 0.6125 - accuracy: 0.6503 - val_loss: 0.6302 - val_accuracy: 0.6339 - 2s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "399/399 - 2s - loss: 0.6094 - accuracy: 0.6555 - val_loss: 0.6290 - val_accuracy: 0.6328 - 2s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "399/399 - 2s - loss: 0.6091 - accuracy: 0.6542 - val_loss: 0.6282 - val_accuracy: 0.6343 - 2s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "399/399 - 2s - loss: 0.6080 - accuracy: 0.6549 - val_loss: 0.6271 - val_accuracy: 0.6365 - 2s/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "399/399 - 2s - loss: 0.6056 - accuracy: 0.6576 - val_loss: 0.6257 - val_accuracy: 0.6374 - 2s/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "399/399 - 2s - loss: 0.6042 - accuracy: 0.6579 - val_loss: 0.6262 - val_accuracy: 0.6374 - 2s/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "399/399 - 2s - loss: 0.6034 - accuracy: 0.6598 - val_loss: 0.6244 - val_accuracy: 0.6383 - 2s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "399/399 - 2s - loss: 0.6022 - accuracy: 0.6614 - val_loss: 0.6254 - val_accuracy: 0.6360 - 2s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "399/399 - 2s - loss: 0.6016 - accuracy: 0.6619 - val_loss: 0.6236 - val_accuracy: 0.6398 - 2s/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "399/399 - 2s - loss: 0.5990 - accuracy: 0.6645 - val_loss: 0.6233 - val_accuracy: 0.6391 - 2s/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "399/399 - 2s - loss: 0.5991 - accuracy: 0.6626 - val_loss: 0.6230 - val_accuracy: 0.6385 - 2s/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "399/399 - 2s - loss: 0.5976 - accuracy: 0.6653 - val_loss: 0.6221 - val_accuracy: 0.6405 - 2s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "399/399 - 2s - loss: 0.5974 - accuracy: 0.6664 - val_loss: 0.6205 - val_accuracy: 0.6405 - 2s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "399/399 - 2s - loss: 0.5956 - accuracy: 0.6663 - val_loss: 0.6201 - val_accuracy: 0.6414 - 2s/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "399/399 - 2s - loss: 0.5944 - accuracy: 0.6682 - val_loss: 0.6197 - val_accuracy: 0.6425 - 2s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "399/399 - 2s - loss: 0.5936 - accuracy: 0.6690 - val_loss: 0.6202 - val_accuracy: 0.6416 - 2s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "399/399 - 2s - loss: 0.5920 - accuracy: 0.6702 - val_loss: 0.6184 - val_accuracy: 0.6451 - 2s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "399/399 - 2s - loss: 0.5914 - accuracy: 0.6702 - val_loss: 0.6178 - val_accuracy: 0.6461 - 2s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "399/399 - 2s - loss: 0.5911 - accuracy: 0.6714 - val_loss: 0.6176 - val_accuracy: 0.6448 - 2s/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "399/399 - 3s - loss: 0.5898 - accuracy: 0.6717 - val_loss: 0.6176 - val_accuracy: 0.6432 - 3s/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "399/399 - 3s - loss: 0.5909 - accuracy: 0.6714 - val_loss: 0.6185 - val_accuracy: 0.6432 - 3s/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "399/399 - 3s - loss: 0.5892 - accuracy: 0.6741 - val_loss: 0.6173 - val_accuracy: 0.6449 - 3s/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "399/399 - 4s - loss: 0.5873 - accuracy: 0.6744 - val_loss: 0.6152 - val_accuracy: 0.6464 - 4s/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "399/399 - 3s - loss: 0.5884 - accuracy: 0.6745 - val_loss: 0.6143 - val_accuracy: 0.6463 - 3s/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "399/399 - 3s - loss: 0.5859 - accuracy: 0.6744 - val_loss: 0.6154 - val_accuracy: 0.6463 - 3s/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "399/399 - 3s - loss: 0.5860 - accuracy: 0.6763 - val_loss: 0.6145 - val_accuracy: 0.6462 - 3s/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "399/399 - 3s - loss: 0.5847 - accuracy: 0.6787 - val_loss: 0.6139 - val_accuracy: 0.6486 - 3s/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "399/399 - 3s - loss: 0.5852 - accuracy: 0.6778 - val_loss: 0.6134 - val_accuracy: 0.6481 - 3s/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "399/399 - 3s - loss: 0.5841 - accuracy: 0.6765 - val_loss: 0.6142 - val_accuracy: 0.6484 - 3s/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "399/399 - 3s - loss: 0.5822 - accuracy: 0.6795 - val_loss: 0.6127 - val_accuracy: 0.6504 - 3s/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "399/399 - 2s - loss: 0.5818 - accuracy: 0.6785 - val_loss: 0.6148 - val_accuracy: 0.6464 - 2s/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "399/399 - 2s - loss: 0.5807 - accuracy: 0.6803 - val_loss: 0.6125 - val_accuracy: 0.6486 - 2s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "399/399 - 2s - loss: 0.5811 - accuracy: 0.6803 - val_loss: 0.6115 - val_accuracy: 0.6502 - 2s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "399/399 - 2s - loss: 0.5809 - accuracy: 0.6813 - val_loss: 0.6119 - val_accuracy: 0.6490 - 2s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "399/399 - 2s - loss: 0.5794 - accuracy: 0.6817 - val_loss: 0.6114 - val_accuracy: 0.6504 - 2s/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "399/399 - 2s - loss: 0.5787 - accuracy: 0.6836 - val_loss: 0.6112 - val_accuracy: 0.6518 - 2s/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "399/399 - 2s - loss: 0.5791 - accuracy: 0.6810 - val_loss: 0.6106 - val_accuracy: 0.6513 - 2s/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "399/399 - 2s - loss: 0.5786 - accuracy: 0.6829 - val_loss: 0.6102 - val_accuracy: 0.6535 - 2s/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "399/399 - 2s - loss: 0.5791 - accuracy: 0.6833 - val_loss: 0.6108 - val_accuracy: 0.6516 - 2s/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "399/399 - 2s - loss: 0.5761 - accuracy: 0.6853 - val_loss: 0.6105 - val_accuracy: 0.6509 - 2s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "399/399 - 2s - loss: 0.5773 - accuracy: 0.6854 - val_loss: 0.6091 - val_accuracy: 0.6515 - 2s/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "399/399 - 2s - loss: 0.5766 - accuracy: 0.6853 - val_loss: 0.6083 - val_accuracy: 0.6527 - 2s/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "399/399 - 2s - loss: 0.5754 - accuracy: 0.6856 - val_loss: 0.6087 - val_accuracy: 0.6536 - 2s/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "399/399 - 2s - loss: 0.5764 - accuracy: 0.6836 - val_loss: 0.6082 - val_accuracy: 0.6548 - 2s/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "399/399 - 2s - loss: 0.5755 - accuracy: 0.6862 - val_loss: 0.6080 - val_accuracy: 0.6550 - 2s/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "399/399 - 2s - loss: 0.5743 - accuracy: 0.6876 - val_loss: 0.6093 - val_accuracy: 0.6528 - 2s/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "399/399 - 2s - loss: 0.5748 - accuracy: 0.6864 - val_loss: 0.6093 - val_accuracy: 0.6540 - 2s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "399/399 - 2s - loss: 0.5715 - accuracy: 0.6886 - val_loss: 0.6080 - val_accuracy: 0.6552 - 2s/epoch - 5ms/step\n",
      "\n",
      "------- Batch Size: 512 -------\n",
      "\n",
      "Training for Fold 1 ...\n",
      "Epoch 1/100\n",
      "200/200 - 3s - loss: 0.6888 - accuracy: 0.5397 - val_loss: 0.6855 - val_accuracy: 0.5473 - 3s/epoch - 14ms/step\n",
      "Epoch 2/100\n",
      "200/200 - 1s - loss: 0.6829 - accuracy: 0.5532 - val_loss: 0.6819 - val_accuracy: 0.5575 - 1s/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "200/200 - 1s - loss: 0.6804 - accuracy: 0.5609 - val_loss: 0.6800 - val_accuracy: 0.5615 - 1s/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "200/200 - 1s - loss: 0.6775 - accuracy: 0.5665 - val_loss: 0.6777 - val_accuracy: 0.5643 - 1s/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "200/200 - 1s - loss: 0.6741 - accuracy: 0.5726 - val_loss: 0.6753 - val_accuracy: 0.5700 - 1s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "200/200 - 1s - loss: 0.6710 - accuracy: 0.5769 - val_loss: 0.6728 - val_accuracy: 0.5731 - 1s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "200/200 - 1s - loss: 0.6679 - accuracy: 0.5826 - val_loss: 0.6710 - val_accuracy: 0.5806 - 1s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "200/200 - 1s - loss: 0.6644 - accuracy: 0.5893 - val_loss: 0.6684 - val_accuracy: 0.5848 - 1s/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "200/200 - 1s - loss: 0.6614 - accuracy: 0.5946 - val_loss: 0.6651 - val_accuracy: 0.5911 - 1s/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "200/200 - 1s - loss: 0.6573 - accuracy: 0.6030 - val_loss: 0.6635 - val_accuracy: 0.5914 - 1s/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "200/200 - 1s - loss: 0.6542 - accuracy: 0.6058 - val_loss: 0.6593 - val_accuracy: 0.5972 - 1s/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "200/200 - 1s - loss: 0.6510 - accuracy: 0.6090 - val_loss: 0.6593 - val_accuracy: 0.5970 - 1s/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "200/200 - 1s - loss: 0.6486 - accuracy: 0.6101 - val_loss: 0.6564 - val_accuracy: 0.6015 - 1s/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "200/200 - 1s - loss: 0.6457 - accuracy: 0.6143 - val_loss: 0.6541 - val_accuracy: 0.6019 - 1s/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "200/200 - 1s - loss: 0.6421 - accuracy: 0.6197 - val_loss: 0.6513 - val_accuracy: 0.6085 - 1s/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "200/200 - 1s - loss: 0.6399 - accuracy: 0.6214 - val_loss: 0.6498 - val_accuracy: 0.6106 - 1s/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "200/200 - 1s - loss: 0.6380 - accuracy: 0.6256 - val_loss: 0.6481 - val_accuracy: 0.6137 - 1s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "200/200 - 1s - loss: 0.6334 - accuracy: 0.6295 - val_loss: 0.6470 - val_accuracy: 0.6119 - 1s/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "200/200 - 1s - loss: 0.6325 - accuracy: 0.6317 - val_loss: 0.6445 - val_accuracy: 0.6149 - 1s/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "200/200 - 1s - loss: 0.6291 - accuracy: 0.6335 - val_loss: 0.6414 - val_accuracy: 0.6189 - 1s/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "200/200 - 1s - loss: 0.6264 - accuracy: 0.6392 - val_loss: 0.6401 - val_accuracy: 0.6199 - 1s/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "200/200 - 1s - loss: 0.6259 - accuracy: 0.6389 - val_loss: 0.6393 - val_accuracy: 0.6225 - 1s/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "200/200 - 1s - loss: 0.6240 - accuracy: 0.6397 - val_loss: 0.6393 - val_accuracy: 0.6229 - 1s/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "200/200 - 1s - loss: 0.6213 - accuracy: 0.6451 - val_loss: 0.6349 - val_accuracy: 0.6284 - 1s/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "200/200 - 1s - loss: 0.6200 - accuracy: 0.6453 - val_loss: 0.6355 - val_accuracy: 0.6267 - 1s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "200/200 - 1s - loss: 0.6179 - accuracy: 0.6475 - val_loss: 0.6329 - val_accuracy: 0.6261 - 1s/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "200/200 - 1s - loss: 0.6152 - accuracy: 0.6488 - val_loss: 0.6320 - val_accuracy: 0.6283 - 1s/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "200/200 - 1s - loss: 0.6152 - accuracy: 0.6528 - val_loss: 0.6317 - val_accuracy: 0.6295 - 1s/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "200/200 - 1s - loss: 0.6136 - accuracy: 0.6516 - val_loss: 0.6300 - val_accuracy: 0.6315 - 1s/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "200/200 - 1s - loss: 0.6104 - accuracy: 0.6556 - val_loss: 0.6302 - val_accuracy: 0.6310 - 1s/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "200/200 - 1s - loss: 0.6096 - accuracy: 0.6553 - val_loss: 0.6292 - val_accuracy: 0.6326 - 1s/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "200/200 - 1s - loss: 0.6090 - accuracy: 0.6565 - val_loss: 0.6280 - val_accuracy: 0.6333 - 1s/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "200/200 - 1s - loss: 0.6059 - accuracy: 0.6601 - val_loss: 0.6254 - val_accuracy: 0.6363 - 1s/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "200/200 - 1s - loss: 0.6057 - accuracy: 0.6597 - val_loss: 0.6260 - val_accuracy: 0.6372 - 1s/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "200/200 - 1s - loss: 0.6047 - accuracy: 0.6621 - val_loss: 0.6250 - val_accuracy: 0.6391 - 1s/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "200/200 - 1s - loss: 0.6032 - accuracy: 0.6634 - val_loss: 0.6245 - val_accuracy: 0.6388 - 1s/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "200/200 - 1s - loss: 0.6014 - accuracy: 0.6641 - val_loss: 0.6248 - val_accuracy: 0.6388 - 1s/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "200/200 - 1s - loss: 0.6012 - accuracy: 0.6638 - val_loss: 0.6251 - val_accuracy: 0.6393 - 1s/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "200/200 - 1s - loss: 0.5997 - accuracy: 0.6666 - val_loss: 0.6219 - val_accuracy: 0.6412 - 1s/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "200/200 - 1s - loss: 0.5990 - accuracy: 0.6675 - val_loss: 0.6216 - val_accuracy: 0.6440 - 1s/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "200/200 - 1s - loss: 0.5959 - accuracy: 0.6695 - val_loss: 0.6206 - val_accuracy: 0.6435 - 1s/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "200/200 - 1s - loss: 0.5965 - accuracy: 0.6688 - val_loss: 0.6206 - val_accuracy: 0.6433 - 1s/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "200/200 - 1s - loss: 0.5937 - accuracy: 0.6702 - val_loss: 0.6193 - val_accuracy: 0.6450 - 1s/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "200/200 - 1s - loss: 0.5938 - accuracy: 0.6713 - val_loss: 0.6183 - val_accuracy: 0.6462 - 1s/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "200/200 - 1s - loss: 0.5936 - accuracy: 0.6710 - val_loss: 0.6178 - val_accuracy: 0.6465 - 1s/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "200/200 - 1s - loss: 0.5932 - accuracy: 0.6711 - val_loss: 0.6169 - val_accuracy: 0.6474 - 1s/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "200/200 - 2s - loss: 0.5917 - accuracy: 0.6742 - val_loss: 0.6170 - val_accuracy: 0.6454 - 2s/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "200/200 - 1s - loss: 0.5903 - accuracy: 0.6729 - val_loss: 0.6155 - val_accuracy: 0.6495 - 1s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "200/200 - 1s - loss: 0.5896 - accuracy: 0.6771 - val_loss: 0.6157 - val_accuracy: 0.6489 - 1s/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "200/200 - 1s - loss: 0.5885 - accuracy: 0.6769 - val_loss: 0.6158 - val_accuracy: 0.6476 - 1s/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "200/200 - 2s - loss: 0.5883 - accuracy: 0.6759 - val_loss: 0.6164 - val_accuracy: 0.6476 - 2s/epoch - 8ms/step\n",
      "\n",
      "Training for Fold 2 ...\n",
      "Epoch 1/100\n",
      "200/200 - 4s - loss: 0.6886 - accuracy: 0.5399 - val_loss: 0.6844 - val_accuracy: 0.5500 - 4s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "200/200 - 2s - loss: 0.6821 - accuracy: 0.5528 - val_loss: 0.6817 - val_accuracy: 0.5558 - 2s/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "200/200 - 2s - loss: 0.6796 - accuracy: 0.5617 - val_loss: 0.6792 - val_accuracy: 0.5592 - 2s/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "200/200 - 2s - loss: 0.6766 - accuracy: 0.5675 - val_loss: 0.6782 - val_accuracy: 0.5624 - 2s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "200/200 - 1s - loss: 0.6736 - accuracy: 0.5743 - val_loss: 0.6754 - val_accuracy: 0.5699 - 1s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "200/200 - 1s - loss: 0.6704 - accuracy: 0.5790 - val_loss: 0.6727 - val_accuracy: 0.5739 - 1s/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "200/200 - 1s - loss: 0.6670 - accuracy: 0.5848 - val_loss: 0.6702 - val_accuracy: 0.5809 - 1s/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "200/200 - 1s - loss: 0.6635 - accuracy: 0.5883 - val_loss: 0.6676 - val_accuracy: 0.5837 - 1s/epoch - 6ms/step\n",
      "Epoch 9/100\n",
      "200/200 - 1s - loss: 0.6597 - accuracy: 0.5948 - val_loss: 0.6647 - val_accuracy: 0.5862 - 1s/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "200/200 - 1s - loss: 0.6576 - accuracy: 0.5996 - val_loss: 0.6640 - val_accuracy: 0.5883 - 1s/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "200/200 - 1s - loss: 0.6539 - accuracy: 0.6023 - val_loss: 0.6604 - val_accuracy: 0.5926 - 1s/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "200/200 - 1s - loss: 0.6512 - accuracy: 0.6070 - val_loss: 0.6583 - val_accuracy: 0.5970 - 1s/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "200/200 - 1s - loss: 0.6480 - accuracy: 0.6115 - val_loss: 0.6558 - val_accuracy: 0.5996 - 1s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "200/200 - 1s - loss: 0.6451 - accuracy: 0.6163 - val_loss: 0.6536 - val_accuracy: 0.6052 - 1s/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "200/200 - 1s - loss: 0.6428 - accuracy: 0.6183 - val_loss: 0.6521 - val_accuracy: 0.6068 - 1s/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "200/200 - 1s - loss: 0.6397 - accuracy: 0.6206 - val_loss: 0.6501 - val_accuracy: 0.6066 - 1s/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "200/200 - 1s - loss: 0.6382 - accuracy: 0.6230 - val_loss: 0.6490 - val_accuracy: 0.6108 - 1s/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "200/200 - 1s - loss: 0.6358 - accuracy: 0.6253 - val_loss: 0.6469 - val_accuracy: 0.6117 - 1s/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "200/200 - 1s - loss: 0.6324 - accuracy: 0.6292 - val_loss: 0.6447 - val_accuracy: 0.6147 - 1s/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "200/200 - 1s - loss: 0.6306 - accuracy: 0.6309 - val_loss: 0.6433 - val_accuracy: 0.6168 - 1s/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "200/200 - 1s - loss: 0.6287 - accuracy: 0.6342 - val_loss: 0.6424 - val_accuracy: 0.6167 - 1s/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "200/200 - 1s - loss: 0.6280 - accuracy: 0.6346 - val_loss: 0.6417 - val_accuracy: 0.6182 - 1s/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "200/200 - 1s - loss: 0.6253 - accuracy: 0.6369 - val_loss: 0.6396 - val_accuracy: 0.6206 - 1s/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "200/200 - 1s - loss: 0.6230 - accuracy: 0.6408 - val_loss: 0.6378 - val_accuracy: 0.6231 - 1s/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "200/200 - 1s - loss: 0.6208 - accuracy: 0.6410 - val_loss: 0.6378 - val_accuracy: 0.6241 - 1s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "200/200 - 1s - loss: 0.6198 - accuracy: 0.6420 - val_loss: 0.6369 - val_accuracy: 0.6225 - 1s/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "200/200 - 1s - loss: 0.6186 - accuracy: 0.6433 - val_loss: 0.6337 - val_accuracy: 0.6259 - 1s/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "200/200 - 1s - loss: 0.6163 - accuracy: 0.6481 - val_loss: 0.6338 - val_accuracy: 0.6255 - 1s/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "200/200 - 1s - loss: 0.6141 - accuracy: 0.6493 - val_loss: 0.6318 - val_accuracy: 0.6288 - 1s/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "200/200 - 1s - loss: 0.6134 - accuracy: 0.6491 - val_loss: 0.6313 - val_accuracy: 0.6286 - 1s/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "200/200 - 1s - loss: 0.6118 - accuracy: 0.6505 - val_loss: 0.6310 - val_accuracy: 0.6308 - 1s/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "200/200 - 1s - loss: 0.6105 - accuracy: 0.6534 - val_loss: 0.6295 - val_accuracy: 0.6332 - 1s/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "200/200 - 1s - loss: 0.6081 - accuracy: 0.6551 - val_loss: 0.6285 - val_accuracy: 0.6355 - 1s/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "200/200 - 1s - loss: 0.6074 - accuracy: 0.6561 - val_loss: 0.6268 - val_accuracy: 0.6334 - 1s/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "200/200 - 1s - loss: 0.6069 - accuracy: 0.6571 - val_loss: 0.6278 - val_accuracy: 0.6344 - 1s/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "200/200 - 1s - loss: 0.6049 - accuracy: 0.6584 - val_loss: 0.6254 - val_accuracy: 0.6372 - 1s/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "200/200 - 1s - loss: 0.6031 - accuracy: 0.6607 - val_loss: 0.6263 - val_accuracy: 0.6348 - 1s/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "200/200 - 1s - loss: 0.6024 - accuracy: 0.6621 - val_loss: 0.6246 - val_accuracy: 0.6398 - 1s/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "200/200 - 1s - loss: 0.6023 - accuracy: 0.6606 - val_loss: 0.6240 - val_accuracy: 0.6400 - 1s/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "200/200 - 1s - loss: 0.6003 - accuracy: 0.6632 - val_loss: 0.6233 - val_accuracy: 0.6382 - 1s/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "200/200 - 1s - loss: 0.5971 - accuracy: 0.6673 - val_loss: 0.6222 - val_accuracy: 0.6400 - 1s/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "200/200 - 1s - loss: 0.5994 - accuracy: 0.6629 - val_loss: 0.6221 - val_accuracy: 0.6404 - 1s/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "200/200 - 1s - loss: 0.5987 - accuracy: 0.6659 - val_loss: 0.6201 - val_accuracy: 0.6452 - 1s/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "200/200 - 1s - loss: 0.5961 - accuracy: 0.6677 - val_loss: 0.6219 - val_accuracy: 0.6395 - 1s/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "200/200 - 1s - loss: 0.5952 - accuracy: 0.6679 - val_loss: 0.6204 - val_accuracy: 0.6422 - 1s/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "200/200 - 1s - loss: 0.5927 - accuracy: 0.6703 - val_loss: 0.6194 - val_accuracy: 0.6443 - 1s/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "200/200 - 1s - loss: 0.5942 - accuracy: 0.6682 - val_loss: 0.6191 - val_accuracy: 0.6458 - 1s/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "200/200 - 1s - loss: 0.5921 - accuracy: 0.6705 - val_loss: 0.6187 - val_accuracy: 0.6446 - 1s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "200/200 - 1s - loss: 0.5902 - accuracy: 0.6722 - val_loss: 0.6173 - val_accuracy: 0.6460 - 1s/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "200/200 - 1s - loss: 0.5915 - accuracy: 0.6713 - val_loss: 0.6168 - val_accuracy: 0.6465 - 1s/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "200/200 - 1s - loss: 0.5909 - accuracy: 0.6710 - val_loss: 0.6174 - val_accuracy: 0.6458 - 1s/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "200/200 - 1s - loss: 0.5896 - accuracy: 0.6722 - val_loss: 0.6173 - val_accuracy: 0.6463 - 1s/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "200/200 - 1s - loss: 0.5879 - accuracy: 0.6730 - val_loss: 0.6163 - val_accuracy: 0.6480 - 1s/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "200/200 - 1s - loss: 0.5866 - accuracy: 0.6765 - val_loss: 0.6159 - val_accuracy: 0.6484 - 1s/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "200/200 - 1s - loss: 0.5865 - accuracy: 0.6762 - val_loss: 0.6154 - val_accuracy: 0.6487 - 1s/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "200/200 - 1s - loss: 0.5876 - accuracy: 0.6747 - val_loss: 0.6149 - val_accuracy: 0.6501 - 1s/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "200/200 - 1s - loss: 0.5856 - accuracy: 0.6762 - val_loss: 0.6140 - val_accuracy: 0.6518 - 1s/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "200/200 - 1s - loss: 0.5850 - accuracy: 0.6775 - val_loss: 0.6148 - val_accuracy: 0.6486 - 1s/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "200/200 - 1s - loss: 0.5843 - accuracy: 0.6781 - val_loss: 0.6143 - val_accuracy: 0.6501 - 1s/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "200/200 - 2s - loss: 0.5831 - accuracy: 0.6774 - val_loss: 0.6129 - val_accuracy: 0.6523 - 2s/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "200/200 - 1s - loss: 0.5829 - accuracy: 0.6782 - val_loss: 0.6131 - val_accuracy: 0.6520 - 1s/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "200/200 - 1s - loss: 0.5819 - accuracy: 0.6788 - val_loss: 0.6119 - val_accuracy: 0.6521 - 1s/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "200/200 - 1s - loss: 0.5810 - accuracy: 0.6811 - val_loss: 0.6125 - val_accuracy: 0.6521 - 1s/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "200/200 - 1s - loss: 0.5815 - accuracy: 0.6801 - val_loss: 0.6136 - val_accuracy: 0.6511 - 1s/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "200/200 - 1s - loss: 0.5792 - accuracy: 0.6826 - val_loss: 0.6139 - val_accuracy: 0.6516 - 1s/epoch - 6ms/step\n",
      "\n",
      "Training for Fold 3 ...\n",
      "Epoch 1/100\n",
      "200/200 - 3s - loss: 0.6893 - accuracy: 0.5404 - val_loss: 0.6845 - val_accuracy: 0.5493 - 3s/epoch - 16ms/step\n",
      "Epoch 2/100\n",
      "200/200 - 1s - loss: 0.6823 - accuracy: 0.5549 - val_loss: 0.6827 - val_accuracy: 0.5565 - 1s/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "200/200 - 1s - loss: 0.6796 - accuracy: 0.5619 - val_loss: 0.6789 - val_accuracy: 0.5630 - 1s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "200/200 - 1s - loss: 0.6766 - accuracy: 0.5688 - val_loss: 0.6769 - val_accuracy: 0.5677 - 1s/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "200/200 - 1s - loss: 0.6738 - accuracy: 0.5741 - val_loss: 0.6746 - val_accuracy: 0.5712 - 1s/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "200/200 - 1s - loss: 0.6705 - accuracy: 0.5795 - val_loss: 0.6723 - val_accuracy: 0.5768 - 1s/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "200/200 - 1s - loss: 0.6673 - accuracy: 0.5841 - val_loss: 0.6703 - val_accuracy: 0.5796 - 1s/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "200/200 - 1s - loss: 0.6643 - accuracy: 0.5897 - val_loss: 0.6673 - val_accuracy: 0.5852 - 1s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "200/200 - 1s - loss: 0.6611 - accuracy: 0.5950 - val_loss: 0.6658 - val_accuracy: 0.5858 - 1s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "200/200 - 1s - loss: 0.6580 - accuracy: 0.5988 - val_loss: 0.6632 - val_accuracy: 0.5889 - 1s/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "200/200 - 1s - loss: 0.6556 - accuracy: 0.6011 - val_loss: 0.6614 - val_accuracy: 0.5947 - 1s/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "200/200 - 1s - loss: 0.6526 - accuracy: 0.6053 - val_loss: 0.6574 - val_accuracy: 0.5985 - 1s/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "200/200 - 1s - loss: 0.6491 - accuracy: 0.6094 - val_loss: 0.6566 - val_accuracy: 0.6007 - 1s/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "200/200 - 1s - loss: 0.6472 - accuracy: 0.6125 - val_loss: 0.6536 - val_accuracy: 0.6048 - 1s/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "200/200 - 2s - loss: 0.6445 - accuracy: 0.6166 - val_loss: 0.6529 - val_accuracy: 0.6063 - 2s/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "200/200 - 1s - loss: 0.6412 - accuracy: 0.6192 - val_loss: 0.6509 - val_accuracy: 0.6073 - 1s/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "200/200 - 1s - loss: 0.6392 - accuracy: 0.6239 - val_loss: 0.6487 - val_accuracy: 0.6120 - 1s/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "200/200 - 1s - loss: 0.6372 - accuracy: 0.6237 - val_loss: 0.6463 - val_accuracy: 0.6141 - 1s/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "200/200 - 1s - loss: 0.6350 - accuracy: 0.6276 - val_loss: 0.6458 - val_accuracy: 0.6152 - 1s/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "200/200 - 1s - loss: 0.6321 - accuracy: 0.6293 - val_loss: 0.6442 - val_accuracy: 0.6175 - 1s/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "200/200 - 1s - loss: 0.6296 - accuracy: 0.6324 - val_loss: 0.6408 - val_accuracy: 0.6228 - 1s/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "200/200 - 2s - loss: 0.6283 - accuracy: 0.6349 - val_loss: 0.6400 - val_accuracy: 0.6230 - 2s/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "200/200 - 2s - loss: 0.6256 - accuracy: 0.6387 - val_loss: 0.6386 - val_accuracy: 0.6247 - 2s/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "200/200 - 1s - loss: 0.6240 - accuracy: 0.6393 - val_loss: 0.6381 - val_accuracy: 0.6257 - 1s/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "200/200 - 2s - loss: 0.6206 - accuracy: 0.6437 - val_loss: 0.6363 - val_accuracy: 0.6257 - 2s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "200/200 - 1s - loss: 0.6214 - accuracy: 0.6422 - val_loss: 0.6360 - val_accuracy: 0.6280 - 1s/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "200/200 - 1s - loss: 0.6183 - accuracy: 0.6443 - val_loss: 0.6335 - val_accuracy: 0.6326 - 1s/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "200/200 - 2s - loss: 0.6169 - accuracy: 0.6486 - val_loss: 0.6333 - val_accuracy: 0.6329 - 2s/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "200/200 - 3s - loss: 0.6154 - accuracy: 0.6474 - val_loss: 0.6313 - val_accuracy: 0.6327 - 3s/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "200/200 - 2s - loss: 0.6160 - accuracy: 0.6466 - val_loss: 0.6307 - val_accuracy: 0.6332 - 2s/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "200/200 - 1s - loss: 0.6130 - accuracy: 0.6518 - val_loss: 0.6293 - val_accuracy: 0.6357 - 1s/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "200/200 - 1s - loss: 0.6091 - accuracy: 0.6559 - val_loss: 0.6297 - val_accuracy: 0.6351 - 1s/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "200/200 - 1s - loss: 0.6102 - accuracy: 0.6542 - val_loss: 0.6301 - val_accuracy: 0.6359 - 1s/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "200/200 - 1s - loss: 0.6077 - accuracy: 0.6563 - val_loss: 0.6288 - val_accuracy: 0.6371 - 977ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "200/200 - 1s - loss: 0.6064 - accuracy: 0.6575 - val_loss: 0.6262 - val_accuracy: 0.6376 - 1s/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "200/200 - 1s - loss: 0.6052 - accuracy: 0.6599 - val_loss: 0.6249 - val_accuracy: 0.6403 - 932ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "200/200 - 1s - loss: 0.6037 - accuracy: 0.6612 - val_loss: 0.6262 - val_accuracy: 0.6386 - 893ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "200/200 - 1s - loss: 0.6035 - accuracy: 0.6621 - val_loss: 0.6256 - val_accuracy: 0.6381 - 866ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "200/200 - 1s - loss: 0.6021 - accuracy: 0.6617 - val_loss: 0.6244 - val_accuracy: 0.6419 - 873ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "200/200 - 1s - loss: 0.6018 - accuracy: 0.6621 - val_loss: 0.6223 - val_accuracy: 0.6422 - 960ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "200/200 - 1s - loss: 0.5988 - accuracy: 0.6640 - val_loss: 0.6218 - val_accuracy: 0.6445 - 1s/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "200/200 - 1s - loss: 0.5999 - accuracy: 0.6641 - val_loss: 0.6225 - val_accuracy: 0.6426 - 899ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "200/200 - 1s - loss: 0.5976 - accuracy: 0.6666 - val_loss: 0.6218 - val_accuracy: 0.6428 - 853ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "200/200 - 1s - loss: 0.5985 - accuracy: 0.6663 - val_loss: 0.6196 - val_accuracy: 0.6447 - 849ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "200/200 - 1s - loss: 0.5956 - accuracy: 0.6687 - val_loss: 0.6182 - val_accuracy: 0.6463 - 806ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "200/200 - 1s - loss: 0.5932 - accuracy: 0.6710 - val_loss: 0.6187 - val_accuracy: 0.6462 - 854ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "200/200 - 1s - loss: 0.5952 - accuracy: 0.6689 - val_loss: 0.6193 - val_accuracy: 0.6480 - 802ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "200/200 - 1s - loss: 0.5926 - accuracy: 0.6698 - val_loss: 0.6174 - val_accuracy: 0.6469 - 801ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "200/200 - 1s - loss: 0.5914 - accuracy: 0.6734 - val_loss: 0.6171 - val_accuracy: 0.6458 - 806ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "200/200 - 1s - loss: 0.5894 - accuracy: 0.6747 - val_loss: 0.6159 - val_accuracy: 0.6506 - 801ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "200/200 - 1s - loss: 0.5906 - accuracy: 0.6730 - val_loss: 0.6170 - val_accuracy: 0.6473 - 812ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "200/200 - 1s - loss: 0.5896 - accuracy: 0.6737 - val_loss: 0.6166 - val_accuracy: 0.6482 - 803ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "200/200 - 1s - loss: 0.5892 - accuracy: 0.6747 - val_loss: 0.6152 - val_accuracy: 0.6492 - 848ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "200/200 - 1s - loss: 0.5876 - accuracy: 0.6739 - val_loss: 0.6152 - val_accuracy: 0.6495 - 814ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "200/200 - 1s - loss: 0.5875 - accuracy: 0.6755 - val_loss: 0.6153 - val_accuracy: 0.6496 - 828ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "200/200 - 1s - loss: 0.5867 - accuracy: 0.6773 - val_loss: 0.6155 - val_accuracy: 0.6505 - 825ms/epoch - 4ms/step\n",
      "\n",
      "Training for Fold 4 ...\n",
      "Epoch 1/100\n",
      "200/200 - 1s - loss: 0.6903 - accuracy: 0.5362 - val_loss: 0.6854 - val_accuracy: 0.5455 - 1s/epoch - 7ms/step\n",
      "Epoch 2/100\n",
      "200/200 - 1s - loss: 0.6835 - accuracy: 0.5541 - val_loss: 0.6833 - val_accuracy: 0.5501 - 806ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "200/200 - 1s - loss: 0.6808 - accuracy: 0.5586 - val_loss: 0.6808 - val_accuracy: 0.5567 - 852ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "200/200 - 1s - loss: 0.6782 - accuracy: 0.5632 - val_loss: 0.6790 - val_accuracy: 0.5616 - 845ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "200/200 - 1s - loss: 0.6750 - accuracy: 0.5724 - val_loss: 0.6770 - val_accuracy: 0.5675 - 872ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "200/200 - 1s - loss: 0.6725 - accuracy: 0.5754 - val_loss: 0.6744 - val_accuracy: 0.5721 - 843ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "200/200 - 1s - loss: 0.6694 - accuracy: 0.5813 - val_loss: 0.6720 - val_accuracy: 0.5777 - 1s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "200/200 - 1s - loss: 0.6661 - accuracy: 0.5876 - val_loss: 0.6689 - val_accuracy: 0.5831 - 859ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "200/200 - 1s - loss: 0.6626 - accuracy: 0.5935 - val_loss: 0.6659 - val_accuracy: 0.5878 - 947ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "200/200 - 1s - loss: 0.6596 - accuracy: 0.5976 - val_loss: 0.6638 - val_accuracy: 0.5915 - 803ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "200/200 - 1s - loss: 0.6559 - accuracy: 0.6020 - val_loss: 0.6621 - val_accuracy: 0.5948 - 850ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "200/200 - 1s - loss: 0.6532 - accuracy: 0.6058 - val_loss: 0.6591 - val_accuracy: 0.5991 - 840ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "200/200 - 1s - loss: 0.6503 - accuracy: 0.6095 - val_loss: 0.6575 - val_accuracy: 0.5984 - 824ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "200/200 - 1s - loss: 0.6470 - accuracy: 0.6144 - val_loss: 0.6553 - val_accuracy: 0.6024 - 821ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "200/200 - 1s - loss: 0.6445 - accuracy: 0.6167 - val_loss: 0.6522 - val_accuracy: 0.6072 - 927ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "200/200 - 1s - loss: 0.6410 - accuracy: 0.6224 - val_loss: 0.6509 - val_accuracy: 0.6082 - 857ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "200/200 - 1s - loss: 0.6381 - accuracy: 0.6254 - val_loss: 0.6482 - val_accuracy: 0.6118 - 1s/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "200/200 - 1s - loss: 0.6358 - accuracy: 0.6286 - val_loss: 0.6462 - val_accuracy: 0.6143 - 1s/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "200/200 - 1s - loss: 0.6344 - accuracy: 0.6301 - val_loss: 0.6453 - val_accuracy: 0.6185 - 1s/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "200/200 - 1s - loss: 0.6311 - accuracy: 0.6316 - val_loss: 0.6433 - val_accuracy: 0.6180 - 1s/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "200/200 - 1s - loss: 0.6280 - accuracy: 0.6354 - val_loss: 0.6414 - val_accuracy: 0.6212 - 1s/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "200/200 - 1s - loss: 0.6264 - accuracy: 0.6380 - val_loss: 0.6400 - val_accuracy: 0.6218 - 1s/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "200/200 - 1s - loss: 0.6236 - accuracy: 0.6410 - val_loss: 0.6390 - val_accuracy: 0.6239 - 1s/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "200/200 - 1s - loss: 0.6234 - accuracy: 0.6420 - val_loss: 0.6364 - val_accuracy: 0.6258 - 1s/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "200/200 - 1s - loss: 0.6208 - accuracy: 0.6443 - val_loss: 0.6355 - val_accuracy: 0.6280 - 1s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "200/200 - 1s - loss: 0.6197 - accuracy: 0.6465 - val_loss: 0.6340 - val_accuracy: 0.6294 - 1s/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "200/200 - 1s - loss: 0.6176 - accuracy: 0.6478 - val_loss: 0.6336 - val_accuracy: 0.6306 - 1s/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "200/200 - 1s - loss: 0.6156 - accuracy: 0.6497 - val_loss: 0.6309 - val_accuracy: 0.6332 - 1s/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "200/200 - 1s - loss: 0.6146 - accuracy: 0.6495 - val_loss: 0.6308 - val_accuracy: 0.6322 - 1s/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "200/200 - 1s - loss: 0.6135 - accuracy: 0.6520 - val_loss: 0.6312 - val_accuracy: 0.6330 - 1s/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "200/200 - 1s - loss: 0.6105 - accuracy: 0.6528 - val_loss: 0.6293 - val_accuracy: 0.6353 - 1s/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "200/200 - 2s - loss: 0.6098 - accuracy: 0.6533 - val_loss: 0.6282 - val_accuracy: 0.6366 - 2s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "200/200 - 2s - loss: 0.6097 - accuracy: 0.6549 - val_loss: 0.6275 - val_accuracy: 0.6380 - 2s/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "200/200 - 2s - loss: 0.6069 - accuracy: 0.6580 - val_loss: 0.6265 - val_accuracy: 0.6373 - 2s/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "200/200 - 3s - loss: 0.6051 - accuracy: 0.6596 - val_loss: 0.6246 - val_accuracy: 0.6396 - 3s/epoch - 13ms/step\n",
      "Epoch 36/100\n",
      "200/200 - 2s - loss: 0.6051 - accuracy: 0.6590 - val_loss: 0.6252 - val_accuracy: 0.6372 - 2s/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "200/200 - 2s - loss: 0.6032 - accuracy: 0.6627 - val_loss: 0.6246 - val_accuracy: 0.6408 - 2s/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "200/200 - 2s - loss: 0.6017 - accuracy: 0.6623 - val_loss: 0.6237 - val_accuracy: 0.6413 - 2s/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "200/200 - 2s - loss: 0.6018 - accuracy: 0.6622 - val_loss: 0.6221 - val_accuracy: 0.6424 - 2s/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "200/200 - 2s - loss: 0.6010 - accuracy: 0.6638 - val_loss: 0.6224 - val_accuracy: 0.6421 - 2s/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "200/200 - 2s - loss: 0.5977 - accuracy: 0.6675 - val_loss: 0.6216 - val_accuracy: 0.6419 - 2s/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "200/200 - 2s - loss: 0.5985 - accuracy: 0.6652 - val_loss: 0.6211 - val_accuracy: 0.6415 - 2s/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "200/200 - 2s - loss: 0.5971 - accuracy: 0.6664 - val_loss: 0.6210 - val_accuracy: 0.6419 - 2s/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "200/200 - 2s - loss: 0.5966 - accuracy: 0.6672 - val_loss: 0.6202 - val_accuracy: 0.6430 - 2s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "200/200 - 1s - loss: 0.5949 - accuracy: 0.6685 - val_loss: 0.6194 - val_accuracy: 0.6437 - 1s/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "200/200 - 2s - loss: 0.5937 - accuracy: 0.6720 - val_loss: 0.6193 - val_accuracy: 0.6439 - 2s/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "200/200 - 2s - loss: 0.5921 - accuracy: 0.6728 - val_loss: 0.6190 - val_accuracy: 0.6443 - 2s/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "200/200 - 1s - loss: 0.5925 - accuracy: 0.6719 - val_loss: 0.6176 - val_accuracy: 0.6469 - 1s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "200/200 - 1s - loss: 0.5930 - accuracy: 0.6717 - val_loss: 0.6181 - val_accuracy: 0.6475 - 1s/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "200/200 - 2s - loss: 0.5909 - accuracy: 0.6729 - val_loss: 0.6173 - val_accuracy: 0.6469 - 2s/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "200/200 - 1s - loss: 0.5880 - accuracy: 0.6766 - val_loss: 0.6167 - val_accuracy: 0.6475 - 1s/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "200/200 - 1s - loss: 0.5905 - accuracy: 0.6732 - val_loss: 0.6171 - val_accuracy: 0.6488 - 1s/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "200/200 - 1s - loss: 0.5884 - accuracy: 0.6759 - val_loss: 0.6159 - val_accuracy: 0.6508 - 1s/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "200/200 - 1s - loss: 0.5885 - accuracy: 0.6747 - val_loss: 0.6156 - val_accuracy: 0.6488 - 1s/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "200/200 - 1s - loss: 0.5852 - accuracy: 0.6763 - val_loss: 0.6134 - val_accuracy: 0.6505 - 1s/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "200/200 - 1s - loss: 0.5866 - accuracy: 0.6749 - val_loss: 0.6143 - val_accuracy: 0.6518 - 1s/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "200/200 - 1s - loss: 0.5861 - accuracy: 0.6777 - val_loss: 0.6131 - val_accuracy: 0.6510 - 1s/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "200/200 - 1s - loss: 0.5850 - accuracy: 0.6790 - val_loss: 0.6133 - val_accuracy: 0.6504 - 1s/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "200/200 - 1s - loss: 0.5835 - accuracy: 0.6793 - val_loss: 0.6134 - val_accuracy: 0.6502 - 1s/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "200/200 - 1s - loss: 0.5840 - accuracy: 0.6784 - val_loss: 0.6133 - val_accuracy: 0.6536 - 1s/epoch - 6ms/step\n",
      "\n",
      "Training for Fold 5 ...\n",
      "Epoch 1/100\n",
      "200/200 - 2s - loss: 0.6892 - accuracy: 0.5377 - val_loss: 0.6850 - val_accuracy: 0.5465 - 2s/epoch - 11ms/step\n",
      "Epoch 2/100\n",
      "200/200 - 1s - loss: 0.6827 - accuracy: 0.5541 - val_loss: 0.6823 - val_accuracy: 0.5552 - 1s/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "200/200 - 1s - loss: 0.6799 - accuracy: 0.5599 - val_loss: 0.6804 - val_accuracy: 0.5564 - 1s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "200/200 - 1s - loss: 0.6776 - accuracy: 0.5662 - val_loss: 0.6793 - val_accuracy: 0.5634 - 1s/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "200/200 - 1s - loss: 0.6737 - accuracy: 0.5738 - val_loss: 0.6756 - val_accuracy: 0.5665 - 1s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "200/200 - 1s - loss: 0.6705 - accuracy: 0.5781 - val_loss: 0.6740 - val_accuracy: 0.5750 - 1s/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "200/200 - 1s - loss: 0.6676 - accuracy: 0.5840 - val_loss: 0.6708 - val_accuracy: 0.5802 - 1s/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "200/200 - 1s - loss: 0.6639 - accuracy: 0.5884 - val_loss: 0.6689 - val_accuracy: 0.5813 - 1s/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "200/200 - 1s - loss: 0.6613 - accuracy: 0.5958 - val_loss: 0.6671 - val_accuracy: 0.5857 - 1s/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "200/200 - 1s - loss: 0.6570 - accuracy: 0.5997 - val_loss: 0.6625 - val_accuracy: 0.5928 - 1s/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "200/200 - 1s - loss: 0.6544 - accuracy: 0.6033 - val_loss: 0.6602 - val_accuracy: 0.5975 - 1s/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "200/200 - 2s - loss: 0.6515 - accuracy: 0.6073 - val_loss: 0.6575 - val_accuracy: 0.6002 - 2s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "200/200 - 1s - loss: 0.6482 - accuracy: 0.6123 - val_loss: 0.6553 - val_accuracy: 0.6035 - 1s/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "200/200 - 1s - loss: 0.6452 - accuracy: 0.6149 - val_loss: 0.6549 - val_accuracy: 0.6057 - 1s/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "200/200 - 1s - loss: 0.6425 - accuracy: 0.6186 - val_loss: 0.6521 - val_accuracy: 0.6107 - 1s/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "200/200 - 1s - loss: 0.6395 - accuracy: 0.6230 - val_loss: 0.6504 - val_accuracy: 0.6114 - 1s/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "200/200 - 1s - loss: 0.6370 - accuracy: 0.6247 - val_loss: 0.6480 - val_accuracy: 0.6122 - 1s/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "200/200 - 1s - loss: 0.6344 - accuracy: 0.6321 - val_loss: 0.6463 - val_accuracy: 0.6163 - 1s/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "200/200 - 1s - loss: 0.6332 - accuracy: 0.6290 - val_loss: 0.6449 - val_accuracy: 0.6182 - 1s/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "200/200 - 1s - loss: 0.6300 - accuracy: 0.6326 - val_loss: 0.6440 - val_accuracy: 0.6184 - 1s/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "200/200 - 1s - loss: 0.6284 - accuracy: 0.6342 - val_loss: 0.6418 - val_accuracy: 0.6204 - 1s/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "200/200 - 1s - loss: 0.6264 - accuracy: 0.6373 - val_loss: 0.6408 - val_accuracy: 0.6217 - 1s/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "200/200 - 1s - loss: 0.6249 - accuracy: 0.6393 - val_loss: 0.6393 - val_accuracy: 0.6260 - 1s/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "200/200 - 1s - loss: 0.6235 - accuracy: 0.6393 - val_loss: 0.6392 - val_accuracy: 0.6224 - 1s/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "200/200 - 1s - loss: 0.6207 - accuracy: 0.6433 - val_loss: 0.6369 - val_accuracy: 0.6252 - 1s/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "200/200 - 1s - loss: 0.6185 - accuracy: 0.6466 - val_loss: 0.6361 - val_accuracy: 0.6293 - 1s/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "200/200 - 1s - loss: 0.6178 - accuracy: 0.6458 - val_loss: 0.6359 - val_accuracy: 0.6270 - 1s/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "200/200 - 1s - loss: 0.6155 - accuracy: 0.6493 - val_loss: 0.6332 - val_accuracy: 0.6278 - 1s/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "200/200 - 1s - loss: 0.6137 - accuracy: 0.6485 - val_loss: 0.6322 - val_accuracy: 0.6318 - 1s/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "200/200 - 1s - loss: 0.6140 - accuracy: 0.6507 - val_loss: 0.6331 - val_accuracy: 0.6322 - 1s/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "200/200 - 1s - loss: 0.6102 - accuracy: 0.6535 - val_loss: 0.6315 - val_accuracy: 0.6325 - 1s/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "200/200 - 1s - loss: 0.6110 - accuracy: 0.6539 - val_loss: 0.6298 - val_accuracy: 0.6344 - 1s/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "200/200 - 1s - loss: 0.6067 - accuracy: 0.6576 - val_loss: 0.6300 - val_accuracy: 0.6316 - 1s/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "200/200 - 1s - loss: 0.6072 - accuracy: 0.6574 - val_loss: 0.6279 - val_accuracy: 0.6369 - 1s/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "200/200 - 1s - loss: 0.6065 - accuracy: 0.6576 - val_loss: 0.6278 - val_accuracy: 0.6360 - 1s/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "200/200 - 1s - loss: 0.6049 - accuracy: 0.6586 - val_loss: 0.6266 - val_accuracy: 0.6382 - 1s/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "200/200 - 1s - loss: 0.6044 - accuracy: 0.6590 - val_loss: 0.6269 - val_accuracy: 0.6367 - 1s/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "200/200 - 1s - loss: 0.6015 - accuracy: 0.6628 - val_loss: 0.6261 - val_accuracy: 0.6399 - 1s/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "200/200 - 1s - loss: 0.6018 - accuracy: 0.6624 - val_loss: 0.6248 - val_accuracy: 0.6403 - 1s/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "200/200 - 1s - loss: 0.6008 - accuracy: 0.6621 - val_loss: 0.6249 - val_accuracy: 0.6390 - 1s/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "200/200 - 1s - loss: 0.5997 - accuracy: 0.6632 - val_loss: 0.6231 - val_accuracy: 0.6424 - 1s/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "200/200 - 1s - loss: 0.5987 - accuracy: 0.6642 - val_loss: 0.6232 - val_accuracy: 0.6415 - 1s/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "200/200 - 1s - loss: 0.5959 - accuracy: 0.6682 - val_loss: 0.6212 - val_accuracy: 0.6424 - 1s/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "200/200 - 1s - loss: 0.5953 - accuracy: 0.6679 - val_loss: 0.6218 - val_accuracy: 0.6422 - 1s/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "200/200 - 1s - loss: 0.5960 - accuracy: 0.6670 - val_loss: 0.6213 - val_accuracy: 0.6433 - 1s/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "200/200 - 1s - loss: 0.5935 - accuracy: 0.6694 - val_loss: 0.6205 - val_accuracy: 0.6414 - 1s/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "200/200 - 1s - loss: 0.5945 - accuracy: 0.6697 - val_loss: 0.6211 - val_accuracy: 0.6436 - 1s/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "200/200 - 1s - loss: 0.5925 - accuracy: 0.6704 - val_loss: 0.6207 - val_accuracy: 0.6436 - 1s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "200/200 - 1s - loss: 0.5921 - accuracy: 0.6699 - val_loss: 0.6191 - val_accuracy: 0.6464 - 1s/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "200/200 - 1s - loss: 0.5921 - accuracy: 0.6727 - val_loss: 0.6181 - val_accuracy: 0.6471 - 1s/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "200/200 - 1s - loss: 0.5896 - accuracy: 0.6723 - val_loss: 0.6179 - val_accuracy: 0.6490 - 1s/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "200/200 - 1s - loss: 0.5900 - accuracy: 0.6729 - val_loss: 0.6181 - val_accuracy: 0.6482 - 1s/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "200/200 - 1s - loss: 0.5880 - accuracy: 0.6753 - val_loss: 0.6175 - val_accuracy: 0.6482 - 1s/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "200/200 - 1s - loss: 0.5867 - accuracy: 0.6780 - val_loss: 0.6162 - val_accuracy: 0.6484 - 1s/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "200/200 - 1s - loss: 0.5873 - accuracy: 0.6765 - val_loss: 0.6175 - val_accuracy: 0.6471 - 1s/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "200/200 - 1s - loss: 0.5858 - accuracy: 0.6774 - val_loss: 0.6160 - val_accuracy: 0.6475 - 1s/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "200/200 - 1s - loss: 0.5855 - accuracy: 0.6799 - val_loss: 0.6158 - val_accuracy: 0.6480 - 1s/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "200/200 - 1s - loss: 0.5866 - accuracy: 0.6762 - val_loss: 0.6161 - val_accuracy: 0.6483 - 1s/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "200/200 - 1s - loss: 0.5832 - accuracy: 0.6781 - val_loss: 0.6157 - val_accuracy: 0.6482 - 1s/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "200/200 - 1s - loss: 0.5817 - accuracy: 0.6816 - val_loss: 0.6151 - val_accuracy: 0.6502 - 1s/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "200/200 - 1s - loss: 0.5821 - accuracy: 0.6811 - val_loss: 0.6138 - val_accuracy: 0.6494 - 1s/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "200/200 - 1s - loss: 0.5812 - accuracy: 0.6796 - val_loss: 0.6140 - val_accuracy: 0.6507 - 1s/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "200/200 - 1s - loss: 0.5822 - accuracy: 0.6813 - val_loss: 0.6139 - val_accuracy: 0.6501 - 1s/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "200/200 - 1s - loss: 0.5808 - accuracy: 0.6808 - val_loss: 0.6130 - val_accuracy: 0.6521 - 1s/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "200/200 - 1s - loss: 0.5808 - accuracy: 0.6820 - val_loss: 0.6122 - val_accuracy: 0.6510 - 1s/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "200/200 - 1s - loss: 0.5781 - accuracy: 0.6841 - val_loss: 0.6116 - val_accuracy: 0.6527 - 1s/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "200/200 - 1s - loss: 0.5787 - accuracy: 0.6828 - val_loss: 0.6119 - val_accuracy: 0.6524 - 1s/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "200/200 - 1s - loss: 0.5802 - accuracy: 0.6841 - val_loss: 0.6119 - val_accuracy: 0.6505 - 1s/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "200/200 - 1s - loss: 0.5782 - accuracy: 0.6838 - val_loss: 0.6116 - val_accuracy: 0.6529 - 1s/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "200/200 - 1s - loss: 0.5781 - accuracy: 0.6852 - val_loss: 0.6111 - val_accuracy: 0.6527 - 1s/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "200/200 - 1s - loss: 0.5776 - accuracy: 0.6870 - val_loss: 0.6104 - val_accuracy: 0.6543 - 1s/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "200/200 - 1s - loss: 0.5765 - accuracy: 0.6857 - val_loss: 0.6110 - val_accuracy: 0.6513 - 1s/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "200/200 - 1s - loss: 0.5769 - accuracy: 0.6865 - val_loss: 0.6101 - val_accuracy: 0.6541 - 1s/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "200/200 - 1s - loss: 0.5743 - accuracy: 0.6859 - val_loss: 0.6115 - val_accuracy: 0.6523 - 1s/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "200/200 - 1s - loss: 0.5753 - accuracy: 0.6863 - val_loss: 0.6098 - val_accuracy: 0.6560 - 1s/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "200/200 - 1s - loss: 0.5745 - accuracy: 0.6872 - val_loss: 0.6102 - val_accuracy: 0.6552 - 1s/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "200/200 - 1s - loss: 0.5747 - accuracy: 0.6872 - val_loss: 0.6097 - val_accuracy: 0.6535 - 1s/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "200/200 - 1s - loss: 0.5741 - accuracy: 0.6882 - val_loss: 0.6094 - val_accuracy: 0.6543 - 1s/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "200/200 - 1s - loss: 0.5719 - accuracy: 0.6904 - val_loss: 0.6088 - val_accuracy: 0.6546 - 1s/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "200/200 - 1s - loss: 0.5732 - accuracy: 0.6875 - val_loss: 0.6096 - val_accuracy: 0.6552 - 1s/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "200/200 - 1s - loss: 0.5724 - accuracy: 0.6906 - val_loss: 0.6089 - val_accuracy: 0.6557 - 1s/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "200/200 - 1s - loss: 0.5719 - accuracy: 0.6900 - val_loss: 0.6081 - val_accuracy: 0.6560 - 1s/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "200/200 - 1s - loss: 0.5739 - accuracy: 0.6872 - val_loss: 0.6082 - val_accuracy: 0.6572 - 1s/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "200/200 - 1s - loss: 0.5713 - accuracy: 0.6910 - val_loss: 0.6081 - val_accuracy: 0.6556 - 1s/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "200/200 - 1s - loss: 0.5704 - accuracy: 0.6897 - val_loss: 0.6064 - val_accuracy: 0.6573 - 1s/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "200/200 - 1s - loss: 0.5710 - accuracy: 0.6899 - val_loss: 0.6078 - val_accuracy: 0.6579 - 1s/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "200/200 - 1s - loss: 0.5713 - accuracy: 0.6907 - val_loss: 0.6080 - val_accuracy: 0.6569 - 1s/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "200/200 - 1s - loss: 0.5694 - accuracy: 0.6920 - val_loss: 0.6084 - val_accuracy: 0.6555 - 1s/epoch - 6ms/step\n",
      "\n",
      "------- Batch Size: 1024 -------\n",
      "\n",
      "Training for Fold 1 ...\n",
      "Epoch 1/100\n",
      "100/100 - 2s - loss: 0.6906 - accuracy: 0.5376 - val_loss: 0.6852 - val_accuracy: 0.5490 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "100/100 - 1s - loss: 0.6836 - accuracy: 0.5524 - val_loss: 0.6829 - val_accuracy: 0.5538 - 774ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "100/100 - 1s - loss: 0.6807 - accuracy: 0.5596 - val_loss: 0.6809 - val_accuracy: 0.5580 - 942ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "100/100 - 1s - loss: 0.6785 - accuracy: 0.5628 - val_loss: 0.6798 - val_accuracy: 0.5594 - 996ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "100/100 - 1s - loss: 0.6761 - accuracy: 0.5685 - val_loss: 0.6778 - val_accuracy: 0.5668 - 887ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "100/100 - 1s - loss: 0.6740 - accuracy: 0.5723 - val_loss: 0.6751 - val_accuracy: 0.5725 - 785ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "100/100 - 1s - loss: 0.6709 - accuracy: 0.5790 - val_loss: 0.6735 - val_accuracy: 0.5728 - 893ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "100/100 - 1s - loss: 0.6685 - accuracy: 0.5833 - val_loss: 0.6721 - val_accuracy: 0.5766 - 902ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "100/100 - 1s - loss: 0.6658 - accuracy: 0.5854 - val_loss: 0.6692 - val_accuracy: 0.5818 - 918ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "100/100 - 1s - loss: 0.6632 - accuracy: 0.5914 - val_loss: 0.6679 - val_accuracy: 0.5837 - 896ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "100/100 - 1s - loss: 0.6608 - accuracy: 0.5956 - val_loss: 0.6654 - val_accuracy: 0.5876 - 857ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "100/100 - 1s - loss: 0.6572 - accuracy: 0.5991 - val_loss: 0.6630 - val_accuracy: 0.5910 - 931ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "100/100 - 1s - loss: 0.6552 - accuracy: 0.6042 - val_loss: 0.6614 - val_accuracy: 0.5938 - 881ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "100/100 - 1s - loss: 0.6524 - accuracy: 0.6065 - val_loss: 0.6590 - val_accuracy: 0.5968 - 943ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "100/100 - 1s - loss: 0.6498 - accuracy: 0.6106 - val_loss: 0.6582 - val_accuracy: 0.5991 - 795ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "100/100 - 1s - loss: 0.6470 - accuracy: 0.6112 - val_loss: 0.6554 - val_accuracy: 0.6031 - 892ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "100/100 - 1s - loss: 0.6438 - accuracy: 0.6162 - val_loss: 0.6544 - val_accuracy: 0.6014 - 906ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "100/100 - 1s - loss: 0.6424 - accuracy: 0.6184 - val_loss: 0.6529 - val_accuracy: 0.6056 - 882ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "100/100 - 1s - loss: 0.6411 - accuracy: 0.6226 - val_loss: 0.6509 - val_accuracy: 0.6072 - 813ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "100/100 - 1s - loss: 0.6372 - accuracy: 0.6268 - val_loss: 0.6477 - val_accuracy: 0.6136 - 907ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "100/100 - 1s - loss: 0.6358 - accuracy: 0.6279 - val_loss: 0.6467 - val_accuracy: 0.6138 - 931ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "100/100 - 1s - loss: 0.6346 - accuracy: 0.6291 - val_loss: 0.6453 - val_accuracy: 0.6163 - 886ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "100/100 - 1s - loss: 0.6312 - accuracy: 0.6329 - val_loss: 0.6441 - val_accuracy: 0.6155 - 807ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "100/100 - 1s - loss: 0.6302 - accuracy: 0.6345 - val_loss: 0.6423 - val_accuracy: 0.6187 - 889ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "100/100 - 1s - loss: 0.6300 - accuracy: 0.6352 - val_loss: 0.6407 - val_accuracy: 0.6215 - 871ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "100/100 - 1s - loss: 0.6261 - accuracy: 0.6384 - val_loss: 0.6390 - val_accuracy: 0.6236 - 917ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "100/100 - 1s - loss: 0.6242 - accuracy: 0.6397 - val_loss: 0.6392 - val_accuracy: 0.6249 - 835ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "100/100 - 1s - loss: 0.6230 - accuracy: 0.6418 - val_loss: 0.6373 - val_accuracy: 0.6252 - 837ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "100/100 - 1s - loss: 0.6212 - accuracy: 0.6431 - val_loss: 0.6363 - val_accuracy: 0.6257 - 855ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "100/100 - 1s - loss: 0.6203 - accuracy: 0.6452 - val_loss: 0.6358 - val_accuracy: 0.6259 - 886ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "100/100 - 1s - loss: 0.6180 - accuracy: 0.6471 - val_loss: 0.6343 - val_accuracy: 0.6276 - 865ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "100/100 - 1s - loss: 0.6162 - accuracy: 0.6496 - val_loss: 0.6330 - val_accuracy: 0.6303 - 787ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "100/100 - 1s - loss: 0.6148 - accuracy: 0.6498 - val_loss: 0.6334 - val_accuracy: 0.6302 - 884ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "100/100 - 1s - loss: 0.6112 - accuracy: 0.6545 - val_loss: 0.6321 - val_accuracy: 0.6320 - 891ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "100/100 - 1s - loss: 0.6125 - accuracy: 0.6536 - val_loss: 0.6299 - val_accuracy: 0.6321 - 980ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "100/100 - 1s - loss: 0.6100 - accuracy: 0.6576 - val_loss: 0.6291 - val_accuracy: 0.6350 - 834ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "100/100 - 1s - loss: 0.6088 - accuracy: 0.6592 - val_loss: 0.6295 - val_accuracy: 0.6336 - 906ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "100/100 - 1s - loss: 0.6081 - accuracy: 0.6576 - val_loss: 0.6284 - val_accuracy: 0.6341 - 878ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "100/100 - 1s - loss: 0.6064 - accuracy: 0.6588 - val_loss: 0.6264 - val_accuracy: 0.6393 - 897ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "100/100 - 1s - loss: 0.6043 - accuracy: 0.6633 - val_loss: 0.6257 - val_accuracy: 0.6383 - 815ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "100/100 - 1s - loss: 0.6028 - accuracy: 0.6625 - val_loss: 0.6247 - val_accuracy: 0.6405 - 847ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "100/100 - 1s - loss: 0.6017 - accuracy: 0.6652 - val_loss: 0.6242 - val_accuracy: 0.6388 - 889ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "100/100 - 1s - loss: 0.6005 - accuracy: 0.6652 - val_loss: 0.6234 - val_accuracy: 0.6409 - 863ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "100/100 - 1s - loss: 0.6010 - accuracy: 0.6644 - val_loss: 0.6229 - val_accuracy: 0.6416 - 899ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "100/100 - 1s - loss: 0.5992 - accuracy: 0.6670 - val_loss: 0.6217 - val_accuracy: 0.6432 - 830ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "100/100 - 1s - loss: 0.5982 - accuracy: 0.6671 - val_loss: 0.6218 - val_accuracy: 0.6440 - 887ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "100/100 - 1s - loss: 0.5971 - accuracy: 0.6697 - val_loss: 0.6203 - val_accuracy: 0.6441 - 914ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "100/100 - 1s - loss: 0.5952 - accuracy: 0.6712 - val_loss: 0.6197 - val_accuracy: 0.6455 - 861ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "100/100 - 1s - loss: 0.5956 - accuracy: 0.6691 - val_loss: 0.6198 - val_accuracy: 0.6450 - 787ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "100/100 - 1s - loss: 0.5936 - accuracy: 0.6709 - val_loss: 0.6184 - val_accuracy: 0.6466 - 854ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "100/100 - 1s - loss: 0.5941 - accuracy: 0.6703 - val_loss: 0.6180 - val_accuracy: 0.6475 - 889ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "100/100 - 1s - loss: 0.5922 - accuracy: 0.6749 - val_loss: 0.6187 - val_accuracy: 0.6459 - 861ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "100/100 - 1s - loss: 0.5926 - accuracy: 0.6723 - val_loss: 0.6179 - val_accuracy: 0.6473 - 824ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "100/100 - 1s - loss: 0.5897 - accuracy: 0.6757 - val_loss: 0.6168 - val_accuracy: 0.6480 - 865ms/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "100/100 - 1s - loss: 0.5897 - accuracy: 0.6764 - val_loss: 0.6170 - val_accuracy: 0.6488 - 912ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "100/100 - 1s - loss: 0.5884 - accuracy: 0.6782 - val_loss: 0.6159 - val_accuracy: 0.6496 - 887ms/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "100/100 - 1s - loss: 0.5902 - accuracy: 0.6757 - val_loss: 0.6153 - val_accuracy: 0.6495 - 809ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "100/100 - 1s - loss: 0.5895 - accuracy: 0.6776 - val_loss: 0.6165 - val_accuracy: 0.6511 - 880ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "100/100 - 1s - loss: 0.5866 - accuracy: 0.6784 - val_loss: 0.6143 - val_accuracy: 0.6513 - 880ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "100/100 - 1s - loss: 0.5872 - accuracy: 0.6781 - val_loss: 0.6143 - val_accuracy: 0.6504 - 865ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "100/100 - 1s - loss: 0.5859 - accuracy: 0.6799 - val_loss: 0.6142 - val_accuracy: 0.6516 - 1s/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "100/100 - 1s - loss: 0.5861 - accuracy: 0.6784 - val_loss: 0.6137 - val_accuracy: 0.6524 - 926ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "100/100 - 1s - loss: 0.5851 - accuracy: 0.6803 - val_loss: 0.6136 - val_accuracy: 0.6515 - 878ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "100/100 - 1s - loss: 0.5843 - accuracy: 0.6804 - val_loss: 0.6125 - val_accuracy: 0.6538 - 918ms/epoch - 9ms/step\n",
      "Epoch 65/100\n",
      "100/100 - 1s - loss: 0.5820 - accuracy: 0.6822 - val_loss: 0.6121 - val_accuracy: 0.6521 - 916ms/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "100/100 - 1s - loss: 0.5838 - accuracy: 0.6820 - val_loss: 0.6125 - val_accuracy: 0.6529 - 822ms/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "100/100 - 1s - loss: 0.5828 - accuracy: 0.6815 - val_loss: 0.6119 - val_accuracy: 0.6535 - 906ms/epoch - 9ms/step\n",
      "Epoch 68/100\n",
      "100/100 - 1s - loss: 0.5810 - accuracy: 0.6850 - val_loss: 0.6118 - val_accuracy: 0.6541 - 903ms/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "100/100 - 1s - loss: 0.5822 - accuracy: 0.6814 - val_loss: 0.6118 - val_accuracy: 0.6529 - 926ms/epoch - 9ms/step\n",
      "Epoch 70/100\n",
      "100/100 - 1s - loss: 0.5793 - accuracy: 0.6848 - val_loss: 0.6105 - val_accuracy: 0.6535 - 843ms/epoch - 8ms/step\n",
      "Epoch 71/100\n",
      "100/100 - 1s - loss: 0.5798 - accuracy: 0.6845 - val_loss: 0.6119 - val_accuracy: 0.6518 - 927ms/epoch - 9ms/step\n",
      "Epoch 72/100\n",
      "100/100 - 1s - loss: 0.5793 - accuracy: 0.6854 - val_loss: 0.6099 - val_accuracy: 0.6549 - 988ms/epoch - 10ms/step\n",
      "Epoch 73/100\n",
      "100/100 - 1s - loss: 0.5792 - accuracy: 0.6849 - val_loss: 0.6112 - val_accuracy: 0.6526 - 914ms/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "100/100 - 1s - loss: 0.5792 - accuracy: 0.6844 - val_loss: 0.6093 - val_accuracy: 0.6566 - 889ms/epoch - 9ms/step\n",
      "Epoch 75/100\n",
      "100/100 - 1s - loss: 0.5778 - accuracy: 0.6866 - val_loss: 0.6095 - val_accuracy: 0.6554 - 899ms/epoch - 9ms/step\n",
      "Epoch 76/100\n",
      "100/100 - 1s - loss: 0.5772 - accuracy: 0.6867 - val_loss: 0.6088 - val_accuracy: 0.6556 - 974ms/epoch - 10ms/step\n",
      "Epoch 77/100\n",
      "100/100 - 1s - loss: 0.5753 - accuracy: 0.6895 - val_loss: 0.6085 - val_accuracy: 0.6568 - 1s/epoch - 10ms/step\n",
      "Epoch 78/100\n",
      "100/100 - 1s - loss: 0.5742 - accuracy: 0.6895 - val_loss: 0.6091 - val_accuracy: 0.6563 - 1s/epoch - 10ms/step\n",
      "Epoch 79/100\n",
      "100/100 - 1s - loss: 0.5750 - accuracy: 0.6892 - val_loss: 0.6084 - val_accuracy: 0.6568 - 911ms/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "100/100 - 1s - loss: 0.5754 - accuracy: 0.6881 - val_loss: 0.6077 - val_accuracy: 0.6576 - 1s/epoch - 11ms/step\n",
      "Epoch 81/100\n",
      "100/100 - 1s - loss: 0.5726 - accuracy: 0.6901 - val_loss: 0.6083 - val_accuracy: 0.6564 - 977ms/epoch - 10ms/step\n",
      "Epoch 82/100\n",
      "100/100 - 1s - loss: 0.5736 - accuracy: 0.6901 - val_loss: 0.6091 - val_accuracy: 0.6562 - 891ms/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "100/100 - 1s - loss: 0.5731 - accuracy: 0.6899 - val_loss: 0.6081 - val_accuracy: 0.6577 - 792ms/epoch - 8ms/step\n",
      "\n",
      "Training for Fold 2 ...\n",
      "Epoch 1/100\n",
      "100/100 - 2s - loss: 0.6905 - accuracy: 0.5352 - val_loss: 0.6852 - val_accuracy: 0.5467 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "100/100 - 1s - loss: 0.6837 - accuracy: 0.5512 - val_loss: 0.6823 - val_accuracy: 0.5546 - 888ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "100/100 - 1s - loss: 0.6801 - accuracy: 0.5601 - val_loss: 0.6802 - val_accuracy: 0.5562 - 947ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "100/100 - 1s - loss: 0.6776 - accuracy: 0.5657 - val_loss: 0.6789 - val_accuracy: 0.5638 - 888ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "100/100 - 1s - loss: 0.6744 - accuracy: 0.5708 - val_loss: 0.6757 - val_accuracy: 0.5685 - 1s/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "100/100 - 1s - loss: 0.6721 - accuracy: 0.5757 - val_loss: 0.6744 - val_accuracy: 0.5714 - 959ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "100/100 - 1s - loss: 0.6694 - accuracy: 0.5807 - val_loss: 0.6724 - val_accuracy: 0.5762 - 1s/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "100/100 - 1s - loss: 0.6664 - accuracy: 0.5857 - val_loss: 0.6690 - val_accuracy: 0.5806 - 889ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "100/100 - 1s - loss: 0.6642 - accuracy: 0.5889 - val_loss: 0.6677 - val_accuracy: 0.5841 - 810ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "100/100 - 1s - loss: 0.6605 - accuracy: 0.5960 - val_loss: 0.6661 - val_accuracy: 0.5848 - 897ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "100/100 - 1s - loss: 0.6588 - accuracy: 0.5978 - val_loss: 0.6642 - val_accuracy: 0.5877 - 878ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "100/100 - 1s - loss: 0.6549 - accuracy: 0.6011 - val_loss: 0.6611 - val_accuracy: 0.5922 - 884ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "100/100 - 1s - loss: 0.6530 - accuracy: 0.6036 - val_loss: 0.6598 - val_accuracy: 0.5932 - 994ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "100/100 - 1s - loss: 0.6492 - accuracy: 0.6089 - val_loss: 0.6574 - val_accuracy: 0.5981 - 1s/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "100/100 - 1s - loss: 0.6479 - accuracy: 0.6108 - val_loss: 0.6555 - val_accuracy: 0.6014 - 961ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "100/100 - 1s - loss: 0.6457 - accuracy: 0.6139 - val_loss: 0.6543 - val_accuracy: 0.6007 - 935ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "100/100 - 1s - loss: 0.6425 - accuracy: 0.6202 - val_loss: 0.6524 - val_accuracy: 0.6052 - 902ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "100/100 - 1s - loss: 0.6401 - accuracy: 0.6208 - val_loss: 0.6504 - val_accuracy: 0.6100 - 778ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "100/100 - 1s - loss: 0.6375 - accuracy: 0.6242 - val_loss: 0.6487 - val_accuracy: 0.6106 - 870ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "100/100 - 1s - loss: 0.6346 - accuracy: 0.6285 - val_loss: 0.6486 - val_accuracy: 0.6106 - 912ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "100/100 - 1s - loss: 0.6329 - accuracy: 0.6278 - val_loss: 0.6464 - val_accuracy: 0.6121 - 878ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "100/100 - 1s - loss: 0.6308 - accuracy: 0.6321 - val_loss: 0.6450 - val_accuracy: 0.6146 - 805ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "100/100 - 1s - loss: 0.6299 - accuracy: 0.6324 - val_loss: 0.6440 - val_accuracy: 0.6160 - 883ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "100/100 - 1s - loss: 0.6277 - accuracy: 0.6367 - val_loss: 0.6418 - val_accuracy: 0.6198 - 867ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "100/100 - 1s - loss: 0.6255 - accuracy: 0.6377 - val_loss: 0.6414 - val_accuracy: 0.6192 - 894ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "100/100 - 1s - loss: 0.6244 - accuracy: 0.6380 - val_loss: 0.6402 - val_accuracy: 0.6197 - 923ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "100/100 - 1s - loss: 0.6225 - accuracy: 0.6401 - val_loss: 0.6389 - val_accuracy: 0.6214 - 998ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "100/100 - 1s - loss: 0.6208 - accuracy: 0.6425 - val_loss: 0.6378 - val_accuracy: 0.6232 - 946ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "100/100 - 1s - loss: 0.6173 - accuracy: 0.6465 - val_loss: 0.6372 - val_accuracy: 0.6260 - 1s/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "100/100 - 1s - loss: 0.6161 - accuracy: 0.6465 - val_loss: 0.6361 - val_accuracy: 0.6235 - 822ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "100/100 - 1s - loss: 0.6154 - accuracy: 0.6482 - val_loss: 0.6354 - val_accuracy: 0.6268 - 763ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "100/100 - 1s - loss: 0.6137 - accuracy: 0.6490 - val_loss: 0.6336 - val_accuracy: 0.6286 - 832ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "100/100 - 1s - loss: 0.6122 - accuracy: 0.6498 - val_loss: 0.6327 - val_accuracy: 0.6285 - 877ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "100/100 - 1s - loss: 0.6097 - accuracy: 0.6541 - val_loss: 0.6322 - val_accuracy: 0.6293 - 827ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "100/100 - 1s - loss: 0.6104 - accuracy: 0.6533 - val_loss: 0.6325 - val_accuracy: 0.6298 - 769ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "100/100 - 1s - loss: 0.6087 - accuracy: 0.6545 - val_loss: 0.6311 - val_accuracy: 0.6307 - 819ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "100/100 - 1s - loss: 0.6079 - accuracy: 0.6545 - val_loss: 0.6291 - val_accuracy: 0.6338 - 823ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "100/100 - 1s - loss: 0.6044 - accuracy: 0.6581 - val_loss: 0.6290 - val_accuracy: 0.6330 - 917ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "100/100 - 1s - loss: 0.6050 - accuracy: 0.6581 - val_loss: 0.6283 - val_accuracy: 0.6357 - 836ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "100/100 - 1s - loss: 0.6039 - accuracy: 0.6584 - val_loss: 0.6272 - val_accuracy: 0.6361 - 771ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "100/100 - 1s - loss: 0.6009 - accuracy: 0.6621 - val_loss: 0.6272 - val_accuracy: 0.6360 - 826ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "100/100 - 1s - loss: 0.6025 - accuracy: 0.6603 - val_loss: 0.6265 - val_accuracy: 0.6364 - 819ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "100/100 - 1s - loss: 0.6012 - accuracy: 0.6593 - val_loss: 0.6252 - val_accuracy: 0.6403 - 825ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "100/100 - 1s - loss: 0.5995 - accuracy: 0.6644 - val_loss: 0.6260 - val_accuracy: 0.6380 - 758ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "100/100 - 1s - loss: 0.5978 - accuracy: 0.6644 - val_loss: 0.6247 - val_accuracy: 0.6419 - 805ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "100/100 - 1s - loss: 0.5971 - accuracy: 0.6648 - val_loss: 0.6244 - val_accuracy: 0.6380 - 829ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "100/100 - 1s - loss: 0.5962 - accuracy: 0.6653 - val_loss: 0.6238 - val_accuracy: 0.6396 - 843ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "100/100 - 1s - loss: 0.5953 - accuracy: 0.6667 - val_loss: 0.6247 - val_accuracy: 0.6388 - 836ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "100/100 - 1s - loss: 0.5956 - accuracy: 0.6679 - val_loss: 0.6229 - val_accuracy: 0.6404 - 852ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "100/100 - 1s - loss: 0.5930 - accuracy: 0.6697 - val_loss: 0.6219 - val_accuracy: 0.6426 - 853ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "100/100 - 1s - loss: 0.5939 - accuracy: 0.6684 - val_loss: 0.6218 - val_accuracy: 0.6414 - 825ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "100/100 - 1s - loss: 0.5902 - accuracy: 0.6724 - val_loss: 0.6212 - val_accuracy: 0.6430 - 873ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "100/100 - 1s - loss: 0.5910 - accuracy: 0.6716 - val_loss: 0.6210 - val_accuracy: 0.6423 - 752ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "100/100 - 1s - loss: 0.5887 - accuracy: 0.6729 - val_loss: 0.6204 - val_accuracy: 0.6443 - 816ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "100/100 - 1s - loss: 0.5890 - accuracy: 0.6724 - val_loss: 0.6198 - val_accuracy: 0.6437 - 818ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "100/100 - 1s - loss: 0.5890 - accuracy: 0.6738 - val_loss: 0.6201 - val_accuracy: 0.6433 - 819ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "100/100 - 1s - loss: 0.5882 - accuracy: 0.6723 - val_loss: 0.6194 - val_accuracy: 0.6451 - 753ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "100/100 - 1s - loss: 0.5873 - accuracy: 0.6756 - val_loss: 0.6184 - val_accuracy: 0.6435 - 869ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "100/100 - 1s - loss: 0.5861 - accuracy: 0.6763 - val_loss: 0.6192 - val_accuracy: 0.6420 - 890ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "100/100 - 1s - loss: 0.5856 - accuracy: 0.6758 - val_loss: 0.6184 - val_accuracy: 0.6455 - 898ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "100/100 - 1s - loss: 0.5838 - accuracy: 0.6787 - val_loss: 0.6174 - val_accuracy: 0.6456 - 846ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "100/100 - 1s - loss: 0.5834 - accuracy: 0.6783 - val_loss: 0.6160 - val_accuracy: 0.6490 - 1s/epoch - 10ms/step\n",
      "Epoch 63/100\n",
      "100/100 - 1s - loss: 0.5847 - accuracy: 0.6768 - val_loss: 0.6172 - val_accuracy: 0.6469 - 1s/epoch - 11ms/step\n",
      "Epoch 64/100\n",
      "100/100 - 1s - loss: 0.5838 - accuracy: 0.6786 - val_loss: 0.6176 - val_accuracy: 0.6456 - 962ms/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "100/100 - 1s - loss: 0.5806 - accuracy: 0.6817 - val_loss: 0.6174 - val_accuracy: 0.6449 - 845ms/epoch - 8ms/step\n",
      "\n",
      "Training for Fold 3 ...\n",
      "Epoch 1/100\n",
      "100/100 - 2s - loss: 0.6906 - accuracy: 0.5361 - val_loss: 0.6851 - val_accuracy: 0.5459 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "100/100 - 1s - loss: 0.6831 - accuracy: 0.5531 - val_loss: 0.6841 - val_accuracy: 0.5471 - 919ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "100/100 - 1s - loss: 0.6803 - accuracy: 0.5602 - val_loss: 0.6800 - val_accuracy: 0.5596 - 987ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "100/100 - 1s - loss: 0.6774 - accuracy: 0.5672 - val_loss: 0.6777 - val_accuracy: 0.5639 - 870ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "100/100 - 1s - loss: 0.6747 - accuracy: 0.5694 - val_loss: 0.6758 - val_accuracy: 0.5697 - 836ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "100/100 - 1s - loss: 0.6723 - accuracy: 0.5757 - val_loss: 0.6732 - val_accuracy: 0.5738 - 905ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "100/100 - 1s - loss: 0.6688 - accuracy: 0.5818 - val_loss: 0.6713 - val_accuracy: 0.5786 - 883ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "100/100 - 1s - loss: 0.6664 - accuracy: 0.5859 - val_loss: 0.6692 - val_accuracy: 0.5840 - 932ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "100/100 - 1s - loss: 0.6640 - accuracy: 0.5909 - val_loss: 0.6675 - val_accuracy: 0.5834 - 1s/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "100/100 - 1s - loss: 0.6603 - accuracy: 0.5962 - val_loss: 0.6648 - val_accuracy: 0.5875 - 854ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "100/100 - 1s - loss: 0.6586 - accuracy: 0.6001 - val_loss: 0.6613 - val_accuracy: 0.5938 - 954ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "100/100 - 1s - loss: 0.6547 - accuracy: 0.6042 - val_loss: 0.6590 - val_accuracy: 0.5978 - 951ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "100/100 - 1s - loss: 0.6523 - accuracy: 0.6087 - val_loss: 0.6569 - val_accuracy: 0.6020 - 1s/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "100/100 - 1s - loss: 0.6518 - accuracy: 0.6090 - val_loss: 0.6554 - val_accuracy: 0.6007 - 982ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "100/100 - 1s - loss: 0.6470 - accuracy: 0.6158 - val_loss: 0.6528 - val_accuracy: 0.6065 - 1s/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "100/100 - 1s - loss: 0.6444 - accuracy: 0.6186 - val_loss: 0.6524 - val_accuracy: 0.6069 - 915ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "100/100 - 1s - loss: 0.6426 - accuracy: 0.6201 - val_loss: 0.6506 - val_accuracy: 0.6107 - 916ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "100/100 - 1s - loss: 0.6407 - accuracy: 0.6222 - val_loss: 0.6480 - val_accuracy: 0.6145 - 861ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "100/100 - 1s - loss: 0.6365 - accuracy: 0.6278 - val_loss: 0.6463 - val_accuracy: 0.6148 - 638ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "100/100 - 1s - loss: 0.6349 - accuracy: 0.6288 - val_loss: 0.6451 - val_accuracy: 0.6190 - 600ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "100/100 - 1s - loss: 0.6338 - accuracy: 0.6306 - val_loss: 0.6434 - val_accuracy: 0.6201 - 619ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "100/100 - 1s - loss: 0.6317 - accuracy: 0.6338 - val_loss: 0.6422 - val_accuracy: 0.6204 - 569ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "100/100 - 1s - loss: 0.6299 - accuracy: 0.6353 - val_loss: 0.6401 - val_accuracy: 0.6242 - 573ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "100/100 - 1s - loss: 0.6266 - accuracy: 0.6402 - val_loss: 0.6392 - val_accuracy: 0.6249 - 585ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "100/100 - 1s - loss: 0.6255 - accuracy: 0.6415 - val_loss: 0.6380 - val_accuracy: 0.6278 - 575ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "100/100 - 1s - loss: 0.6235 - accuracy: 0.6414 - val_loss: 0.6368 - val_accuracy: 0.6277 - 572ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "100/100 - 1s - loss: 0.6223 - accuracy: 0.6448 - val_loss: 0.6360 - val_accuracy: 0.6293 - 597ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "100/100 - 1s - loss: 0.6213 - accuracy: 0.6462 - val_loss: 0.6344 - val_accuracy: 0.6333 - 578ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "100/100 - 1s - loss: 0.6188 - accuracy: 0.6471 - val_loss: 0.6334 - val_accuracy: 0.6338 - 573ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "100/100 - 1s - loss: 0.6169 - accuracy: 0.6508 - val_loss: 0.6313 - val_accuracy: 0.6343 - 577ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "100/100 - 1s - loss: 0.6153 - accuracy: 0.6504 - val_loss: 0.6309 - val_accuracy: 0.6349 - 581ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "100/100 - 1s - loss: 0.6146 - accuracy: 0.6539 - val_loss: 0.6297 - val_accuracy: 0.6375 - 581ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "100/100 - 1s - loss: 0.6135 - accuracy: 0.6531 - val_loss: 0.6287 - val_accuracy: 0.6369 - 568ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "100/100 - 1s - loss: 0.6107 - accuracy: 0.6571 - val_loss: 0.6282 - val_accuracy: 0.6385 - 578ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "100/100 - 1s - loss: 0.6095 - accuracy: 0.6558 - val_loss: 0.6266 - val_accuracy: 0.6379 - 583ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "100/100 - 1s - loss: 0.6078 - accuracy: 0.6597 - val_loss: 0.6258 - val_accuracy: 0.6385 - 568ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "100/100 - 1s - loss: 0.6086 - accuracy: 0.6586 - val_loss: 0.6247 - val_accuracy: 0.6404 - 578ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "100/100 - 1s - loss: 0.6034 - accuracy: 0.6636 - val_loss: 0.6243 - val_accuracy: 0.6406 - 585ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "100/100 - 1s - loss: 0.6044 - accuracy: 0.6616 - val_loss: 0.6234 - val_accuracy: 0.6412 - 655ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "100/100 - 1s - loss: 0.6038 - accuracy: 0.6635 - val_loss: 0.6227 - val_accuracy: 0.6418 - 720ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "100/100 - 1s - loss: 0.6014 - accuracy: 0.6644 - val_loss: 0.6222 - val_accuracy: 0.6417 - 620ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "100/100 - 1s - loss: 0.5996 - accuracy: 0.6662 - val_loss: 0.6212 - val_accuracy: 0.6446 - 713ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "100/100 - 1s - loss: 0.5994 - accuracy: 0.6668 - val_loss: 0.6202 - val_accuracy: 0.6449 - 725ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "100/100 - 1s - loss: 0.5988 - accuracy: 0.6682 - val_loss: 0.6203 - val_accuracy: 0.6455 - 624ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "100/100 - 1s - loss: 0.5976 - accuracy: 0.6706 - val_loss: 0.6201 - val_accuracy: 0.6450 - 676ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "100/100 - 1s - loss: 0.5955 - accuracy: 0.6703 - val_loss: 0.6189 - val_accuracy: 0.6464 - 648ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "100/100 - 1s - loss: 0.5957 - accuracy: 0.6705 - val_loss: 0.6180 - val_accuracy: 0.6472 - 714ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "100/100 - 1s - loss: 0.5952 - accuracy: 0.6714 - val_loss: 0.6182 - val_accuracy: 0.6467 - 576ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "100/100 - 1s - loss: 0.5931 - accuracy: 0.6736 - val_loss: 0.6173 - val_accuracy: 0.6495 - 693ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "100/100 - 1s - loss: 0.5938 - accuracy: 0.6727 - val_loss: 0.6170 - val_accuracy: 0.6495 - 604ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "100/100 - 1s - loss: 0.5926 - accuracy: 0.6747 - val_loss: 0.6166 - val_accuracy: 0.6488 - 628ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "100/100 - 1s - loss: 0.5901 - accuracy: 0.6762 - val_loss: 0.6153 - val_accuracy: 0.6499 - 621ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "100/100 - 1s - loss: 0.5895 - accuracy: 0.6783 - val_loss: 0.6153 - val_accuracy: 0.6506 - 756ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "100/100 - 1s - loss: 0.5895 - accuracy: 0.6771 - val_loss: 0.6149 - val_accuracy: 0.6533 - 650ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "100/100 - 1s - loss: 0.5873 - accuracy: 0.6795 - val_loss: 0.6144 - val_accuracy: 0.6507 - 652ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "100/100 - 1s - loss: 0.5868 - accuracy: 0.6783 - val_loss: 0.6139 - val_accuracy: 0.6524 - 715ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "100/100 - 1s - loss: 0.5868 - accuracy: 0.6784 - val_loss: 0.6137 - val_accuracy: 0.6529 - 628ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "100/100 - 1s - loss: 0.5865 - accuracy: 0.6802 - val_loss: 0.6133 - val_accuracy: 0.6531 - 650ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "100/100 - 1s - loss: 0.5865 - accuracy: 0.6784 - val_loss: 0.6136 - val_accuracy: 0.6525 - 730ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "100/100 - 1s - loss: 0.5851 - accuracy: 0.6799 - val_loss: 0.6127 - val_accuracy: 0.6525 - 602ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "100/100 - 1s - loss: 0.5841 - accuracy: 0.6819 - val_loss: 0.6110 - val_accuracy: 0.6562 - 602ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "100/100 - 1s - loss: 0.5839 - accuracy: 0.6815 - val_loss: 0.6111 - val_accuracy: 0.6552 - 612ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "100/100 - 1s - loss: 0.5822 - accuracy: 0.6825 - val_loss: 0.6113 - val_accuracy: 0.6548 - 627ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "100/100 - 1s - loss: 0.5825 - accuracy: 0.6814 - val_loss: 0.6114 - val_accuracy: 0.6539 - 581ms/epoch - 6ms/step\n",
      "\n",
      "Training for Fold 4 ...\n",
      "Epoch 1/100\n",
      "100/100 - 1s - loss: 0.6901 - accuracy: 0.5366 - val_loss: 0.6849 - val_accuracy: 0.5465 - 1s/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "100/100 - 1s - loss: 0.6835 - accuracy: 0.5508 - val_loss: 0.6822 - val_accuracy: 0.5529 - 698ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "100/100 - 1s - loss: 0.6799 - accuracy: 0.5590 - val_loss: 0.6808 - val_accuracy: 0.5603 - 630ms/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "100/100 - 1s - loss: 0.6770 - accuracy: 0.5658 - val_loss: 0.6781 - val_accuracy: 0.5644 - 815ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "100/100 - 1s - loss: 0.6743 - accuracy: 0.5705 - val_loss: 0.6762 - val_accuracy: 0.5710 - 666ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "100/100 - 1s - loss: 0.6720 - accuracy: 0.5751 - val_loss: 0.6729 - val_accuracy: 0.5742 - 688ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "100/100 - 1s - loss: 0.6694 - accuracy: 0.5794 - val_loss: 0.6709 - val_accuracy: 0.5779 - 584ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "100/100 - 1s - loss: 0.6662 - accuracy: 0.5855 - val_loss: 0.6688 - val_accuracy: 0.5808 - 591ms/epoch - 6ms/step\n",
      "Epoch 9/100\n",
      "100/100 - 1s - loss: 0.6628 - accuracy: 0.5894 - val_loss: 0.6664 - val_accuracy: 0.5849 - 594ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "100/100 - 1s - loss: 0.6598 - accuracy: 0.5959 - val_loss: 0.6633 - val_accuracy: 0.5884 - 581ms/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "100/100 - 1s - loss: 0.6567 - accuracy: 0.5989 - val_loss: 0.6615 - val_accuracy: 0.5937 - 585ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "100/100 - 1s - loss: 0.6533 - accuracy: 0.6035 - val_loss: 0.6590 - val_accuracy: 0.5964 - 703ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "100/100 - 1s - loss: 0.6505 - accuracy: 0.6084 - val_loss: 0.6575 - val_accuracy: 0.5989 - 689ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "100/100 - 1s - loss: 0.6480 - accuracy: 0.6117 - val_loss: 0.6561 - val_accuracy: 0.5990 - 578ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "100/100 - 1s - loss: 0.6469 - accuracy: 0.6123 - val_loss: 0.6534 - val_accuracy: 0.6044 - 833ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "100/100 - 1s - loss: 0.6445 - accuracy: 0.6152 - val_loss: 0.6522 - val_accuracy: 0.6055 - 857ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "100/100 - 1s - loss: 0.6408 - accuracy: 0.6196 - val_loss: 0.6504 - val_accuracy: 0.6086 - 855ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "100/100 - 1s - loss: 0.6386 - accuracy: 0.6238 - val_loss: 0.6482 - val_accuracy: 0.6081 - 846ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "100/100 - 1s - loss: 0.6373 - accuracy: 0.6240 - val_loss: 0.6477 - val_accuracy: 0.6115 - 648ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "100/100 - 1s - loss: 0.6345 - accuracy: 0.6287 - val_loss: 0.6470 - val_accuracy: 0.6136 - 872ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "100/100 - 1s - loss: 0.6325 - accuracy: 0.6308 - val_loss: 0.6444 - val_accuracy: 0.6147 - 844ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "100/100 - 1s - loss: 0.6290 - accuracy: 0.6332 - val_loss: 0.6439 - val_accuracy: 0.6149 - 904ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "100/100 - 1s - loss: 0.6302 - accuracy: 0.6331 - val_loss: 0.6428 - val_accuracy: 0.6174 - 809ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "100/100 - 1s - loss: 0.6272 - accuracy: 0.6356 - val_loss: 0.6409 - val_accuracy: 0.6183 - 803ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "100/100 - 1s - loss: 0.6250 - accuracy: 0.6386 - val_loss: 0.6389 - val_accuracy: 0.6208 - 863ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "100/100 - 1s - loss: 0.6234 - accuracy: 0.6388 - val_loss: 0.6371 - val_accuracy: 0.6244 - 846ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "100/100 - 1s - loss: 0.6215 - accuracy: 0.6442 - val_loss: 0.6368 - val_accuracy: 0.6245 - 885ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "100/100 - 1s - loss: 0.6197 - accuracy: 0.6456 - val_loss: 0.6360 - val_accuracy: 0.6233 - 748ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "100/100 - 1s - loss: 0.6194 - accuracy: 0.6454 - val_loss: 0.6350 - val_accuracy: 0.6252 - 872ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "100/100 - 1s - loss: 0.6182 - accuracy: 0.6461 - val_loss: 0.6352 - val_accuracy: 0.6278 - 889ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "100/100 - 1s - loss: 0.6149 - accuracy: 0.6501 - val_loss: 0.6330 - val_accuracy: 0.6289 - 1s/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "100/100 - 1s - loss: 0.6147 - accuracy: 0.6483 - val_loss: 0.6322 - val_accuracy: 0.6293 - 1s/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "100/100 - 1s - loss: 0.6136 - accuracy: 0.6508 - val_loss: 0.6305 - val_accuracy: 0.6324 - 1s/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "100/100 - 1s - loss: 0.6120 - accuracy: 0.6526 - val_loss: 0.6311 - val_accuracy: 0.6317 - 871ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "100/100 - 1s - loss: 0.6102 - accuracy: 0.6544 - val_loss: 0.6310 - val_accuracy: 0.6300 - 895ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "100/100 - 1s - loss: 0.6073 - accuracy: 0.6556 - val_loss: 0.6284 - val_accuracy: 0.6355 - 837ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "100/100 - 1s - loss: 0.6081 - accuracy: 0.6563 - val_loss: 0.6284 - val_accuracy: 0.6343 - 846ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "100/100 - 1s - loss: 0.6049 - accuracy: 0.6610 - val_loss: 0.6268 - val_accuracy: 0.6375 - 883ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "100/100 - 1s - loss: 0.6059 - accuracy: 0.6595 - val_loss: 0.6263 - val_accuracy: 0.6372 - 835ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "100/100 - 1s - loss: 0.6027 - accuracy: 0.6606 - val_loss: 0.6261 - val_accuracy: 0.6367 - 827ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "100/100 - 1s - loss: 0.6041 - accuracy: 0.6595 - val_loss: 0.6245 - val_accuracy: 0.6386 - 765ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "100/100 - 1s - loss: 0.6020 - accuracy: 0.6620 - val_loss: 0.6245 - val_accuracy: 0.6380 - 834ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "100/100 - 1s - loss: 0.6005 - accuracy: 0.6627 - val_loss: 0.6236 - val_accuracy: 0.6389 - 846ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "100/100 - 1s - loss: 0.5993 - accuracy: 0.6650 - val_loss: 0.6229 - val_accuracy: 0.6398 - 823ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "100/100 - 1s - loss: 0.5987 - accuracy: 0.6630 - val_loss: 0.6218 - val_accuracy: 0.6410 - 768ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "100/100 - 1s - loss: 0.5963 - accuracy: 0.6672 - val_loss: 0.6224 - val_accuracy: 0.6377 - 835ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "100/100 - 1s - loss: 0.5975 - accuracy: 0.6669 - val_loss: 0.6224 - val_accuracy: 0.6398 - 833ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "100/100 - 1s - loss: 0.5965 - accuracy: 0.6669 - val_loss: 0.6211 - val_accuracy: 0.6418 - 820ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "100/100 - 1s - loss: 0.5954 - accuracy: 0.6682 - val_loss: 0.6204 - val_accuracy: 0.6425 - 751ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "100/100 - 1s - loss: 0.5950 - accuracy: 0.6683 - val_loss: 0.6202 - val_accuracy: 0.6421 - 866ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "100/100 - 1s - loss: 0.5933 - accuracy: 0.6706 - val_loss: 0.6191 - val_accuracy: 0.6420 - 868ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "100/100 - 1s - loss: 0.5921 - accuracy: 0.6715 - val_loss: 0.6197 - val_accuracy: 0.6431 - 888ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "100/100 - 1s - loss: 0.5933 - accuracy: 0.6678 - val_loss: 0.6180 - val_accuracy: 0.6451 - 897ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "100/100 - 1s - loss: 0.5917 - accuracy: 0.6716 - val_loss: 0.6174 - val_accuracy: 0.6462 - 1s/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "100/100 - 1s - loss: 0.5905 - accuracy: 0.6724 - val_loss: 0.6166 - val_accuracy: 0.6441 - 1s/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "100/100 - 1s - loss: 0.5902 - accuracy: 0.6733 - val_loss: 0.6164 - val_accuracy: 0.6466 - 1s/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "100/100 - 1s - loss: 0.5887 - accuracy: 0.6736 - val_loss: 0.6161 - val_accuracy: 0.6464 - 889ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "100/100 - 1s - loss: 0.5875 - accuracy: 0.6760 - val_loss: 0.6166 - val_accuracy: 0.6481 - 769ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "100/100 - 1s - loss: 0.5895 - accuracy: 0.6739 - val_loss: 0.6162 - val_accuracy: 0.6453 - 853ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "100/100 - 1s - loss: 0.5859 - accuracy: 0.6766 - val_loss: 0.6151 - val_accuracy: 0.6464 - 842ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "100/100 - 1s - loss: 0.5858 - accuracy: 0.6763 - val_loss: 0.6150 - val_accuracy: 0.6485 - 835ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "100/100 - 1s - loss: 0.5856 - accuracy: 0.6773 - val_loss: 0.6154 - val_accuracy: 0.6463 - 765ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "100/100 - 1s - loss: 0.5846 - accuracy: 0.6791 - val_loss: 0.6143 - val_accuracy: 0.6476 - 620ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "100/100 - 1s - loss: 0.5840 - accuracy: 0.6791 - val_loss: 0.6147 - val_accuracy: 0.6463 - 619ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "100/100 - 1s - loss: 0.5835 - accuracy: 0.6796 - val_loss: 0.6139 - val_accuracy: 0.6482 - 645ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "100/100 - 1s - loss: 0.5822 - accuracy: 0.6789 - val_loss: 0.6134 - val_accuracy: 0.6511 - 713ms/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "100/100 - 1s - loss: 0.5822 - accuracy: 0.6792 - val_loss: 0.6118 - val_accuracy: 0.6513 - 587ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "100/100 - 1s - loss: 0.5818 - accuracy: 0.6802 - val_loss: 0.6123 - val_accuracy: 0.6515 - 625ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "100/100 - 1s - loss: 0.5812 - accuracy: 0.6805 - val_loss: 0.6129 - val_accuracy: 0.6503 - 644ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "100/100 - 1s - loss: 0.5796 - accuracy: 0.6815 - val_loss: 0.6125 - val_accuracy: 0.6503 - 641ms/epoch - 6ms/step\n",
      "\n",
      "Training for Fold 5 ...\n",
      "Epoch 1/100\n",
      "100/100 - 1s - loss: 0.6899 - accuracy: 0.5373 - val_loss: 0.6853 - val_accuracy: 0.5476 - 1s/epoch - 15ms/step\n",
      "Epoch 2/100\n",
      "100/100 - 1s - loss: 0.6832 - accuracy: 0.5526 - val_loss: 0.6830 - val_accuracy: 0.5540 - 670ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "100/100 - 1s - loss: 0.6806 - accuracy: 0.5582 - val_loss: 0.6810 - val_accuracy: 0.5556 - 690ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "100/100 - 1s - loss: 0.6778 - accuracy: 0.5655 - val_loss: 0.6788 - val_accuracy: 0.5624 - 612ms/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "100/100 - 1s - loss: 0.6746 - accuracy: 0.5694 - val_loss: 0.6765 - val_accuracy: 0.5677 - 606ms/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "100/100 - 1s - loss: 0.6723 - accuracy: 0.5746 - val_loss: 0.6743 - val_accuracy: 0.5702 - 558ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "100/100 - 1s - loss: 0.6696 - accuracy: 0.5786 - val_loss: 0.6730 - val_accuracy: 0.5775 - 569ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "100/100 - 1s - loss: 0.6662 - accuracy: 0.5859 - val_loss: 0.6710 - val_accuracy: 0.5763 - 576ms/epoch - 6ms/step\n",
      "Epoch 9/100\n",
      "100/100 - 1s - loss: 0.6637 - accuracy: 0.5889 - val_loss: 0.6672 - val_accuracy: 0.5840 - 558ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "100/100 - 1s - loss: 0.6601 - accuracy: 0.5944 - val_loss: 0.6649 - val_accuracy: 0.5873 - 563ms/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "100/100 - 1s - loss: 0.6573 - accuracy: 0.5987 - val_loss: 0.6630 - val_accuracy: 0.5906 - 565ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "100/100 - 1s - loss: 0.6557 - accuracy: 0.6000 - val_loss: 0.6609 - val_accuracy: 0.5944 - 561ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "100/100 - 1s - loss: 0.6522 - accuracy: 0.6063 - val_loss: 0.6590 - val_accuracy: 0.5965 - 565ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "100/100 - 1s - loss: 0.6499 - accuracy: 0.6082 - val_loss: 0.6571 - val_accuracy: 0.6025 - 572ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "100/100 - 1s - loss: 0.6483 - accuracy: 0.6118 - val_loss: 0.6555 - val_accuracy: 0.6027 - 572ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "100/100 - 1s - loss: 0.6452 - accuracy: 0.6143 - val_loss: 0.6529 - val_accuracy: 0.6062 - 559ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "100/100 - 1s - loss: 0.6419 - accuracy: 0.6196 - val_loss: 0.6521 - val_accuracy: 0.6094 - 564ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "100/100 - 1s - loss: 0.6410 - accuracy: 0.6209 - val_loss: 0.6497 - val_accuracy: 0.6114 - 569ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "100/100 - 1s - loss: 0.6382 - accuracy: 0.6255 - val_loss: 0.6480 - val_accuracy: 0.6117 - 564ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "100/100 - 1s - loss: 0.6347 - accuracy: 0.6265 - val_loss: 0.6462 - val_accuracy: 0.6130 - 554ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "100/100 - 1s - loss: 0.6331 - accuracy: 0.6288 - val_loss: 0.6461 - val_accuracy: 0.6171 - 571ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "100/100 - 1s - loss: 0.6314 - accuracy: 0.6305 - val_loss: 0.6450 - val_accuracy: 0.6156 - 636ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "100/100 - 1s - loss: 0.6283 - accuracy: 0.6334 - val_loss: 0.6427 - val_accuracy: 0.6199 - 653ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "100/100 - 1s - loss: 0.6285 - accuracy: 0.6350 - val_loss: 0.6410 - val_accuracy: 0.6209 - 687ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "100/100 - 1s - loss: 0.6266 - accuracy: 0.6377 - val_loss: 0.6405 - val_accuracy: 0.6225 - 779ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "100/100 - 1s - loss: 0.6240 - accuracy: 0.6397 - val_loss: 0.6400 - val_accuracy: 0.6228 - 621ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "100/100 - 1s - loss: 0.6219 - accuracy: 0.6429 - val_loss: 0.6381 - val_accuracy: 0.6255 - 650ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "100/100 - 1s - loss: 0.6212 - accuracy: 0.6420 - val_loss: 0.6385 - val_accuracy: 0.6227 - 631ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "100/100 - 1s - loss: 0.6188 - accuracy: 0.6458 - val_loss: 0.6368 - val_accuracy: 0.6279 - 583ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "100/100 - 1s - loss: 0.6176 - accuracy: 0.6471 - val_loss: 0.6353 - val_accuracy: 0.6273 - 598ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "100/100 - 1s - loss: 0.6166 - accuracy: 0.6478 - val_loss: 0.6357 - val_accuracy: 0.6287 - 678ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "100/100 - 1s - loss: 0.6151 - accuracy: 0.6504 - val_loss: 0.6333 - val_accuracy: 0.6291 - 603ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "100/100 - 1s - loss: 0.6137 - accuracy: 0.6499 - val_loss: 0.6325 - val_accuracy: 0.6304 - 595ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "100/100 - 1s - loss: 0.6103 - accuracy: 0.6556 - val_loss: 0.6331 - val_accuracy: 0.6305 - 633ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "100/100 - 1s - loss: 0.6123 - accuracy: 0.6524 - val_loss: 0.6320 - val_accuracy: 0.6319 - 610ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "100/100 - 1s - loss: 0.6086 - accuracy: 0.6563 - val_loss: 0.6315 - val_accuracy: 0.6328 - 632ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "100/100 - 1s - loss: 0.6079 - accuracy: 0.6559 - val_loss: 0.6301 - val_accuracy: 0.6338 - 643ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "100/100 - 1s - loss: 0.6057 - accuracy: 0.6580 - val_loss: 0.6304 - val_accuracy: 0.6336 - 584ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "100/100 - 1s - loss: 0.6065 - accuracy: 0.6582 - val_loss: 0.6291 - val_accuracy: 0.6341 - 568ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "100/100 - 1s - loss: 0.6041 - accuracy: 0.6591 - val_loss: 0.6284 - val_accuracy: 0.6352 - 615ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "100/100 - 1s - loss: 0.6048 - accuracy: 0.6615 - val_loss: 0.6290 - val_accuracy: 0.6355 - 608ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "100/100 - 1s - loss: 0.6013 - accuracy: 0.6618 - val_loss: 0.6278 - val_accuracy: 0.6360 - 605ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "100/100 - 1s - loss: 0.6010 - accuracy: 0.6648 - val_loss: 0.6276 - val_accuracy: 0.6359 - 631ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "100/100 - 1s - loss: 0.6011 - accuracy: 0.6640 - val_loss: 0.6271 - val_accuracy: 0.6371 - 628ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "100/100 - 1s - loss: 0.5993 - accuracy: 0.6659 - val_loss: 0.6255 - val_accuracy: 0.6389 - 565ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "100/100 - 1s - loss: 0.5990 - accuracy: 0.6648 - val_loss: 0.6252 - val_accuracy: 0.6401 - 613ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "100/100 - 1s - loss: 0.5986 - accuracy: 0.6663 - val_loss: 0.6249 - val_accuracy: 0.6390 - 572ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "100/100 - 1s - loss: 0.5974 - accuracy: 0.6677 - val_loss: 0.6244 - val_accuracy: 0.6397 - 631ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "100/100 - 1s - loss: 0.5949 - accuracy: 0.6687 - val_loss: 0.6226 - val_accuracy: 0.6401 - 608ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "100/100 - 1s - loss: 0.5959 - accuracy: 0.6693 - val_loss: 0.6233 - val_accuracy: 0.6417 - 573ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "100/100 - 1s - loss: 0.5936 - accuracy: 0.6691 - val_loss: 0.6233 - val_accuracy: 0.6412 - 647ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "100/100 - 1s - loss: 0.5935 - accuracy: 0.6709 - val_loss: 0.6224 - val_accuracy: 0.6409 - 616ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "100/100 - 1s - loss: 0.5916 - accuracy: 0.6716 - val_loss: 0.6224 - val_accuracy: 0.6410 - 572ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "100/100 - 1s - loss: 0.5918 - accuracy: 0.6722 - val_loss: 0.6212 - val_accuracy: 0.6426 - 581ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "100/100 - 1s - loss: 0.5919 - accuracy: 0.6725 - val_loss: 0.6208 - val_accuracy: 0.6443 - 580ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "100/100 - 1s - loss: 0.5892 - accuracy: 0.6739 - val_loss: 0.6206 - val_accuracy: 0.6435 - 574ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "100/100 - 1s - loss: 0.5890 - accuracy: 0.6734 - val_loss: 0.6198 - val_accuracy: 0.6428 - 598ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "100/100 - 1s - loss: 0.5885 - accuracy: 0.6753 - val_loss: 0.6194 - val_accuracy: 0.6439 - 633ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "100/100 - 1s - loss: 0.5884 - accuracy: 0.6751 - val_loss: 0.6189 - val_accuracy: 0.6432 - 596ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "100/100 - 1s - loss: 0.5885 - accuracy: 0.6746 - val_loss: 0.6187 - val_accuracy: 0.6452 - 574ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "100/100 - 1s - loss: 0.5870 - accuracy: 0.6775 - val_loss: 0.6191 - val_accuracy: 0.6454 - 592ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "100/100 - 1s - loss: 0.5857 - accuracy: 0.6764 - val_loss: 0.6191 - val_accuracy: 0.6450 - 559ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "100/100 - 1s - loss: 0.5850 - accuracy: 0.6793 - val_loss: 0.6173 - val_accuracy: 0.6472 - 568ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "100/100 - 1s - loss: 0.5833 - accuracy: 0.6795 - val_loss: 0.6177 - val_accuracy: 0.6461 - 584ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "100/100 - 1s - loss: 0.5848 - accuracy: 0.6779 - val_loss: 0.6172 - val_accuracy: 0.6461 - 569ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "100/100 - 1s - loss: 0.5851 - accuracy: 0.6798 - val_loss: 0.6169 - val_accuracy: 0.6478 - 586ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "100/100 - 1s - loss: 0.5831 - accuracy: 0.6809 - val_loss: 0.6166 - val_accuracy: 0.6462 - 626ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "100/100 - 1s - loss: 0.5829 - accuracy: 0.6798 - val_loss: 0.6175 - val_accuracy: 0.6469 - 569ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "100/100 - 1s - loss: 0.5829 - accuracy: 0.6788 - val_loss: 0.6158 - val_accuracy: 0.6484 - 567ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "100/100 - 1s - loss: 0.5826 - accuracy: 0.6796 - val_loss: 0.6159 - val_accuracy: 0.6492 - 574ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "100/100 - 1s - loss: 0.5800 - accuracy: 0.6824 - val_loss: 0.6157 - val_accuracy: 0.6480 - 576ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "100/100 - 1s - loss: 0.5795 - accuracy: 0.6833 - val_loss: 0.6144 - val_accuracy: 0.6509 - 580ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "100/100 - 1s - loss: 0.5799 - accuracy: 0.6828 - val_loss: 0.6144 - val_accuracy: 0.6486 - 563ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "100/100 - 1s - loss: 0.5789 - accuracy: 0.6835 - val_loss: 0.6134 - val_accuracy: 0.6496 - 570ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "100/100 - 1s - loss: 0.5796 - accuracy: 0.6810 - val_loss: 0.6142 - val_accuracy: 0.6496 - 586ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "100/100 - 1s - loss: 0.5776 - accuracy: 0.6854 - val_loss: 0.6137 - val_accuracy: 0.6513 - 558ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "100/100 - 1s - loss: 0.5760 - accuracy: 0.6863 - val_loss: 0.6136 - val_accuracy: 0.6499 - 567ms/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_acc ={}\n",
    "batch_time ={}\n",
    "\n",
    "# Experiment on batch sizes\n",
    "# Iterating through all batch sizes\n",
    "for batch_no in batch_size:\n",
    "    fold_acc = []\n",
    "    fold_time = []\n",
    "    fold_no = 1\n",
    "\n",
    "    print(\"\\n------- Batch Size: \" + str(batch_no) + \" -------\")\n",
    "\n",
    "    # Iterating through each split of training data\n",
    "    for train, test in kfold.split(X_train_scaled, y_train):\n",
    "        print(\"\\nTraining for Fold \" + str(fold_no) + \" ...\")\n",
    "        # define the model\n",
    "        model = Sequential([\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(1, activation='sigmoid'),\n",
    "        ])\n",
    "\n",
    "        # compile the model\n",
    "        model.compile(optimizer= opt,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        # fit the model\n",
    "        history = model.fit(X_train_scaled[train], y_train[train], \n",
    "                            epochs=no_epochs, \n",
    "                            batch_size=batch_no, \n",
    "                            verbose = 2, \n",
    "                            use_multiprocessing=True,\n",
    "                            callbacks=[early_stop, timing_callback],\n",
    "                            validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "        \n",
    "        \n",
    "        # Storing history of every k-fold\n",
    "        time_ = timing_callback.times\n",
    "        acc_ = model.evaluate(X_train_scaled[test], y_train[test], verbose=0)\n",
    "        #print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {acc_[0]}; {model.metrics_names[1]} of {acc_[1]}%')\n",
    "        fold_acc.append(acc_[1])\n",
    "        fold_time.append(time_)\n",
    "        \n",
    "        # increase fold number\n",
    "        fold_no += 1\n",
    "\n",
    "    # Storing history for every batch size\n",
    "    batch_acc[batch_no] = {\"Accuracy\":fold_acc}\n",
    "    batch_time[batch_no] = {\"Time\":fold_time}                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZqoqP9Uc6F3x"
   },
   "outputs": [],
   "source": [
    "batch_size_plot = []\n",
    "mean_accuracy_plot =[]\n",
    "\n",
    "for batch_size, acc in batch_acc.items():\n",
    "  batch_size_acc = acc[\"Accuracy\"]\n",
    "  mean_fold_acc = sum(batch_size_acc)/len(batch_size_acc)\n",
    "\n",
    "  batch_size_plot.append(batch_size)\n",
    "  mean_accuracy_plot.append(mean_fold_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "y-437rRG_IvA",
    "outputId": "8e8666c9-7c27-487a-d9f6-f667a915cd4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Batch size')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(batch_size_plot,mean_accuracy_plot)\n",
    "plt.title('Mean CV accuracies for batch sizes')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Batch size')\n",
    "\n",
    "#plt.savefig('Q2(a)mean cross-validation accuracies.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZgYz7-ZoxEL"
   },
   "source": [
    "### Part b\n",
    "\n",
    "Create a table of time taken to train the network on the last epoch against different batch sizes. (Hint: Introduce a callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "x79cKuNdPZvr"
   },
   "outputs": [],
   "source": [
    "time_taken_fold = []\n",
    "\n",
    "for batch_sizes, data in batch_time.items():\n",
    "  time_taken_per_batch = data[\"Time\"]\n",
    "  i = 1\n",
    "  for time_taken in time_taken_per_batch:\n",
    "    time_taken_fold.append(time_taken[-1])\n",
    "    i+=1\n",
    "\n",
    "#print(time_taken_fold) \n",
    "#print(len(time_taken_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kKzWavw4Wic3"
   },
   "outputs": [],
   "source": [
    "all_time = []\n",
    "\n",
    "time_128 = sum(time_taken_fold[0:5])\n",
    "all_time.append(time_128)\n",
    "\n",
    "time_256 = sum(time_taken_fold[5:10])\n",
    "all_time.append(time_256)\n",
    "\n",
    "time_512 = sum(time_taken_fold[10:15])\n",
    "all_time.append(time_512)\n",
    "\n",
    "time_1024 = sum(time_taken_fold[15:20])\n",
    "all_time.append(time_1024)\n",
    "\n",
    "#print(all_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "t8BSKH8cODgg",
    "outputId": "d1b8b7a2-4b22-45c9-f396-1283c3797cbc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>8.550996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1024</td>\n",
       "      <td>6.418202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024</td>\n",
       "      <td>5.997085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>3.425350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  time_taken\n",
       "0        1024    8.550996\n",
       "1        1024    6.418202\n",
       "2        1024    5.997085\n",
       "3        1024    3.425350"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'batch_size':batch_size , 'time_taken': all_time}\n",
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PA34QRMeo06L"
   },
   "source": [
    "### Part c\n",
    "\n",
    "Select the optimal batch size and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3PJaX20ao8RP"
   },
   "outputs": [],
   "source": [
    "# select optimal batch size\n",
    "\n",
    "# state reason\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IaqUGK2o7E8"
   },
   "source": [
    "### Part d\n",
    "\n",
    "What happens when batch size increases, and why does it happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "u0QuQKsAo_fV"
   },
   "outputs": [],
   "source": [
    "# what happens when batch size increase\n",
    "\n",
    "# why happen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loWSZIzpo_oY"
   },
   "source": [
    "### Part e\n",
    "\n",
    "Plot the train and test accuracies against epochs for the optimal batch size in a line plot.\n",
    "\n",
    "Note: use this optimal batch size for the rest of the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "cW2KXmfApCpo"
   },
   "outputs": [],
   "source": [
    "# optimal batch size\n",
    "batch_size = 128\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "no_epochs = 100\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlFjdqJSRlI9",
    "outputId": "b1a0965c-1fd4-4780-affc-e9458a462c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "997/997 - 3s - loss: 0.6889 - accuracy: 0.5369 - val_loss: 0.6841 - val_accuracy: 0.5513 - 3s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "997/997 - 2s - loss: 0.6826 - accuracy: 0.5547 - val_loss: 0.6815 - val_accuracy: 0.5561 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "997/997 - 3s - loss: 0.6793 - accuracy: 0.5589 - val_loss: 0.6797 - val_accuracy: 0.5614 - 3s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "997/997 - 3s - loss: 0.6772 - accuracy: 0.5645 - val_loss: 0.6756 - val_accuracy: 0.5669 - 3s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "997/997 - 4s - loss: 0.6734 - accuracy: 0.5709 - val_loss: 0.6730 - val_accuracy: 0.5763 - 4s/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "997/997 - 4s - loss: 0.6687 - accuracy: 0.5823 - val_loss: 0.6702 - val_accuracy: 0.5794 - 4s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "997/997 - 3s - loss: 0.6657 - accuracy: 0.5860 - val_loss: 0.6663 - val_accuracy: 0.5880 - 3s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "997/997 - 4s - loss: 0.6608 - accuracy: 0.5942 - val_loss: 0.6641 - val_accuracy: 0.5885 - 4s/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "997/997 - 4s - loss: 0.6565 - accuracy: 0.5991 - val_loss: 0.6606 - val_accuracy: 0.5959 - 4s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "997/997 - 3s - loss: 0.6529 - accuracy: 0.6034 - val_loss: 0.6575 - val_accuracy: 0.6004 - 3s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "997/997 - 4s - loss: 0.6488 - accuracy: 0.6089 - val_loss: 0.6518 - val_accuracy: 0.6065 - 4s/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "997/997 - 4s - loss: 0.6468 - accuracy: 0.6118 - val_loss: 0.6504 - val_accuracy: 0.6067 - 4s/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "997/997 - 4s - loss: 0.6431 - accuracy: 0.6151 - val_loss: 0.6464 - val_accuracy: 0.6119 - 4s/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "997/997 - 4s - loss: 0.6385 - accuracy: 0.6220 - val_loss: 0.6442 - val_accuracy: 0.6163 - 4s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "997/997 - 4s - loss: 0.6365 - accuracy: 0.6228 - val_loss: 0.6421 - val_accuracy: 0.6178 - 4s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "997/997 - 3s - loss: 0.6341 - accuracy: 0.6254 - val_loss: 0.6402 - val_accuracy: 0.6209 - 3s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "997/997 - 4s - loss: 0.6317 - accuracy: 0.6303 - val_loss: 0.6372 - val_accuracy: 0.6246 - 4s/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "997/997 - 4s - loss: 0.6297 - accuracy: 0.6324 - val_loss: 0.6362 - val_accuracy: 0.6266 - 4s/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "997/997 - 4s - loss: 0.6254 - accuracy: 0.6366 - val_loss: 0.6344 - val_accuracy: 0.6296 - 4s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "997/997 - 4s - loss: 0.6235 - accuracy: 0.6389 - val_loss: 0.6311 - val_accuracy: 0.6315 - 4s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "997/997 - 4s - loss: 0.6218 - accuracy: 0.6423 - val_loss: 0.6311 - val_accuracy: 0.6309 - 4s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "997/997 - 4s - loss: 0.6202 - accuracy: 0.6417 - val_loss: 0.6288 - val_accuracy: 0.6349 - 4s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "997/997 - 4s - loss: 0.6185 - accuracy: 0.6443 - val_loss: 0.6281 - val_accuracy: 0.6339 - 4s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "997/997 - 3s - loss: 0.6171 - accuracy: 0.6442 - val_loss: 0.6253 - val_accuracy: 0.6387 - 3s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "997/997 - 3s - loss: 0.6154 - accuracy: 0.6485 - val_loss: 0.6253 - val_accuracy: 0.6388 - 3s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "997/997 - 4s - loss: 0.6128 - accuracy: 0.6501 - val_loss: 0.6227 - val_accuracy: 0.6412 - 4s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "997/997 - 4s - loss: 0.6125 - accuracy: 0.6516 - val_loss: 0.6218 - val_accuracy: 0.6426 - 4s/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "997/997 - 4s - loss: 0.6094 - accuracy: 0.6533 - val_loss: 0.6207 - val_accuracy: 0.6432 - 4s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "997/997 - 4s - loss: 0.6096 - accuracy: 0.6543 - val_loss: 0.6206 - val_accuracy: 0.6429 - 4s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "997/997 - 4s - loss: 0.6078 - accuracy: 0.6556 - val_loss: 0.6187 - val_accuracy: 0.6457 - 4s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "997/997 - 4s - loss: 0.6060 - accuracy: 0.6565 - val_loss: 0.6170 - val_accuracy: 0.6484 - 4s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "997/997 - 4s - loss: 0.6050 - accuracy: 0.6581 - val_loss: 0.6167 - val_accuracy: 0.6480 - 4s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "997/997 - 4s - loss: 0.6042 - accuracy: 0.6588 - val_loss: 0.6153 - val_accuracy: 0.6495 - 4s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "997/997 - 4s - loss: 0.6021 - accuracy: 0.6607 - val_loss: 0.6144 - val_accuracy: 0.6498 - 4s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "997/997 - 4s - loss: 0.6021 - accuracy: 0.6599 - val_loss: 0.6143 - val_accuracy: 0.6504 - 4s/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "997/997 - 4s - loss: 0.6001 - accuracy: 0.6628 - val_loss: 0.6137 - val_accuracy: 0.6524 - 4s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "997/997 - 4s - loss: 0.5983 - accuracy: 0.6641 - val_loss: 0.6110 - val_accuracy: 0.6538 - 4s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "997/997 - 4s - loss: 0.5978 - accuracy: 0.6653 - val_loss: 0.6117 - val_accuracy: 0.6542 - 4s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "997/997 - 4s - loss: 0.5962 - accuracy: 0.6658 - val_loss: 0.6125 - val_accuracy: 0.6542 - 4s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "997/997 - 4s - loss: 0.5949 - accuracy: 0.6669 - val_loss: 0.6103 - val_accuracy: 0.6553 - 4s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "997/997 - 4s - loss: 0.5940 - accuracy: 0.6688 - val_loss: 0.6094 - val_accuracy: 0.6552 - 4s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "997/997 - 4s - loss: 0.5929 - accuracy: 0.6701 - val_loss: 0.6099 - val_accuracy: 0.6580 - 4s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "997/997 - 4s - loss: 0.5932 - accuracy: 0.6712 - val_loss: 0.6084 - val_accuracy: 0.6574 - 4s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "997/997 - 4s - loss: 0.5911 - accuracy: 0.6712 - val_loss: 0.6073 - val_accuracy: 0.6601 - 4s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "997/997 - 4s - loss: 0.5912 - accuracy: 0.6713 - val_loss: 0.6061 - val_accuracy: 0.6582 - 4s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "997/997 - 4s - loss: 0.5907 - accuracy: 0.6706 - val_loss: 0.6064 - val_accuracy: 0.6610 - 4s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "997/997 - 4s - loss: 0.5898 - accuracy: 0.6734 - val_loss: 0.6062 - val_accuracy: 0.6594 - 4s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "997/997 - 4s - loss: 0.5880 - accuracy: 0.6755 - val_loss: 0.6055 - val_accuracy: 0.6599 - 4s/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "997/997 - 4s - loss: 0.5864 - accuracy: 0.6752 - val_loss: 0.6021 - val_accuracy: 0.6631 - 4s/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "997/997 - 4s - loss: 0.5870 - accuracy: 0.6755 - val_loss: 0.6025 - val_accuracy: 0.6636 - 4s/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "997/997 - 4s - loss: 0.5852 - accuracy: 0.6774 - val_loss: 0.6027 - val_accuracy: 0.6673 - 4s/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "997/997 - 4s - loss: 0.5862 - accuracy: 0.6766 - val_loss: 0.6038 - val_accuracy: 0.6621 - 4s/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#define the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer= opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "          epochs=no_epochs, \n",
    "          batch_size=batch_size, \n",
    "          verbose = 2, \n",
    "          use_multiprocessing=True,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(X_test_scaled, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "FFwmi_z3RlTI",
    "outputId": "97658826-c57a-4842-c553-903e06de9393"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x225bb82e070>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test accuracies\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for batch size 128')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train accuracy', 'Test accuracy'], loc='upper left')\n",
    "\n",
    "#plt.savefig('Q1(e)accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgCivYfMbuq8"
   },
   "source": [
    "## Question 3\n",
    "\n",
    "Find the optimal number of hidden neurons for first hidden layer of the 5-layer network (input layer, 3 hidden layers, output layer) designed in Question 1 and 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbOR85uRbzuN"
   },
   "source": [
    "### Part a\n",
    "\n",
    "Plot the mean cross-validation accuracies on the final epoch for different numbers of hidden-layer neurons using a scatter plot. Limit the search space of the number of neurons to {64, 128, 256}.\n",
    "\n",
    "Continue using 5-fold cross validation on training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "kwztOFcVby83"
   },
   "outputs": [],
   "source": [
    "hidden_neurons = [64, 128, 256]\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "no_epochs = 100\n",
    "batch_size = 128\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "no_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "dv4Xwp4LfiUi"
   },
   "outputs": [],
   "source": [
    "# 5-fold cross-validation on training partition\n",
    "kfold = KFold(n_splits=no_folds, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "lawZ1MgKfib0",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "291e6dd1-90f3-4652-dca4-4a9dd6c850fe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- Batch Size: 1024 -------\n",
      "\n",
      "Training for Fold 1 ...\n",
      "Epoch 1/100\n",
      "798/798 - 4s - loss: 0.6909 - accuracy: 0.5346 - val_loss: 0.6858 - val_accuracy: 0.5441 - 4s/epoch - 6ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 3s - loss: 0.6850 - accuracy: 0.5486 - val_loss: 0.6842 - val_accuracy: 0.5500 - 3s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 3s - loss: 0.6826 - accuracy: 0.5519 - val_loss: 0.6826 - val_accuracy: 0.5550 - 3s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 3s - loss: 0.6803 - accuracy: 0.5594 - val_loss: 0.6800 - val_accuracy: 0.5582 - 3s/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 3s - loss: 0.6786 - accuracy: 0.5623 - val_loss: 0.6794 - val_accuracy: 0.5600 - 3s/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 3s - loss: 0.6764 - accuracy: 0.5683 - val_loss: 0.6767 - val_accuracy: 0.5713 - 3s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 3s - loss: 0.6745 - accuracy: 0.5709 - val_loss: 0.6753 - val_accuracy: 0.5695 - 3s/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 3s - loss: 0.6722 - accuracy: 0.5748 - val_loss: 0.6733 - val_accuracy: 0.5703 - 3s/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 3s - loss: 0.6707 - accuracy: 0.5770 - val_loss: 0.6721 - val_accuracy: 0.5756 - 3s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 3s - loss: 0.6678 - accuracy: 0.5830 - val_loss: 0.6711 - val_accuracy: 0.5785 - 3s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 3s - loss: 0.6667 - accuracy: 0.5849 - val_loss: 0.6690 - val_accuracy: 0.5800 - 3s/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 3s - loss: 0.6644 - accuracy: 0.5881 - val_loss: 0.6668 - val_accuracy: 0.5856 - 3s/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 3s - loss: 0.6625 - accuracy: 0.5927 - val_loss: 0.6649 - val_accuracy: 0.5887 - 3s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 3s - loss: 0.6603 - accuracy: 0.5932 - val_loss: 0.6647 - val_accuracy: 0.5877 - 3s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 3s - loss: 0.6584 - accuracy: 0.5967 - val_loss: 0.6622 - val_accuracy: 0.5941 - 3s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 3s - loss: 0.6569 - accuracy: 0.6012 - val_loss: 0.6610 - val_accuracy: 0.5960 - 3s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 3s - loss: 0.6554 - accuracy: 0.6027 - val_loss: 0.6599 - val_accuracy: 0.5982 - 3s/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 3s - loss: 0.6556 - accuracy: 0.6006 - val_loss: 0.6594 - val_accuracy: 0.5972 - 3s/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 3s - loss: 0.6541 - accuracy: 0.6032 - val_loss: 0.6588 - val_accuracy: 0.5992 - 3s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 3s - loss: 0.6527 - accuracy: 0.6054 - val_loss: 0.6578 - val_accuracy: 0.5984 - 3s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 3s - loss: 0.6508 - accuracy: 0.6087 - val_loss: 0.6566 - val_accuracy: 0.6020 - 3s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 3s - loss: 0.6501 - accuracy: 0.6095 - val_loss: 0.6548 - val_accuracy: 0.6028 - 3s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 3s - loss: 0.6481 - accuracy: 0.6109 - val_loss: 0.6551 - val_accuracy: 0.6008 - 3s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 3s - loss: 0.6472 - accuracy: 0.6124 - val_loss: 0.6538 - val_accuracy: 0.6027 - 3s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 3s - loss: 0.6462 - accuracy: 0.6141 - val_loss: 0.6537 - val_accuracy: 0.6082 - 3s/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 3s - loss: 0.6459 - accuracy: 0.6146 - val_loss: 0.6525 - val_accuracy: 0.6076 - 3s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 3s - loss: 0.6445 - accuracy: 0.6165 - val_loss: 0.6517 - val_accuracy: 0.6082 - 3s/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 3s - loss: 0.6441 - accuracy: 0.6153 - val_loss: 0.6512 - val_accuracy: 0.6105 - 3s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 3s - loss: 0.6433 - accuracy: 0.6170 - val_loss: 0.6496 - val_accuracy: 0.6118 - 3s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 3s - loss: 0.6423 - accuracy: 0.6206 - val_loss: 0.6495 - val_accuracy: 0.6111 - 3s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 3s - loss: 0.6423 - accuracy: 0.6203 - val_loss: 0.6492 - val_accuracy: 0.6130 - 3s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 3s - loss: 0.6404 - accuracy: 0.6211 - val_loss: 0.6491 - val_accuracy: 0.6128 - 3s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 3s - loss: 0.6401 - accuracy: 0.6221 - val_loss: 0.6474 - val_accuracy: 0.6125 - 3s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6401 - accuracy: 0.6211 - val_loss: 0.6488 - val_accuracy: 0.6118 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6378 - accuracy: 0.6240 - val_loss: 0.6462 - val_accuracy: 0.6126 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6390 - accuracy: 0.6235 - val_loss: 0.6460 - val_accuracy: 0.6143 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.6363 - accuracy: 0.6254 - val_loss: 0.6463 - val_accuracy: 0.6160 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.6366 - accuracy: 0.6270 - val_loss: 0.6453 - val_accuracy: 0.6168 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.6349 - accuracy: 0.6267 - val_loss: 0.6446 - val_accuracy: 0.6176 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.6363 - accuracy: 0.6285 - val_loss: 0.6445 - val_accuracy: 0.6204 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.6341 - accuracy: 0.6276 - val_loss: 0.6448 - val_accuracy: 0.6182 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.6324 - accuracy: 0.6303 - val_loss: 0.6444 - val_accuracy: 0.6183 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.6344 - accuracy: 0.6293 - val_loss: 0.6421 - val_accuracy: 0.6189 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.6333 - accuracy: 0.6292 - val_loss: 0.6425 - val_accuracy: 0.6198 - 2s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.6308 - accuracy: 0.6342 - val_loss: 0.6430 - val_accuracy: 0.6163 - 2s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.6335 - accuracy: 0.6292 - val_loss: 0.6414 - val_accuracy: 0.6203 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.6311 - accuracy: 0.6315 - val_loss: 0.6416 - val_accuracy: 0.6206 - 2s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.6303 - accuracy: 0.6335 - val_loss: 0.6409 - val_accuracy: 0.6209 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.6304 - accuracy: 0.6328 - val_loss: 0.6403 - val_accuracy: 0.6227 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.6309 - accuracy: 0.6329 - val_loss: 0.6402 - val_accuracy: 0.6206 - 2s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 2s - loss: 0.6302 - accuracy: 0.6329 - val_loss: 0.6398 - val_accuracy: 0.6224 - 2s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "798/798 - 2s - loss: 0.6287 - accuracy: 0.6332 - val_loss: 0.6397 - val_accuracy: 0.6207 - 2s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "798/798 - 2s - loss: 0.6286 - accuracy: 0.6374 - val_loss: 0.6385 - val_accuracy: 0.6236 - 2s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "798/798 - 2s - loss: 0.6292 - accuracy: 0.6346 - val_loss: 0.6396 - val_accuracy: 0.6245 - 2s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "798/798 - 2s - loss: 0.6270 - accuracy: 0.6381 - val_loss: 0.6385 - val_accuracy: 0.6235 - 2s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "798/798 - 2s - loss: 0.6266 - accuracy: 0.6366 - val_loss: 0.6386 - val_accuracy: 0.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "798/798 - 2s - loss: 0.6270 - accuracy: 0.6380 - val_loss: 0.6372 - val_accuracy: 0.6272 - 2s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "798/798 - 2s - loss: 0.6267 - accuracy: 0.6393 - val_loss: 0.6373 - val_accuracy: 0.6255 - 2s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "798/798 - 2s - loss: 0.6260 - accuracy: 0.6367 - val_loss: 0.6381 - val_accuracy: 0.6247 - 2s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "798/798 - 2s - loss: 0.6259 - accuracy: 0.6395 - val_loss: 0.6378 - val_accuracy: 0.6258 - 2s/epoch - 2ms/step\n",
      "Score for fold 1: loss of 0.6360634565353394; accuracy of 0.6264304518699646%\n",
      "\n",
      "Training for Fold 2 ...\n",
      "Epoch 1/100\n",
      "798/798 - 3s - loss: 0.6882 - accuracy: 0.5421 - val_loss: 0.6850 - val_accuracy: 0.5500 - 3s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6832 - accuracy: 0.5534 - val_loss: 0.6819 - val_accuracy: 0.5528 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6806 - accuracy: 0.5576 - val_loss: 0.6806 - val_accuracy: 0.5562 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6782 - accuracy: 0.5644 - val_loss: 0.6797 - val_accuracy: 0.5598 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6758 - accuracy: 0.5684 - val_loss: 0.6772 - val_accuracy: 0.5674 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6736 - accuracy: 0.5712 - val_loss: 0.6747 - val_accuracy: 0.5732 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6713 - accuracy: 0.5778 - val_loss: 0.6728 - val_accuracy: 0.5753 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6696 - accuracy: 0.5812 - val_loss: 0.6710 - val_accuracy: 0.5800 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6671 - accuracy: 0.5850 - val_loss: 0.6701 - val_accuracy: 0.5815 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6641 - accuracy: 0.5912 - val_loss: 0.6678 - val_accuracy: 0.5847 - 2s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6631 - accuracy: 0.5924 - val_loss: 0.6665 - val_accuracy: 0.5872 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6606 - accuracy: 0.5941 - val_loss: 0.6657 - val_accuracy: 0.5868 - 2s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6595 - accuracy: 0.5977 - val_loss: 0.6650 - val_accuracy: 0.5910 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6578 - accuracy: 0.5983 - val_loss: 0.6621 - val_accuracy: 0.5922 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6569 - accuracy: 0.6005 - val_loss: 0.6620 - val_accuracy: 0.5921 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6543 - accuracy: 0.6032 - val_loss: 0.6606 - val_accuracy: 0.5959 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6531 - accuracy: 0.6051 - val_loss: 0.6590 - val_accuracy: 0.5972 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6528 - accuracy: 0.6067 - val_loss: 0.6588 - val_accuracy: 0.5971 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6506 - accuracy: 0.6093 - val_loss: 0.6578 - val_accuracy: 0.5991 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6493 - accuracy: 0.6108 - val_loss: 0.6560 - val_accuracy: 0.6017 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6481 - accuracy: 0.6122 - val_loss: 0.6547 - val_accuracy: 0.6038 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6464 - accuracy: 0.6139 - val_loss: 0.6556 - val_accuracy: 0.6053 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6456 - accuracy: 0.6146 - val_loss: 0.6527 - val_accuracy: 0.6048 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6453 - accuracy: 0.6145 - val_loss: 0.6530 - val_accuracy: 0.6050 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6441 - accuracy: 0.6169 - val_loss: 0.6518 - val_accuracy: 0.6054 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6420 - accuracy: 0.6203 - val_loss: 0.6510 - val_accuracy: 0.6085 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6416 - accuracy: 0.6214 - val_loss: 0.6511 - val_accuracy: 0.6080 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6400 - accuracy: 0.6233 - val_loss: 0.6493 - val_accuracy: 0.6120 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6399 - accuracy: 0.6226 - val_loss: 0.6497 - val_accuracy: 0.6121 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6391 - accuracy: 0.6241 - val_loss: 0.6493 - val_accuracy: 0.6126 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6392 - accuracy: 0.6234 - val_loss: 0.6482 - val_accuracy: 0.6113 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6375 - accuracy: 0.6252 - val_loss: 0.6466 - val_accuracy: 0.6157 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6364 - accuracy: 0.6244 - val_loss: 0.6463 - val_accuracy: 0.6138 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6372 - accuracy: 0.6264 - val_loss: 0.6474 - val_accuracy: 0.6151 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6364 - accuracy: 0.6263 - val_loss: 0.6479 - val_accuracy: 0.6142 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6347 - accuracy: 0.6277 - val_loss: 0.6462 - val_accuracy: 0.6167 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.6340 - accuracy: 0.6280 - val_loss: 0.6463 - val_accuracy: 0.6149 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.6323 - accuracy: 0.6330 - val_loss: 0.6454 - val_accuracy: 0.6167 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.6319 - accuracy: 0.6309 - val_loss: 0.6446 - val_accuracy: 0.6178 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.6314 - accuracy: 0.6311 - val_loss: 0.6434 - val_accuracy: 0.6168 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.6319 - accuracy: 0.6310 - val_loss: 0.6451 - val_accuracy: 0.6187 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.6303 - accuracy: 0.6330 - val_loss: 0.6437 - val_accuracy: 0.6183 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.6313 - accuracy: 0.6323 - val_loss: 0.6420 - val_accuracy: 0.6212 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.6299 - accuracy: 0.6335 - val_loss: 0.6408 - val_accuracy: 0.6214 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.6284 - accuracy: 0.6342 - val_loss: 0.6405 - val_accuracy: 0.6203 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.6279 - accuracy: 0.6365 - val_loss: 0.6412 - val_accuracy: 0.6206 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.6274 - accuracy: 0.6353 - val_loss: 0.6413 - val_accuracy: 0.6216 - 2s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.6261 - accuracy: 0.6378 - val_loss: 0.6419 - val_accuracy: 0.6218 - 2s/epoch - 2ms/step\n",
      "Score for fold 2: loss of 0.6415600180625916; accuracy of 0.6195328235626221%\n",
      "\n",
      "Training for Fold 3 ...\n",
      "Epoch 1/100\n",
      "798/798 - 2s - loss: 0.6888 - accuracy: 0.5378 - val_loss: 0.6854 - val_accuracy: 0.5469 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6834 - accuracy: 0.5508 - val_loss: 0.6845 - val_accuracy: 0.5537 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6813 - accuracy: 0.5557 - val_loss: 0.6808 - val_accuracy: 0.5566 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6795 - accuracy: 0.5574 - val_loss: 0.6805 - val_accuracy: 0.5605 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6773 - accuracy: 0.5633 - val_loss: 0.6786 - val_accuracy: 0.5635 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6754 - accuracy: 0.5664 - val_loss: 0.6759 - val_accuracy: 0.5676 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6736 - accuracy: 0.5701 - val_loss: 0.6763 - val_accuracy: 0.5704 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6711 - accuracy: 0.5735 - val_loss: 0.6724 - val_accuracy: 0.5734 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6694 - accuracy: 0.5776 - val_loss: 0.6727 - val_accuracy: 0.5729 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6674 - accuracy: 0.5827 - val_loss: 0.6710 - val_accuracy: 0.5766 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6654 - accuracy: 0.5857 - val_loss: 0.6704 - val_accuracy: 0.5775 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6630 - accuracy: 0.5895 - val_loss: 0.6677 - val_accuracy: 0.5824 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6614 - accuracy: 0.5916 - val_loss: 0.6671 - val_accuracy: 0.5822 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6596 - accuracy: 0.5934 - val_loss: 0.6663 - val_accuracy: 0.5869 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6581 - accuracy: 0.5967 - val_loss: 0.6641 - val_accuracy: 0.5895 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6566 - accuracy: 0.6000 - val_loss: 0.6615 - val_accuracy: 0.5917 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6558 - accuracy: 0.6010 - val_loss: 0.6616 - val_accuracy: 0.5926 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6551 - accuracy: 0.6014 - val_loss: 0.6606 - val_accuracy: 0.5937 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6532 - accuracy: 0.6015 - val_loss: 0.6584 - val_accuracy: 0.5962 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6514 - accuracy: 0.6066 - val_loss: 0.6592 - val_accuracy: 0.5958 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6506 - accuracy: 0.6046 - val_loss: 0.6585 - val_accuracy: 0.5989 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6491 - accuracy: 0.6090 - val_loss: 0.6579 - val_accuracy: 0.5952 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6487 - accuracy: 0.6105 - val_loss: 0.6561 - val_accuracy: 0.6002 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6468 - accuracy: 0.6117 - val_loss: 0.6553 - val_accuracy: 0.6011 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6470 - accuracy: 0.6117 - val_loss: 0.6539 - val_accuracy: 0.6034 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6457 - accuracy: 0.6136 - val_loss: 0.6550 - val_accuracy: 0.6022 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6453 - accuracy: 0.6150 - val_loss: 0.6526 - val_accuracy: 0.6041 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6437 - accuracy: 0.6174 - val_loss: 0.6541 - val_accuracy: 0.6033 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6435 - accuracy: 0.6170 - val_loss: 0.6530 - val_accuracy: 0.6043 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6424 - accuracy: 0.6176 - val_loss: 0.6512 - val_accuracy: 0.6082 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6399 - accuracy: 0.6225 - val_loss: 0.6508 - val_accuracy: 0.6078 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6399 - accuracy: 0.6209 - val_loss: 0.6507 - val_accuracy: 0.6092 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6401 - accuracy: 0.6195 - val_loss: 0.6500 - val_accuracy: 0.6082 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6381 - accuracy: 0.6230 - val_loss: 0.6499 - val_accuracy: 0.6095 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6376 - accuracy: 0.6234 - val_loss: 0.6499 - val_accuracy: 0.6078 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6373 - accuracy: 0.6236 - val_loss: 0.6471 - val_accuracy: 0.6140 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.6363 - accuracy: 0.6258 - val_loss: 0.6480 - val_accuracy: 0.6148 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.6353 - accuracy: 0.6279 - val_loss: 0.6467 - val_accuracy: 0.6123 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.6357 - accuracy: 0.6276 - val_loss: 0.6467 - val_accuracy: 0.6130 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.6350 - accuracy: 0.6281 - val_loss: 0.6472 - val_accuracy: 0.6139 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.6341 - accuracy: 0.6267 - val_loss: 0.6466 - val_accuracy: 0.6153 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.6339 - accuracy: 0.6271 - val_loss: 0.6455 - val_accuracy: 0.6149 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.6334 - accuracy: 0.6288 - val_loss: 0.6462 - val_accuracy: 0.6153 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.6328 - accuracy: 0.6301 - val_loss: 0.6438 - val_accuracy: 0.6183 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.6328 - accuracy: 0.6294 - val_loss: 0.6439 - val_accuracy: 0.6176 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.6311 - accuracy: 0.6330 - val_loss: 0.6445 - val_accuracy: 0.6161 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.6314 - accuracy: 0.6318 - val_loss: 0.6431 - val_accuracy: 0.6166 - 2s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.6313 - accuracy: 0.6295 - val_loss: 0.6423 - val_accuracy: 0.6189 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.6305 - accuracy: 0.6329 - val_loss: 0.6435 - val_accuracy: 0.6180 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.6281 - accuracy: 0.6374 - val_loss: 0.6438 - val_accuracy: 0.6167 - 2s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 3s - loss: 0.6292 - accuracy: 0.6344 - val_loss: 0.6424 - val_accuracy: 0.6184 - 3s/epoch - 3ms/step\n",
      "Score for fold 3: loss of 0.6407345533370972; accuracy of 0.6228101253509521%\n",
      "\n",
      "Training for Fold 4 ...\n",
      "Epoch 1/100\n",
      "798/798 - 2s - loss: 0.6887 - accuracy: 0.5357 - val_loss: 0.6854 - val_accuracy: 0.5509 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6838 - accuracy: 0.5498 - val_loss: 0.6844 - val_accuracy: 0.5480 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6814 - accuracy: 0.5561 - val_loss: 0.6814 - val_accuracy: 0.5596 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6792 - accuracy: 0.5598 - val_loss: 0.6800 - val_accuracy: 0.5591 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6772 - accuracy: 0.5641 - val_loss: 0.6786 - val_accuracy: 0.5619 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6752 - accuracy: 0.5677 - val_loss: 0.6767 - val_accuracy: 0.5662 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6732 - accuracy: 0.5709 - val_loss: 0.6753 - val_accuracy: 0.5699 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6710 - accuracy: 0.5772 - val_loss: 0.6734 - val_accuracy: 0.5729 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6690 - accuracy: 0.5782 - val_loss: 0.6723 - val_accuracy: 0.5777 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6673 - accuracy: 0.5828 - val_loss: 0.6706 - val_accuracy: 0.5793 - 2s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6651 - accuracy: 0.5852 - val_loss: 0.6705 - val_accuracy: 0.5806 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6635 - accuracy: 0.5882 - val_loss: 0.6673 - val_accuracy: 0.5871 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6620 - accuracy: 0.5905 - val_loss: 0.6669 - val_accuracy: 0.5875 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6602 - accuracy: 0.5937 - val_loss: 0.6642 - val_accuracy: 0.5904 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6582 - accuracy: 0.5971 - val_loss: 0.6626 - val_accuracy: 0.5939 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6565 - accuracy: 0.5991 - val_loss: 0.6620 - val_accuracy: 0.5924 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6559 - accuracy: 0.5999 - val_loss: 0.6608 - val_accuracy: 0.5965 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6537 - accuracy: 0.6044 - val_loss: 0.6608 - val_accuracy: 0.5966 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6529 - accuracy: 0.6054 - val_loss: 0.6581 - val_accuracy: 0.6013 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6515 - accuracy: 0.6077 - val_loss: 0.6569 - val_accuracy: 0.6002 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6496 - accuracy: 0.6109 - val_loss: 0.6562 - val_accuracy: 0.6018 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6487 - accuracy: 0.6103 - val_loss: 0.6565 - val_accuracy: 0.5989 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6478 - accuracy: 0.6114 - val_loss: 0.6554 - val_accuracy: 0.6035 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6468 - accuracy: 0.6142 - val_loss: 0.6542 - val_accuracy: 0.6049 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6459 - accuracy: 0.6156 - val_loss: 0.6527 - val_accuracy: 0.6088 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6444 - accuracy: 0.6177 - val_loss: 0.6520 - val_accuracy: 0.6103 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6448 - accuracy: 0.6157 - val_loss: 0.6509 - val_accuracy: 0.6100 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6430 - accuracy: 0.6197 - val_loss: 0.6506 - val_accuracy: 0.6097 - 2s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6425 - accuracy: 0.6178 - val_loss: 0.6522 - val_accuracy: 0.6106 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6400 - accuracy: 0.6216 - val_loss: 0.6494 - val_accuracy: 0.6117 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6401 - accuracy: 0.6235 - val_loss: 0.6485 - val_accuracy: 0.6124 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6384 - accuracy: 0.6233 - val_loss: 0.6484 - val_accuracy: 0.6135 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6386 - accuracy: 0.6244 - val_loss: 0.6478 - val_accuracy: 0.6142 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6370 - accuracy: 0.6240 - val_loss: 0.6465 - val_accuracy: 0.6153 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6371 - accuracy: 0.6270 - val_loss: 0.6452 - val_accuracy: 0.6165 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6372 - accuracy: 0.6263 - val_loss: 0.6460 - val_accuracy: 0.6169 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.6360 - accuracy: 0.6277 - val_loss: 0.6443 - val_accuracy: 0.6170 - 2s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.6347 - accuracy: 0.6277 - val_loss: 0.6450 - val_accuracy: 0.6151 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.6340 - accuracy: 0.6273 - val_loss: 0.6445 - val_accuracy: 0.6182 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.6344 - accuracy: 0.6309 - val_loss: 0.6427 - val_accuracy: 0.6199 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.6350 - accuracy: 0.6278 - val_loss: 0.6431 - val_accuracy: 0.6217 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.6336 - accuracy: 0.6295 - val_loss: 0.6429 - val_accuracy: 0.6187 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.6320 - accuracy: 0.6307 - val_loss: 0.6431 - val_accuracy: 0.6165 - 2s/epoch - 2ms/step\n",
      "Score for fold 4: loss of 0.643231987953186; accuracy of 0.6181461811065674%\n",
      "\n",
      "Training for Fold 5 ...\n",
      "Epoch 1/100\n",
      "798/798 - 2s - loss: 0.6886 - accuracy: 0.5404 - val_loss: 0.6845 - val_accuracy: 0.5486 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6834 - accuracy: 0.5527 - val_loss: 0.6825 - val_accuracy: 0.5558 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6802 - accuracy: 0.5596 - val_loss: 0.6810 - val_accuracy: 0.5583 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6780 - accuracy: 0.5645 - val_loss: 0.6793 - val_accuracy: 0.5594 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6762 - accuracy: 0.5697 - val_loss: 0.6765 - val_accuracy: 0.5640 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6735 - accuracy: 0.5722 - val_loss: 0.6757 - val_accuracy: 0.5686 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6714 - accuracy: 0.5760 - val_loss: 0.6738 - val_accuracy: 0.5718 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6692 - accuracy: 0.5795 - val_loss: 0.6720 - val_accuracy: 0.5724 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6669 - accuracy: 0.5829 - val_loss: 0.6703 - val_accuracy: 0.5788 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6640 - accuracy: 0.5884 - val_loss: 0.6677 - val_accuracy: 0.5833 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6624 - accuracy: 0.5904 - val_loss: 0.6664 - val_accuracy: 0.5854 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6604 - accuracy: 0.5937 - val_loss: 0.6646 - val_accuracy: 0.5875 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6574 - accuracy: 0.5995 - val_loss: 0.6630 - val_accuracy: 0.5898 - 2s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6577 - accuracy: 0.5971 - val_loss: 0.6641 - val_accuracy: 0.5866 - 2s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6561 - accuracy: 0.6005 - val_loss: 0.6610 - val_accuracy: 0.5948 - 2s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6538 - accuracy: 0.6020 - val_loss: 0.6595 - val_accuracy: 0.5947 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6525 - accuracy: 0.6056 - val_loss: 0.6586 - val_accuracy: 0.5979 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6514 - accuracy: 0.6057 - val_loss: 0.6584 - val_accuracy: 0.5988 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6494 - accuracy: 0.6077 - val_loss: 0.6563 - val_accuracy: 0.5999 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6476 - accuracy: 0.6103 - val_loss: 0.6554 - val_accuracy: 0.6011 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6480 - accuracy: 0.6117 - val_loss: 0.6547 - val_accuracy: 0.6019 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6465 - accuracy: 0.6156 - val_loss: 0.6532 - val_accuracy: 0.6029 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6453 - accuracy: 0.6146 - val_loss: 0.6534 - val_accuracy: 0.6074 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6430 - accuracy: 0.6169 - val_loss: 0.6513 - val_accuracy: 0.6075 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6437 - accuracy: 0.6154 - val_loss: 0.6496 - val_accuracy: 0.6091 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6411 - accuracy: 0.6172 - val_loss: 0.6514 - val_accuracy: 0.6100 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6405 - accuracy: 0.6212 - val_loss: 0.6496 - val_accuracy: 0.6123 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6394 - accuracy: 0.6220 - val_loss: 0.6481 - val_accuracy: 0.6125 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6379 - accuracy: 0.6241 - val_loss: 0.6478 - val_accuracy: 0.6126 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6380 - accuracy: 0.6232 - val_loss: 0.6482 - val_accuracy: 0.6103 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6368 - accuracy: 0.6252 - val_loss: 0.6461 - val_accuracy: 0.6118 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6352 - accuracy: 0.6269 - val_loss: 0.6450 - val_accuracy: 0.6152 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6358 - accuracy: 0.6265 - val_loss: 0.6447 - val_accuracy: 0.6174 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6340 - accuracy: 0.6283 - val_loss: 0.6447 - val_accuracy: 0.6153 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6342 - accuracy: 0.6272 - val_loss: 0.6455 - val_accuracy: 0.6168 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6330 - accuracy: 0.6282 - val_loss: 0.6449 - val_accuracy: 0.6173 - 2s/epoch - 2ms/step\n",
      "Score for fold 5: loss of 0.6442761421203613; accuracy of 0.6200274229049683%\n",
      "\n",
      "------- Batch Size: 1024 -------\n",
      "\n",
      "Training for Fold 1 ...\n",
      "Epoch 1/100\n",
      "798/798 - 3s - loss: 0.6887 - accuracy: 0.5395 - val_loss: 0.6846 - val_accuracy: 0.5471 - 3s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6827 - accuracy: 0.5523 - val_loss: 0.6834 - val_accuracy: 0.5515 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6799 - accuracy: 0.5589 - val_loss: 0.6803 - val_accuracy: 0.5571 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6772 - accuracy: 0.5659 - val_loss: 0.6774 - val_accuracy: 0.5644 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6742 - accuracy: 0.5712 - val_loss: 0.6767 - val_accuracy: 0.5673 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6711 - accuracy: 0.5751 - val_loss: 0.6732 - val_accuracy: 0.5730 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6680 - accuracy: 0.5822 - val_loss: 0.6705 - val_accuracy: 0.5765 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6642 - accuracy: 0.5877 - val_loss: 0.6679 - val_accuracy: 0.5820 - 2s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6612 - accuracy: 0.5920 - val_loss: 0.6642 - val_accuracy: 0.5887 - 2s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6569 - accuracy: 0.5948 - val_loss: 0.6626 - val_accuracy: 0.5905 - 2s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6539 - accuracy: 0.6008 - val_loss: 0.6597 - val_accuracy: 0.5948 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 3s - loss: 0.6495 - accuracy: 0.6057 - val_loss: 0.6571 - val_accuracy: 0.5986 - 3s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6470 - accuracy: 0.6089 - val_loss: 0.6551 - val_accuracy: 0.5999 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6436 - accuracy: 0.6142 - val_loss: 0.6530 - val_accuracy: 0.6027 - 2s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6417 - accuracy: 0.6166 - val_loss: 0.6510 - val_accuracy: 0.6068 - 2s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6382 - accuracy: 0.6220 - val_loss: 0.6489 - val_accuracy: 0.6078 - 2s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6358 - accuracy: 0.6243 - val_loss: 0.6470 - val_accuracy: 0.6103 - 2s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6325 - accuracy: 0.6270 - val_loss: 0.6469 - val_accuracy: 0.6094 - 2s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6312 - accuracy: 0.6293 - val_loss: 0.6442 - val_accuracy: 0.6159 - 2s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6291 - accuracy: 0.6303 - val_loss: 0.6431 - val_accuracy: 0.6154 - 2s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6278 - accuracy: 0.6322 - val_loss: 0.6412 - val_accuracy: 0.6203 - 2s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6239 - accuracy: 0.6357 - val_loss: 0.6391 - val_accuracy: 0.6181 - 2s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6233 - accuracy: 0.6366 - val_loss: 0.6392 - val_accuracy: 0.6187 - 2s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6210 - accuracy: 0.6395 - val_loss: 0.6360 - val_accuracy: 0.6253 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6203 - accuracy: 0.6393 - val_loss: 0.6364 - val_accuracy: 0.6244 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6176 - accuracy: 0.6426 - val_loss: 0.6337 - val_accuracy: 0.6264 - 2s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6169 - accuracy: 0.6450 - val_loss: 0.6338 - val_accuracy: 0.6261 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6160 - accuracy: 0.6463 - val_loss: 0.6323 - val_accuracy: 0.6311 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6124 - accuracy: 0.6482 - val_loss: 0.6312 - val_accuracy: 0.6320 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6117 - accuracy: 0.6502 - val_loss: 0.6308 - val_accuracy: 0.6261 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6100 - accuracy: 0.6520 - val_loss: 0.6276 - val_accuracy: 0.6349 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6064 - accuracy: 0.6539 - val_loss: 0.6276 - val_accuracy: 0.6341 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6061 - accuracy: 0.6552 - val_loss: 0.6261 - val_accuracy: 0.6369 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6052 - accuracy: 0.6564 - val_loss: 0.6288 - val_accuracy: 0.6330 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6048 - accuracy: 0.6561 - val_loss: 0.6243 - val_accuracy: 0.6374 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6031 - accuracy: 0.6595 - val_loss: 0.6243 - val_accuracy: 0.6347 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.6006 - accuracy: 0.6615 - val_loss: 0.6242 - val_accuracy: 0.6386 - 2s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.5992 - accuracy: 0.6626 - val_loss: 0.6235 - val_accuracy: 0.6381 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.6011 - accuracy: 0.6589 - val_loss: 0.6232 - val_accuracy: 0.6400 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5980 - accuracy: 0.6632 - val_loss: 0.6220 - val_accuracy: 0.6411 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5978 - accuracy: 0.6634 - val_loss: 0.6215 - val_accuracy: 0.6409 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5956 - accuracy: 0.6651 - val_loss: 0.6202 - val_accuracy: 0.6418 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5952 - accuracy: 0.6648 - val_loss: 0.6209 - val_accuracy: 0.6391 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.5960 - accuracy: 0.6652 - val_loss: 0.6191 - val_accuracy: 0.6435 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.5948 - accuracy: 0.6665 - val_loss: 0.6188 - val_accuracy: 0.6439 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5942 - accuracy: 0.6655 - val_loss: 0.6187 - val_accuracy: 0.6440 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.5909 - accuracy: 0.6691 - val_loss: 0.6178 - val_accuracy: 0.6450 - 2s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.5912 - accuracy: 0.6693 - val_loss: 0.6165 - val_accuracy: 0.6464 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5879 - accuracy: 0.6717 - val_loss: 0.6153 - val_accuracy: 0.6474 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.5894 - accuracy: 0.6711 - val_loss: 0.6164 - val_accuracy: 0.6460 - 2s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 2s - loss: 0.5880 - accuracy: 0.6719 - val_loss: 0.6156 - val_accuracy: 0.6472 - 2s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "798/798 - 2s - loss: 0.5892 - accuracy: 0.6704 - val_loss: 0.6165 - val_accuracy: 0.6458 - 2s/epoch - 2ms/step\n",
      "Score for fold 1: loss of 0.6125116944313049; accuracy of 0.645869255065918%\n",
      "\n",
      "Training for Fold 2 ...\n",
      "Epoch 1/100\n",
      "798/798 - 2s - loss: 0.6882 - accuracy: 0.5409 - val_loss: 0.6844 - val_accuracy: 0.5493 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6827 - accuracy: 0.5548 - val_loss: 0.6820 - val_accuracy: 0.5538 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6796 - accuracy: 0.5615 - val_loss: 0.6799 - val_accuracy: 0.5584 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6766 - accuracy: 0.5683 - val_loss: 0.6769 - val_accuracy: 0.5640 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6735 - accuracy: 0.5742 - val_loss: 0.6747 - val_accuracy: 0.5722 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6699 - accuracy: 0.5807 - val_loss: 0.6714 - val_accuracy: 0.5754 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6654 - accuracy: 0.5877 - val_loss: 0.6684 - val_accuracy: 0.5825 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6622 - accuracy: 0.5937 - val_loss: 0.6654 - val_accuracy: 0.5876 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6583 - accuracy: 0.5984 - val_loss: 0.6612 - val_accuracy: 0.5919 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6546 - accuracy: 0.6032 - val_loss: 0.6592 - val_accuracy: 0.5943 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6515 - accuracy: 0.6084 - val_loss: 0.6571 - val_accuracy: 0.5983 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6487 - accuracy: 0.6132 - val_loss: 0.6559 - val_accuracy: 0.6013 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6456 - accuracy: 0.6162 - val_loss: 0.6510 - val_accuracy: 0.6070 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6423 - accuracy: 0.6208 - val_loss: 0.6494 - val_accuracy: 0.6091 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6416 - accuracy: 0.6221 - val_loss: 0.6478 - val_accuracy: 0.6126 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6370 - accuracy: 0.6263 - val_loss: 0.6446 - val_accuracy: 0.6167 - 2s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6354 - accuracy: 0.6299 - val_loss: 0.6446 - val_accuracy: 0.6156 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6322 - accuracy: 0.6307 - val_loss: 0.6419 - val_accuracy: 0.6184 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6305 - accuracy: 0.6334 - val_loss: 0.6388 - val_accuracy: 0.6239 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6273 - accuracy: 0.6374 - val_loss: 0.6369 - val_accuracy: 0.6263 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6268 - accuracy: 0.6369 - val_loss: 0.6360 - val_accuracy: 0.6269 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6213 - accuracy: 0.6435 - val_loss: 0.6352 - val_accuracy: 0.6268 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6207 - accuracy: 0.6445 - val_loss: 0.6358 - val_accuracy: 0.6255 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6187 - accuracy: 0.6455 - val_loss: 0.6328 - val_accuracy: 0.6291 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6168 - accuracy: 0.6474 - val_loss: 0.6318 - val_accuracy: 0.6331 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6148 - accuracy: 0.6509 - val_loss: 0.6294 - val_accuracy: 0.6347 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6149 - accuracy: 0.6509 - val_loss: 0.6292 - val_accuracy: 0.6336 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6117 - accuracy: 0.6526 - val_loss: 0.6288 - val_accuracy: 0.6349 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6108 - accuracy: 0.6531 - val_loss: 0.6283 - val_accuracy: 0.6363 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6094 - accuracy: 0.6552 - val_loss: 0.6261 - val_accuracy: 0.6390 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6081 - accuracy: 0.6561 - val_loss: 0.6263 - val_accuracy: 0.6369 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6061 - accuracy: 0.6571 - val_loss: 0.6238 - val_accuracy: 0.6425 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6060 - accuracy: 0.6592 - val_loss: 0.6232 - val_accuracy: 0.6412 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6044 - accuracy: 0.6611 - val_loss: 0.6225 - val_accuracy: 0.6420 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6027 - accuracy: 0.6614 - val_loss: 0.6224 - val_accuracy: 0.6422 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6005 - accuracy: 0.6633 - val_loss: 0.6206 - val_accuracy: 0.6421 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.5989 - accuracy: 0.6667 - val_loss: 0.6180 - val_accuracy: 0.6467 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.5997 - accuracy: 0.6650 - val_loss: 0.6191 - val_accuracy: 0.6444 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5978 - accuracy: 0.6673 - val_loss: 0.6205 - val_accuracy: 0.6437 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5970 - accuracy: 0.6671 - val_loss: 0.6207 - val_accuracy: 0.6422 - 2s/epoch - 2ms/step\n",
      "Score for fold 2: loss of 0.6196557879447937; accuracy of 0.6446543335914612%\n",
      "\n",
      "Training for Fold 3 ...\n",
      "Epoch 1/100\n",
      "798/798 - 2s - loss: 0.6881 - accuracy: 0.5416 - val_loss: 0.6846 - val_accuracy: 0.5492 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6829 - accuracy: 0.5535 - val_loss: 0.6839 - val_accuracy: 0.5500 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6805 - accuracy: 0.5557 - val_loss: 0.6805 - val_accuracy: 0.5567 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6776 - accuracy: 0.5649 - val_loss: 0.6796 - val_accuracy: 0.5614 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6748 - accuracy: 0.5703 - val_loss: 0.6767 - val_accuracy: 0.5647 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6718 - accuracy: 0.5762 - val_loss: 0.6738 - val_accuracy: 0.5703 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6689 - accuracy: 0.5795 - val_loss: 0.6723 - val_accuracy: 0.5738 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6657 - accuracy: 0.5859 - val_loss: 0.6678 - val_accuracy: 0.5807 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6617 - accuracy: 0.5930 - val_loss: 0.6654 - val_accuracy: 0.5843 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6578 - accuracy: 0.5970 - val_loss: 0.6635 - val_accuracy: 0.5855 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6545 - accuracy: 0.6021 - val_loss: 0.6608 - val_accuracy: 0.5898 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6505 - accuracy: 0.6083 - val_loss: 0.6571 - val_accuracy: 0.5954 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6466 - accuracy: 0.6135 - val_loss: 0.6541 - val_accuracy: 0.6017 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6426 - accuracy: 0.6173 - val_loss: 0.6522 - val_accuracy: 0.6034 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6406 - accuracy: 0.6211 - val_loss: 0.6501 - val_accuracy: 0.6081 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6373 - accuracy: 0.6234 - val_loss: 0.6479 - val_accuracy: 0.6064 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6358 - accuracy: 0.6259 - val_loss: 0.6461 - val_accuracy: 0.6139 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6332 - accuracy: 0.6287 - val_loss: 0.6440 - val_accuracy: 0.6163 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6296 - accuracy: 0.6335 - val_loss: 0.6436 - val_accuracy: 0.6149 - 2s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6277 - accuracy: 0.6371 - val_loss: 0.6424 - val_accuracy: 0.6164 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6262 - accuracy: 0.6375 - val_loss: 0.6392 - val_accuracy: 0.6206 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6234 - accuracy: 0.6403 - val_loss: 0.6377 - val_accuracy: 0.6230 - 2s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6213 - accuracy: 0.6431 - val_loss: 0.6356 - val_accuracy: 0.6261 - 2s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6194 - accuracy: 0.6458 - val_loss: 0.6352 - val_accuracy: 0.6253 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6173 - accuracy: 0.6465 - val_loss: 0.6339 - val_accuracy: 0.6246 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6154 - accuracy: 0.6480 - val_loss: 0.6317 - val_accuracy: 0.6282 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6143 - accuracy: 0.6472 - val_loss: 0.6320 - val_accuracy: 0.6275 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6126 - accuracy: 0.6520 - val_loss: 0.6313 - val_accuracy: 0.6307 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6109 - accuracy: 0.6541 - val_loss: 0.6291 - val_accuracy: 0.6320 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6096 - accuracy: 0.6544 - val_loss: 0.6289 - val_accuracy: 0.6324 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6082 - accuracy: 0.6558 - val_loss: 0.6273 - val_accuracy: 0.6343 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6059 - accuracy: 0.6568 - val_loss: 0.6257 - val_accuracy: 0.6384 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6055 - accuracy: 0.6596 - val_loss: 0.6256 - val_accuracy: 0.6378 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6035 - accuracy: 0.6611 - val_loss: 0.6255 - val_accuracy: 0.6366 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6018 - accuracy: 0.6604 - val_loss: 0.6240 - val_accuracy: 0.6368 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6004 - accuracy: 0.6625 - val_loss: 0.6230 - val_accuracy: 0.6408 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.6005 - accuracy: 0.6639 - val_loss: 0.6228 - val_accuracy: 0.6402 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.5978 - accuracy: 0.6654 - val_loss: 0.6209 - val_accuracy: 0.6416 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5978 - accuracy: 0.6666 - val_loss: 0.6215 - val_accuracy: 0.6418 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5962 - accuracy: 0.6669 - val_loss: 0.6191 - val_accuracy: 0.6436 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5960 - accuracy: 0.6684 - val_loss: 0.6203 - val_accuracy: 0.6433 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5959 - accuracy: 0.6682 - val_loss: 0.6177 - val_accuracy: 0.6470 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5935 - accuracy: 0.6707 - val_loss: 0.6184 - val_accuracy: 0.6456 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.5929 - accuracy: 0.6706 - val_loss: 0.6185 - val_accuracy: 0.6445 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.5932 - accuracy: 0.6703 - val_loss: 0.6169 - val_accuracy: 0.6482 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5910 - accuracy: 0.6739 - val_loss: 0.6169 - val_accuracy: 0.6464 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.5904 - accuracy: 0.6729 - val_loss: 0.6150 - val_accuracy: 0.6495 - 2s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.5890 - accuracy: 0.6748 - val_loss: 0.6151 - val_accuracy: 0.6486 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5867 - accuracy: 0.6763 - val_loss: 0.6143 - val_accuracy: 0.6481 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.5876 - accuracy: 0.6775 - val_loss: 0.6137 - val_accuracy: 0.6500 - 2s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 2s - loss: 0.5858 - accuracy: 0.6775 - val_loss: 0.6140 - val_accuracy: 0.6500 - 2s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "798/798 - 2s - loss: 0.5832 - accuracy: 0.6804 - val_loss: 0.6129 - val_accuracy: 0.6486 - 2s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "798/798 - 2s - loss: 0.5854 - accuracy: 0.6777 - val_loss: 0.6118 - val_accuracy: 0.6517 - 2s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "798/798 - 2s - loss: 0.5848 - accuracy: 0.6792 - val_loss: 0.6118 - val_accuracy: 0.6494 - 2s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "798/798 - 2s - loss: 0.5828 - accuracy: 0.6804 - val_loss: 0.6110 - val_accuracy: 0.6521 - 2s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "798/798 - 2s - loss: 0.5827 - accuracy: 0.6811 - val_loss: 0.6113 - val_accuracy: 0.6522 - 2s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "798/798 - 2s - loss: 0.5813 - accuracy: 0.6823 - val_loss: 0.6115 - val_accuracy: 0.6515 - 2s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "798/798 - 2s - loss: 0.5800 - accuracy: 0.6823 - val_loss: 0.6098 - val_accuracy: 0.6529 - 2s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "798/798 - 2s - loss: 0.5795 - accuracy: 0.6819 - val_loss: 0.6104 - val_accuracy: 0.6529 - 2s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "798/798 - 2s - loss: 0.5792 - accuracy: 0.6839 - val_loss: 0.6097 - val_accuracy: 0.6534 - 2s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "798/798 - 2s - loss: 0.5797 - accuracy: 0.6825 - val_loss: 0.6097 - val_accuracy: 0.6547 - 2s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "798/798 - 2s - loss: 0.5792 - accuracy: 0.6838 - val_loss: 0.6085 - val_accuracy: 0.6532 - 2s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "798/798 - 2s - loss: 0.5782 - accuracy: 0.6844 - val_loss: 0.6098 - val_accuracy: 0.6531 - 2s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "798/798 - 2s - loss: 0.5784 - accuracy: 0.6851 - val_loss: 0.6084 - val_accuracy: 0.6556 - 2s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "798/798 - 2s - loss: 0.5778 - accuracy: 0.6833 - val_loss: 0.6096 - val_accuracy: 0.6544 - 2s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "798/798 - 2s - loss: 0.5755 - accuracy: 0.6876 - val_loss: 0.6080 - val_accuracy: 0.6566 - 2s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "798/798 - 2s - loss: 0.5778 - accuracy: 0.6852 - val_loss: 0.6088 - val_accuracy: 0.6560 - 2s/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "798/798 - 2s - loss: 0.5734 - accuracy: 0.6885 - val_loss: 0.6062 - val_accuracy: 0.6565 - 2s/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "798/798 - 2s - loss: 0.5750 - accuracy: 0.6869 - val_loss: 0.6060 - val_accuracy: 0.6571 - 2s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "798/798 - 2s - loss: 0.5741 - accuracy: 0.6881 - val_loss: 0.6060 - val_accuracy: 0.6574 - 2s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "798/798 - 2s - loss: 0.5736 - accuracy: 0.6886 - val_loss: 0.6070 - val_accuracy: 0.6559 - 2s/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "798/798 - 2s - loss: 0.5737 - accuracy: 0.6873 - val_loss: 0.6064 - val_accuracy: 0.6582 - 2s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "798/798 - 2s - loss: 0.5721 - accuracy: 0.6895 - val_loss: 0.6064 - val_accuracy: 0.6576 - 2s/epoch - 3ms/step\n",
      "Score for fold 3: loss of 0.6083087921142578; accuracy of 0.6575739979743958%\n",
      "\n",
      "Training for Fold 4 ...\n",
      "Epoch 1/100\n",
      "798/798 - 3s - loss: 0.6887 - accuracy: 0.5401 - val_loss: 0.6848 - val_accuracy: 0.5493 - 3s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6828 - accuracy: 0.5552 - val_loss: 0.6832 - val_accuracy: 0.5529 - 2s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6810 - accuracy: 0.5579 - val_loss: 0.6803 - val_accuracy: 0.5590 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6775 - accuracy: 0.5642 - val_loss: 0.6781 - val_accuracy: 0.5627 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6743 - accuracy: 0.5724 - val_loss: 0.6757 - val_accuracy: 0.5679 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6703 - accuracy: 0.5791 - val_loss: 0.6724 - val_accuracy: 0.5759 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6665 - accuracy: 0.5854 - val_loss: 0.6696 - val_accuracy: 0.5832 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 3s - loss: 0.6641 - accuracy: 0.5872 - val_loss: 0.6659 - val_accuracy: 0.5874 - 3s/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6595 - accuracy: 0.5961 - val_loss: 0.6628 - val_accuracy: 0.5913 - 2s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6565 - accuracy: 0.5995 - val_loss: 0.6611 - val_accuracy: 0.5947 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6534 - accuracy: 0.6047 - val_loss: 0.6599 - val_accuracy: 0.6006 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6492 - accuracy: 0.6090 - val_loss: 0.6560 - val_accuracy: 0.6045 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6462 - accuracy: 0.6153 - val_loss: 0.6547 - val_accuracy: 0.6064 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6436 - accuracy: 0.6185 - val_loss: 0.6519 - val_accuracy: 0.6082 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6411 - accuracy: 0.6195 - val_loss: 0.6505 - val_accuracy: 0.6111 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6390 - accuracy: 0.6233 - val_loss: 0.6466 - val_accuracy: 0.6151 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6357 - accuracy: 0.6275 - val_loss: 0.6463 - val_accuracy: 0.6178 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6333 - accuracy: 0.6278 - val_loss: 0.6437 - val_accuracy: 0.6180 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6295 - accuracy: 0.6332 - val_loss: 0.6433 - val_accuracy: 0.6216 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6299 - accuracy: 0.6353 - val_loss: 0.6425 - val_accuracy: 0.6200 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6271 - accuracy: 0.6387 - val_loss: 0.6394 - val_accuracy: 0.6230 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6244 - accuracy: 0.6385 - val_loss: 0.6375 - val_accuracy: 0.6268 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6230 - accuracy: 0.6421 - val_loss: 0.6372 - val_accuracy: 0.6264 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6200 - accuracy: 0.6454 - val_loss: 0.6351 - val_accuracy: 0.6301 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6184 - accuracy: 0.6460 - val_loss: 0.6351 - val_accuracy: 0.6266 - 2s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6172 - accuracy: 0.6472 - val_loss: 0.6333 - val_accuracy: 0.6285 - 2s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6148 - accuracy: 0.6489 - val_loss: 0.6315 - val_accuracy: 0.6329 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6127 - accuracy: 0.6516 - val_loss: 0.6288 - val_accuracy: 0.6359 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6110 - accuracy: 0.6523 - val_loss: 0.6299 - val_accuracy: 0.6346 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6105 - accuracy: 0.6565 - val_loss: 0.6280 - val_accuracy: 0.6364 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6082 - accuracy: 0.6564 - val_loss: 0.6288 - val_accuracy: 0.6337 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6072 - accuracy: 0.6574 - val_loss: 0.6277 - val_accuracy: 0.6371 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6064 - accuracy: 0.6574 - val_loss: 0.6259 - val_accuracy: 0.6405 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6045 - accuracy: 0.6605 - val_loss: 0.6243 - val_accuracy: 0.6402 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6041 - accuracy: 0.6608 - val_loss: 0.6247 - val_accuracy: 0.6422 - 2s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6027 - accuracy: 0.6613 - val_loss: 0.6228 - val_accuracy: 0.6423 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.6014 - accuracy: 0.6629 - val_loss: 0.6231 - val_accuracy: 0.6435 - 2s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.6013 - accuracy: 0.6632 - val_loss: 0.6229 - val_accuracy: 0.6425 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5975 - accuracy: 0.6663 - val_loss: 0.6208 - val_accuracy: 0.6479 - 2s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5982 - accuracy: 0.6648 - val_loss: 0.6204 - val_accuracy: 0.6456 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5953 - accuracy: 0.6702 - val_loss: 0.6211 - val_accuracy: 0.6442 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5953 - accuracy: 0.6704 - val_loss: 0.6182 - val_accuracy: 0.6463 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5942 - accuracy: 0.6692 - val_loss: 0.6180 - val_accuracy: 0.6476 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.5942 - accuracy: 0.6702 - val_loss: 0.6164 - val_accuracy: 0.6495 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.5931 - accuracy: 0.6701 - val_loss: 0.6166 - val_accuracy: 0.6493 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5939 - accuracy: 0.6711 - val_loss: 0.6183 - val_accuracy: 0.6480 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.5910 - accuracy: 0.6726 - val_loss: 0.6147 - val_accuracy: 0.6504 - 2s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.5886 - accuracy: 0.6755 - val_loss: 0.6139 - val_accuracy: 0.6516 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5890 - accuracy: 0.6753 - val_loss: 0.6143 - val_accuracy: 0.6514 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.5870 - accuracy: 0.6771 - val_loss: 0.6151 - val_accuracy: 0.6495 - 2s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 2s - loss: 0.5885 - accuracy: 0.6765 - val_loss: 0.6142 - val_accuracy: 0.6512 - 2s/epoch - 2ms/step\n",
      "Score for fold 4: loss of 0.6122620701789856; accuracy of 0.6566725373268127%\n",
      "\n",
      "Training for Fold 5 ...\n",
      "Epoch 1/100\n",
      "798/798 - 2s - loss: 0.6883 - accuracy: 0.5408 - val_loss: 0.6846 - val_accuracy: 0.5468 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6830 - accuracy: 0.5529 - val_loss: 0.6822 - val_accuracy: 0.5540 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6802 - accuracy: 0.5592 - val_loss: 0.6800 - val_accuracy: 0.5575 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6773 - accuracy: 0.5641 - val_loss: 0.6788 - val_accuracy: 0.5627 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6745 - accuracy: 0.5725 - val_loss: 0.6750 - val_accuracy: 0.5683 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6709 - accuracy: 0.5772 - val_loss: 0.6735 - val_accuracy: 0.5735 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6679 - accuracy: 0.5819 - val_loss: 0.6711 - val_accuracy: 0.5775 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6640 - accuracy: 0.5876 - val_loss: 0.6681 - val_accuracy: 0.5805 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6600 - accuracy: 0.5946 - val_loss: 0.6659 - val_accuracy: 0.5864 - 2s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6571 - accuracy: 0.5981 - val_loss: 0.6633 - val_accuracy: 0.5906 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6539 - accuracy: 0.6028 - val_loss: 0.6609 - val_accuracy: 0.5934 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6501 - accuracy: 0.6078 - val_loss: 0.6581 - val_accuracy: 0.5978 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6481 - accuracy: 0.6117 - val_loss: 0.6570 - val_accuracy: 0.5977 - 2s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6448 - accuracy: 0.6141 - val_loss: 0.6552 - val_accuracy: 0.5982 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6405 - accuracy: 0.6196 - val_loss: 0.6513 - val_accuracy: 0.6072 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6392 - accuracy: 0.6223 - val_loss: 0.6499 - val_accuracy: 0.6100 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6370 - accuracy: 0.6249 - val_loss: 0.6488 - val_accuracy: 0.6118 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6326 - accuracy: 0.6301 - val_loss: 0.6469 - val_accuracy: 0.6143 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6316 - accuracy: 0.6300 - val_loss: 0.6438 - val_accuracy: 0.6152 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6289 - accuracy: 0.6347 - val_loss: 0.6435 - val_accuracy: 0.6140 - 2s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6263 - accuracy: 0.6366 - val_loss: 0.6418 - val_accuracy: 0.6188 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6229 - accuracy: 0.6412 - val_loss: 0.6409 - val_accuracy: 0.6204 - 2s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.6226 - accuracy: 0.6409 - val_loss: 0.6372 - val_accuracy: 0.6237 - 2s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.6191 - accuracy: 0.6450 - val_loss: 0.6371 - val_accuracy: 0.6259 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.6175 - accuracy: 0.6452 - val_loss: 0.6362 - val_accuracy: 0.6247 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.6160 - accuracy: 0.6477 - val_loss: 0.6344 - val_accuracy: 0.6291 - 2s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.6146 - accuracy: 0.6501 - val_loss: 0.6343 - val_accuracy: 0.6310 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.6144 - accuracy: 0.6508 - val_loss: 0.6321 - val_accuracy: 0.6312 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.6122 - accuracy: 0.6513 - val_loss: 0.6309 - val_accuracy: 0.6335 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.6111 - accuracy: 0.6546 - val_loss: 0.6301 - val_accuracy: 0.6328 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.6095 - accuracy: 0.6541 - val_loss: 0.6295 - val_accuracy: 0.6368 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.6078 - accuracy: 0.6573 - val_loss: 0.6284 - val_accuracy: 0.6380 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.6055 - accuracy: 0.6592 - val_loss: 0.6271 - val_accuracy: 0.6377 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.6044 - accuracy: 0.6589 - val_loss: 0.6274 - val_accuracy: 0.6384 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.6046 - accuracy: 0.6588 - val_loss: 0.6271 - val_accuracy: 0.6349 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.6032 - accuracy: 0.6623 - val_loss: 0.6259 - val_accuracy: 0.6374 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 3s - loss: 0.6015 - accuracy: 0.6634 - val_loss: 0.6253 - val_accuracy: 0.6388 - 3s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.6025 - accuracy: 0.6609 - val_loss: 0.6230 - val_accuracy: 0.6418 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5989 - accuracy: 0.6637 - val_loss: 0.6229 - val_accuracy: 0.6411 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5985 - accuracy: 0.6643 - val_loss: 0.6208 - val_accuracy: 0.6412 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5964 - accuracy: 0.6668 - val_loss: 0.6222 - val_accuracy: 0.6406 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5945 - accuracy: 0.6687 - val_loss: 0.6211 - val_accuracy: 0.6435 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5951 - accuracy: 0.6681 - val_loss: 0.6183 - val_accuracy: 0.6451 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.5938 - accuracy: 0.6684 - val_loss: 0.6187 - val_accuracy: 0.6449 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.5919 - accuracy: 0.6714 - val_loss: 0.6181 - val_accuracy: 0.6484 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5916 - accuracy: 0.6711 - val_loss: 0.6185 - val_accuracy: 0.6466 - 2s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.5904 - accuracy: 0.6722 - val_loss: 0.6171 - val_accuracy: 0.6483 - 2s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.5888 - accuracy: 0.6748 - val_loss: 0.6171 - val_accuracy: 0.6493 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5900 - accuracy: 0.6734 - val_loss: 0.6172 - val_accuracy: 0.6468 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.5872 - accuracy: 0.6761 - val_loss: 0.6157 - val_accuracy: 0.6494 - 2s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 3s - loss: 0.5883 - accuracy: 0.6713 - val_loss: 0.6157 - val_accuracy: 0.6490 - 3s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "798/798 - 2s - loss: 0.5877 - accuracy: 0.6757 - val_loss: 0.6152 - val_accuracy: 0.6482 - 2s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "798/798 - 2s - loss: 0.5876 - accuracy: 0.6746 - val_loss: 0.6139 - val_accuracy: 0.6499 - 2s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "798/798 - 2s - loss: 0.5867 - accuracy: 0.6741 - val_loss: 0.6140 - val_accuracy: 0.6507 - 2s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "798/798 - 2s - loss: 0.5858 - accuracy: 0.6780 - val_loss: 0.6140 - val_accuracy: 0.6525 - 2s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "798/798 - 2s - loss: 0.5842 - accuracy: 0.6785 - val_loss: 0.6144 - val_accuracy: 0.6503 - 2s/epoch - 2ms/step\n",
      "Score for fold 5: loss of 0.6123321056365967; accuracy of 0.6560454368591309%\n",
      "\n",
      "------- Batch Size: 1024 -------\n",
      "\n",
      "Training for Fold 1 ...\n",
      "Epoch 1/100\n",
      "798/798 - 3s - loss: 0.6888 - accuracy: 0.5386 - val_loss: 0.6840 - val_accuracy: 0.5515 - 3s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6821 - accuracy: 0.5581 - val_loss: 0.6822 - val_accuracy: 0.5552 - 2s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 3s - loss: 0.6784 - accuracy: 0.5629 - val_loss: 0.6798 - val_accuracy: 0.5596 - 3s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6745 - accuracy: 0.5718 - val_loss: 0.6768 - val_accuracy: 0.5632 - 2s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6708 - accuracy: 0.5784 - val_loss: 0.6745 - val_accuracy: 0.5727 - 2s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6661 - accuracy: 0.5866 - val_loss: 0.6697 - val_accuracy: 0.5788 - 2s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6611 - accuracy: 0.5932 - val_loss: 0.6674 - val_accuracy: 0.5833 - 2s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6566 - accuracy: 0.5991 - val_loss: 0.6632 - val_accuracy: 0.5903 - 2s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6515 - accuracy: 0.6069 - val_loss: 0.6597 - val_accuracy: 0.5966 - 2s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6471 - accuracy: 0.6104 - val_loss: 0.6558 - val_accuracy: 0.6011 - 2s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6420 - accuracy: 0.6168 - val_loss: 0.6534 - val_accuracy: 0.6036 - 2s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6366 - accuracy: 0.6216 - val_loss: 0.6510 - val_accuracy: 0.6069 - 2s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6335 - accuracy: 0.6256 - val_loss: 0.6473 - val_accuracy: 0.6096 - 2s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6279 - accuracy: 0.6325 - val_loss: 0.6455 - val_accuracy: 0.6131 - 2s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6239 - accuracy: 0.6348 - val_loss: 0.6415 - val_accuracy: 0.6176 - 2s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6214 - accuracy: 0.6381 - val_loss: 0.6394 - val_accuracy: 0.6240 - 2s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6182 - accuracy: 0.6407 - val_loss: 0.6369 - val_accuracy: 0.6233 - 2s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6142 - accuracy: 0.6465 - val_loss: 0.6372 - val_accuracy: 0.6220 - 2s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6110 - accuracy: 0.6478 - val_loss: 0.6351 - val_accuracy: 0.6258 - 2s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6076 - accuracy: 0.6512 - val_loss: 0.6324 - val_accuracy: 0.6279 - 2s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6054 - accuracy: 0.6531 - val_loss: 0.6297 - val_accuracy: 0.6339 - 2s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6029 - accuracy: 0.6556 - val_loss: 0.6270 - val_accuracy: 0.6331 - 2s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.5986 - accuracy: 0.6586 - val_loss: 0.6255 - val_accuracy: 0.6345 - 2s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.5962 - accuracy: 0.6613 - val_loss: 0.6231 - val_accuracy: 0.6364 - 2s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.5922 - accuracy: 0.6644 - val_loss: 0.6229 - val_accuracy: 0.6401 - 2s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.5906 - accuracy: 0.6649 - val_loss: 0.6204 - val_accuracy: 0.6411 - 2s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.5883 - accuracy: 0.6682 - val_loss: 0.6187 - val_accuracy: 0.6438 - 2s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.5840 - accuracy: 0.6715 - val_loss: 0.6171 - val_accuracy: 0.6445 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.5828 - accuracy: 0.6734 - val_loss: 0.6156 - val_accuracy: 0.6452 - 2s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.5792 - accuracy: 0.6758 - val_loss: 0.6143 - val_accuracy: 0.6460 - 2s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 3s - loss: 0.5777 - accuracy: 0.6782 - val_loss: 0.6131 - val_accuracy: 0.6493 - 3s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.5742 - accuracy: 0.6803 - val_loss: 0.6124 - val_accuracy: 0.6495 - 2s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.5727 - accuracy: 0.6819 - val_loss: 0.6115 - val_accuracy: 0.6497 - 2s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.5709 - accuracy: 0.6836 - val_loss: 0.6104 - val_accuracy: 0.6525 - 2s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.5683 - accuracy: 0.6857 - val_loss: 0.6084 - val_accuracy: 0.6540 - 2s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.5671 - accuracy: 0.6856 - val_loss: 0.6081 - val_accuracy: 0.6521 - 2s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.5670 - accuracy: 0.6876 - val_loss: 0.6068 - val_accuracy: 0.6551 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.5632 - accuracy: 0.6891 - val_loss: 0.6049 - val_accuracy: 0.6540 - 2s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5607 - accuracy: 0.6917 - val_loss: 0.6055 - val_accuracy: 0.6550 - 2s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5594 - accuracy: 0.6933 - val_loss: 0.6058 - val_accuracy: 0.6563 - 2s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5595 - accuracy: 0.6937 - val_loss: 0.6038 - val_accuracy: 0.6590 - 2s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5573 - accuracy: 0.6951 - val_loss: 0.6025 - val_accuracy: 0.6610 - 2s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5563 - accuracy: 0.6935 - val_loss: 0.6020 - val_accuracy: 0.6601 - 2s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 3s - loss: 0.5538 - accuracy: 0.6975 - val_loss: 0.5989 - val_accuracy: 0.6623 - 3s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 3s - loss: 0.5524 - accuracy: 0.6989 - val_loss: 0.5999 - val_accuracy: 0.6616 - 3s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5496 - accuracy: 0.7001 - val_loss: 0.5993 - val_accuracy: 0.6610 - 2s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 3s - loss: 0.5507 - accuracy: 0.7007 - val_loss: 0.5986 - val_accuracy: 0.6621 - 3s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 3s - loss: 0.5480 - accuracy: 0.7019 - val_loss: 0.5974 - val_accuracy: 0.6646 - 3s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5466 - accuracy: 0.7027 - val_loss: 0.5954 - val_accuracy: 0.6657 - 2s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 3s - loss: 0.5458 - accuracy: 0.7042 - val_loss: 0.5970 - val_accuracy: 0.6647 - 3s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 2s - loss: 0.5431 - accuracy: 0.7058 - val_loss: 0.5952 - val_accuracy: 0.6665 - 2s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "798/798 - 2s - loss: 0.5429 - accuracy: 0.7077 - val_loss: 0.5948 - val_accuracy: 0.6679 - 2s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "798/798 - 2s - loss: 0.5420 - accuracy: 0.7086 - val_loss: 0.5949 - val_accuracy: 0.6688 - 2s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "798/798 - 2s - loss: 0.5411 - accuracy: 0.7089 - val_loss: 0.5940 - val_accuracy: 0.6687 - 2s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "798/798 - 3s - loss: 0.5392 - accuracy: 0.7097 - val_loss: 0.5929 - val_accuracy: 0.6707 - 3s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "798/798 - 2s - loss: 0.5373 - accuracy: 0.7109 - val_loss: 0.5942 - val_accuracy: 0.6687 - 2s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "798/798 - 2s - loss: 0.5358 - accuracy: 0.7116 - val_loss: 0.5940 - val_accuracy: 0.6681 - 2s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "798/798 - 2s - loss: 0.5350 - accuracy: 0.7119 - val_loss: 0.5939 - val_accuracy: 0.6676 - 2s/epoch - 3ms/step\n",
      "Score for fold 1: loss of 0.5929471850395203; accuracy of 0.6698933839797974%\n",
      "\n",
      "Training for Fold 2 ...\n",
      "Epoch 1/100\n",
      "798/798 - 3s - loss: 0.6887 - accuracy: 0.5414 - val_loss: 0.6841 - val_accuracy: 0.5471 - 3s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6824 - accuracy: 0.5553 - val_loss: 0.6817 - val_accuracy: 0.5529 - 2s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6791 - accuracy: 0.5607 - val_loss: 0.6788 - val_accuracy: 0.5608 - 2s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6753 - accuracy: 0.5700 - val_loss: 0.6762 - val_accuracy: 0.5665 - 2s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6705 - accuracy: 0.5758 - val_loss: 0.6721 - val_accuracy: 0.5705 - 2s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6657 - accuracy: 0.5866 - val_loss: 0.6685 - val_accuracy: 0.5802 - 2s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6601 - accuracy: 0.5958 - val_loss: 0.6652 - val_accuracy: 0.5857 - 2s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6555 - accuracy: 0.6009 - val_loss: 0.6610 - val_accuracy: 0.5872 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6497 - accuracy: 0.6055 - val_loss: 0.6581 - val_accuracy: 0.5945 - 2s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6455 - accuracy: 0.6136 - val_loss: 0.6541 - val_accuracy: 0.6001 - 2s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6402 - accuracy: 0.6174 - val_loss: 0.6513 - val_accuracy: 0.6050 - 2s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6365 - accuracy: 0.6242 - val_loss: 0.6477 - val_accuracy: 0.6119 - 2s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6320 - accuracy: 0.6287 - val_loss: 0.6440 - val_accuracy: 0.6141 - 2s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6276 - accuracy: 0.6337 - val_loss: 0.6406 - val_accuracy: 0.6187 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6230 - accuracy: 0.6383 - val_loss: 0.6388 - val_accuracy: 0.6222 - 2s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6193 - accuracy: 0.6424 - val_loss: 0.6364 - val_accuracy: 0.6247 - 2s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6146 - accuracy: 0.6463 - val_loss: 0.6344 - val_accuracy: 0.6262 - 2s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6093 - accuracy: 0.6528 - val_loss: 0.6318 - val_accuracy: 0.6269 - 2s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6063 - accuracy: 0.6552 - val_loss: 0.6282 - val_accuracy: 0.6326 - 2s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 3s - loss: 0.6032 - accuracy: 0.6584 - val_loss: 0.6276 - val_accuracy: 0.6323 - 3s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.5991 - accuracy: 0.6604 - val_loss: 0.6264 - val_accuracy: 0.6333 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.5969 - accuracy: 0.6647 - val_loss: 0.6239 - val_accuracy: 0.6375 - 2s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.5930 - accuracy: 0.6665 - val_loss: 0.6220 - val_accuracy: 0.6400 - 2s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 3s - loss: 0.5887 - accuracy: 0.6724 - val_loss: 0.6189 - val_accuracy: 0.6404 - 3s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 4s - loss: 0.5858 - accuracy: 0.6737 - val_loss: 0.6220 - val_accuracy: 0.6388 - 4s/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 3s - loss: 0.5843 - accuracy: 0.6730 - val_loss: 0.6177 - val_accuracy: 0.6471 - 3s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.5799 - accuracy: 0.6790 - val_loss: 0.6148 - val_accuracy: 0.6473 - 2s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 3s - loss: 0.5791 - accuracy: 0.6807 - val_loss: 0.6147 - val_accuracy: 0.6474 - 3s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.5744 - accuracy: 0.6857 - val_loss: 0.6144 - val_accuracy: 0.6474 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.5725 - accuracy: 0.6848 - val_loss: 0.6104 - val_accuracy: 0.6519 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.5705 - accuracy: 0.6857 - val_loss: 0.6130 - val_accuracy: 0.6494 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.5692 - accuracy: 0.6870 - val_loss: 0.6101 - val_accuracy: 0.6499 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.5672 - accuracy: 0.6892 - val_loss: 0.6088 - val_accuracy: 0.6511 - 2s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.5647 - accuracy: 0.6909 - val_loss: 0.6096 - val_accuracy: 0.6496 - 2s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.5622 - accuracy: 0.6932 - val_loss: 0.6055 - val_accuracy: 0.6544 - 2s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.5589 - accuracy: 0.6953 - val_loss: 0.6041 - val_accuracy: 0.6575 - 2s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.5574 - accuracy: 0.6978 - val_loss: 0.6045 - val_accuracy: 0.6551 - 2s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.5556 - accuracy: 0.6987 - val_loss: 0.6033 - val_accuracy: 0.6599 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5539 - accuracy: 0.7005 - val_loss: 0.6020 - val_accuracy: 0.6610 - 2s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5536 - accuracy: 0.7021 - val_loss: 0.6048 - val_accuracy: 0.6592 - 2s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5489 - accuracy: 0.7039 - val_loss: 0.6029 - val_accuracy: 0.6593 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5484 - accuracy: 0.7036 - val_loss: 0.6002 - val_accuracy: 0.6624 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5485 - accuracy: 0.7046 - val_loss: 0.5992 - val_accuracy: 0.6643 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.5458 - accuracy: 0.7065 - val_loss: 0.6000 - val_accuracy: 0.6625 - 2s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.5446 - accuracy: 0.7079 - val_loss: 0.5988 - val_accuracy: 0.6640 - 2s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5421 - accuracy: 0.7094 - val_loss: 0.5995 - val_accuracy: 0.6641 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.5414 - accuracy: 0.7110 - val_loss: 0.5958 - val_accuracy: 0.6671 - 2s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.5397 - accuracy: 0.7119 - val_loss: 0.5971 - val_accuracy: 0.6678 - 2s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5408 - accuracy: 0.7112 - val_loss: 0.5980 - val_accuracy: 0.6660 - 2s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.5385 - accuracy: 0.7128 - val_loss: 0.5960 - val_accuracy: 0.6678 - 2s/epoch - 3ms/step\n",
      "Score for fold 2: loss of 0.5955818891525269; accuracy of 0.6681298017501831%\n",
      "\n",
      "Training for Fold 3 ...\n",
      "Epoch 1/100\n",
      "798/798 - 3s - loss: 0.6882 - accuracy: 0.5422 - val_loss: 0.6836 - val_accuracy: 0.5500 - 3s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6817 - accuracy: 0.5570 - val_loss: 0.6828 - val_accuracy: 0.5557 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6787 - accuracy: 0.5635 - val_loss: 0.6787 - val_accuracy: 0.5606 - 2s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6747 - accuracy: 0.5678 - val_loss: 0.6776 - val_accuracy: 0.5665 - 2s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6707 - accuracy: 0.5749 - val_loss: 0.6728 - val_accuracy: 0.5732 - 2s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6661 - accuracy: 0.5842 - val_loss: 0.6679 - val_accuracy: 0.5792 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6605 - accuracy: 0.5926 - val_loss: 0.6648 - val_accuracy: 0.5876 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6558 - accuracy: 0.5979 - val_loss: 0.6602 - val_accuracy: 0.5941 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6508 - accuracy: 0.6075 - val_loss: 0.6568 - val_accuracy: 0.5950 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6457 - accuracy: 0.6114 - val_loss: 0.6535 - val_accuracy: 0.6040 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6405 - accuracy: 0.6185 - val_loss: 0.6517 - val_accuracy: 0.6075 - 2s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6358 - accuracy: 0.6238 - val_loss: 0.6471 - val_accuracy: 0.6120 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6315 - accuracy: 0.6291 - val_loss: 0.6442 - val_accuracy: 0.6141 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6284 - accuracy: 0.6314 - val_loss: 0.6430 - val_accuracy: 0.6165 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6234 - accuracy: 0.6374 - val_loss: 0.6392 - val_accuracy: 0.6191 - 2s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6209 - accuracy: 0.6396 - val_loss: 0.6371 - val_accuracy: 0.6220 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6154 - accuracy: 0.6461 - val_loss: 0.6339 - val_accuracy: 0.6259 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6117 - accuracy: 0.6483 - val_loss: 0.6295 - val_accuracy: 0.6305 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6089 - accuracy: 0.6509 - val_loss: 0.6323 - val_accuracy: 0.6281 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6044 - accuracy: 0.6573 - val_loss: 0.6277 - val_accuracy: 0.6335 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6008 - accuracy: 0.6609 - val_loss: 0.6246 - val_accuracy: 0.6372 - 2s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6004 - accuracy: 0.6606 - val_loss: 0.6243 - val_accuracy: 0.6371 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.5976 - accuracy: 0.6627 - val_loss: 0.6254 - val_accuracy: 0.6342 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.5907 - accuracy: 0.6680 - val_loss: 0.6226 - val_accuracy: 0.6375 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.5909 - accuracy: 0.6686 - val_loss: 0.6194 - val_accuracy: 0.6437 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.5889 - accuracy: 0.6689 - val_loss: 0.6188 - val_accuracy: 0.6448 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.5841 - accuracy: 0.6753 - val_loss: 0.6175 - val_accuracy: 0.6445 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.5826 - accuracy: 0.6779 - val_loss: 0.6144 - val_accuracy: 0.6485 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.5797 - accuracy: 0.6792 - val_loss: 0.6133 - val_accuracy: 0.6505 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.5779 - accuracy: 0.6805 - val_loss: 0.6123 - val_accuracy: 0.6492 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.5747 - accuracy: 0.6819 - val_loss: 0.6111 - val_accuracy: 0.6509 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.5724 - accuracy: 0.6841 - val_loss: 0.6095 - val_accuracy: 0.6537 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.5706 - accuracy: 0.6871 - val_loss: 0.6101 - val_accuracy: 0.6527 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.5689 - accuracy: 0.6898 - val_loss: 0.6072 - val_accuracy: 0.6551 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.5660 - accuracy: 0.6899 - val_loss: 0.6076 - val_accuracy: 0.6562 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.5648 - accuracy: 0.6928 - val_loss: 0.6045 - val_accuracy: 0.6569 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.5625 - accuracy: 0.6953 - val_loss: 0.6055 - val_accuracy: 0.6569 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.5596 - accuracy: 0.6957 - val_loss: 0.6056 - val_accuracy: 0.6564 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5593 - accuracy: 0.6972 - val_loss: 0.6035 - val_accuracy: 0.6583 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5576 - accuracy: 0.7002 - val_loss: 0.6021 - val_accuracy: 0.6620 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5556 - accuracy: 0.6999 - val_loss: 0.6033 - val_accuracy: 0.6587 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5528 - accuracy: 0.7032 - val_loss: 0.6018 - val_accuracy: 0.6593 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5540 - accuracy: 0.7023 - val_loss: 0.6012 - val_accuracy: 0.6622 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.5514 - accuracy: 0.7062 - val_loss: 0.5977 - val_accuracy: 0.6659 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.5487 - accuracy: 0.7045 - val_loss: 0.5994 - val_accuracy: 0.6657 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5479 - accuracy: 0.7073 - val_loss: 0.5977 - val_accuracy: 0.6641 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.5462 - accuracy: 0.7092 - val_loss: 0.5971 - val_accuracy: 0.6637 - 2s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.5448 - accuracy: 0.7080 - val_loss: 0.5954 - val_accuracy: 0.6687 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5430 - accuracy: 0.7114 - val_loss: 0.5973 - val_accuracy: 0.6672 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.5410 - accuracy: 0.7112 - val_loss: 0.5956 - val_accuracy: 0.6693 - 2s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 2s - loss: 0.5421 - accuracy: 0.7102 - val_loss: 0.5947 - val_accuracy: 0.6675 - 2s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "798/798 - 2s - loss: 0.5363 - accuracy: 0.7154 - val_loss: 0.5950 - val_accuracy: 0.6675 - 2s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "798/798 - 2s - loss: 0.5364 - accuracy: 0.7169 - val_loss: 0.5909 - val_accuracy: 0.6718 - 2s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "798/798 - 2s - loss: 0.5359 - accuracy: 0.7148 - val_loss: 0.5923 - val_accuracy: 0.6703 - 2s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "798/798 - 2s - loss: 0.5362 - accuracy: 0.7148 - val_loss: 0.5918 - val_accuracy: 0.6695 - 2s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "798/798 - 2s - loss: 0.5337 - accuracy: 0.7189 - val_loss: 0.5927 - val_accuracy: 0.6721 - 2s/epoch - 2ms/step\n",
      "Score for fold 3: loss of 0.5909140706062317; accuracy of 0.6728199124336243%\n",
      "\n",
      "Training for Fold 4 ...\n",
      "Epoch 1/100\n",
      "798/798 - 3s - loss: 0.6883 - accuracy: 0.5392 - val_loss: 0.6850 - val_accuracy: 0.5489 - 3s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6823 - accuracy: 0.5541 - val_loss: 0.6833 - val_accuracy: 0.5523 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6796 - accuracy: 0.5610 - val_loss: 0.6792 - val_accuracy: 0.5595 - 2s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6758 - accuracy: 0.5680 - val_loss: 0.6780 - val_accuracy: 0.5643 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6729 - accuracy: 0.5745 - val_loss: 0.6752 - val_accuracy: 0.5704 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 2s - loss: 0.6677 - accuracy: 0.5812 - val_loss: 0.6708 - val_accuracy: 0.5752 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 2s - loss: 0.6631 - accuracy: 0.5902 - val_loss: 0.6669 - val_accuracy: 0.5817 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 2s - loss: 0.6576 - accuracy: 0.5979 - val_loss: 0.6633 - val_accuracy: 0.5902 - 2s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 2s - loss: 0.6533 - accuracy: 0.6037 - val_loss: 0.6594 - val_accuracy: 0.5928 - 2s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6488 - accuracy: 0.6060 - val_loss: 0.6554 - val_accuracy: 0.5978 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6436 - accuracy: 0.6132 - val_loss: 0.6546 - val_accuracy: 0.6011 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6388 - accuracy: 0.6202 - val_loss: 0.6500 - val_accuracy: 0.6054 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 2s - loss: 0.6336 - accuracy: 0.6244 - val_loss: 0.6460 - val_accuracy: 0.6127 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6287 - accuracy: 0.6295 - val_loss: 0.6429 - val_accuracy: 0.6165 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 2s - loss: 0.6250 - accuracy: 0.6321 - val_loss: 0.6398 - val_accuracy: 0.6195 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 2s - loss: 0.6202 - accuracy: 0.6379 - val_loss: 0.6383 - val_accuracy: 0.6198 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6178 - accuracy: 0.6389 - val_loss: 0.6374 - val_accuracy: 0.6177 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6155 - accuracy: 0.6431 - val_loss: 0.6326 - val_accuracy: 0.6246 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6098 - accuracy: 0.6482 - val_loss: 0.6313 - val_accuracy: 0.6299 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6064 - accuracy: 0.6514 - val_loss: 0.6288 - val_accuracy: 0.6330 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6039 - accuracy: 0.6522 - val_loss: 0.6283 - val_accuracy: 0.6275 - 2s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6017 - accuracy: 0.6558 - val_loss: 0.6254 - val_accuracy: 0.6368 - 2s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.5960 - accuracy: 0.6603 - val_loss: 0.6249 - val_accuracy: 0.6333 - 2s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.5944 - accuracy: 0.6626 - val_loss: 0.6226 - val_accuracy: 0.6386 - 2s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.5900 - accuracy: 0.6648 - val_loss: 0.6217 - val_accuracy: 0.6404 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.5873 - accuracy: 0.6678 - val_loss: 0.6192 - val_accuracy: 0.6418 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.5860 - accuracy: 0.6673 - val_loss: 0.6182 - val_accuracy: 0.6443 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.5840 - accuracy: 0.6718 - val_loss: 0.6162 - val_accuracy: 0.6451 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.5805 - accuracy: 0.6732 - val_loss: 0.6157 - val_accuracy: 0.6465 - 2s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.5781 - accuracy: 0.6765 - val_loss: 0.6157 - val_accuracy: 0.6464 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.5761 - accuracy: 0.6772 - val_loss: 0.6138 - val_accuracy: 0.6478 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.5735 - accuracy: 0.6813 - val_loss: 0.6123 - val_accuracy: 0.6495 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.5725 - accuracy: 0.6817 - val_loss: 0.6097 - val_accuracy: 0.6535 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.5698 - accuracy: 0.6838 - val_loss: 0.6090 - val_accuracy: 0.6522 - 2s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.5668 - accuracy: 0.6851 - val_loss: 0.6088 - val_accuracy: 0.6524 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.5654 - accuracy: 0.6860 - val_loss: 0.6088 - val_accuracy: 0.6538 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.5617 - accuracy: 0.6889 - val_loss: 0.6061 - val_accuracy: 0.6565 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.5606 - accuracy: 0.6900 - val_loss: 0.6057 - val_accuracy: 0.6562 - 2s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5599 - accuracy: 0.6898 - val_loss: 0.6057 - val_accuracy: 0.6567 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5586 - accuracy: 0.6918 - val_loss: 0.6033 - val_accuracy: 0.6595 - 2s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5536 - accuracy: 0.6947 - val_loss: 0.6057 - val_accuracy: 0.6567 - 2s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5533 - accuracy: 0.6966 - val_loss: 0.6037 - val_accuracy: 0.6601 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5520 - accuracy: 0.6969 - val_loss: 0.6021 - val_accuracy: 0.6556 - 2s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.5501 - accuracy: 0.6979 - val_loss: 0.6018 - val_accuracy: 0.6575 - 2s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.5506 - accuracy: 0.6968 - val_loss: 0.6006 - val_accuracy: 0.6617 - 2s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5474 - accuracy: 0.7006 - val_loss: 0.5990 - val_accuracy: 0.6616 - 2s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.5446 - accuracy: 0.7022 - val_loss: 0.6001 - val_accuracy: 0.6641 - 2s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.5456 - accuracy: 0.7027 - val_loss: 0.5976 - val_accuracy: 0.6667 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5414 - accuracy: 0.7054 - val_loss: 0.5997 - val_accuracy: 0.6592 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.5418 - accuracy: 0.7063 - val_loss: 0.5967 - val_accuracy: 0.6651 - 2s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 2s - loss: 0.5386 - accuracy: 0.7087 - val_loss: 0.5974 - val_accuracy: 0.6629 - 2s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "798/798 - 2s - loss: 0.5372 - accuracy: 0.7095 - val_loss: 0.5975 - val_accuracy: 0.6639 - 2s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "798/798 - 2s - loss: 0.5375 - accuracy: 0.7079 - val_loss: 0.5959 - val_accuracy: 0.6686 - 2s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "798/798 - 2s - loss: 0.5371 - accuracy: 0.7109 - val_loss: 0.5966 - val_accuracy: 0.6654 - 2s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "798/798 - 2s - loss: 0.5350 - accuracy: 0.7112 - val_loss: 0.5955 - val_accuracy: 0.6618 - 2s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "798/798 - 2s - loss: 0.5341 - accuracy: 0.7124 - val_loss: 0.5958 - val_accuracy: 0.6622 - 2s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "798/798 - 2s - loss: 0.5330 - accuracy: 0.7128 - val_loss: 0.5961 - val_accuracy: 0.6655 - 2s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "798/798 - 2s - loss: 0.5319 - accuracy: 0.7125 - val_loss: 0.5923 - val_accuracy: 0.6689 - 2s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "798/798 - 2s - loss: 0.5290 - accuracy: 0.7166 - val_loss: 0.5945 - val_accuracy: 0.6670 - 2s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "798/798 - 2s - loss: 0.5306 - accuracy: 0.7127 - val_loss: 0.5921 - val_accuracy: 0.6701 - 2s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "798/798 - 2s - loss: 0.5285 - accuracy: 0.7173 - val_loss: 0.5953 - val_accuracy: 0.6675 - 2s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "798/798 - 2s - loss: 0.5270 - accuracy: 0.7164 - val_loss: 0.5927 - val_accuracy: 0.6708 - 2s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "798/798 - 2s - loss: 0.5259 - accuracy: 0.7179 - val_loss: 0.5913 - val_accuracy: 0.6700 - 2s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "798/798 - 2s - loss: 0.5253 - accuracy: 0.7195 - val_loss: 0.5914 - val_accuracy: 0.6662 - 2s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "798/798 - 2s - loss: 0.5255 - accuracy: 0.7189 - val_loss: 0.5905 - val_accuracy: 0.6695 - 2s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "798/798 - 2s - loss: 0.5231 - accuracy: 0.7195 - val_loss: 0.5896 - val_accuracy: 0.6727 - 2s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "798/798 - 2s - loss: 0.5220 - accuracy: 0.7227 - val_loss: 0.5900 - val_accuracy: 0.6735 - 2s/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "798/798 - 2s - loss: 0.5218 - accuracy: 0.7199 - val_loss: 0.5925 - val_accuracy: 0.6705 - 2s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "798/798 - 2s - loss: 0.5190 - accuracy: 0.7197 - val_loss: 0.5882 - val_accuracy: 0.6697 - 2s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "798/798 - 2s - loss: 0.5191 - accuracy: 0.7232 - val_loss: 0.5893 - val_accuracy: 0.6743 - 2s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "798/798 - 2s - loss: 0.5192 - accuracy: 0.7227 - val_loss: 0.5906 - val_accuracy: 0.6721 - 2s/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "798/798 - 2s - loss: 0.5159 - accuracy: 0.7231 - val_loss: 0.5887 - val_accuracy: 0.6731 - 2s/epoch - 2ms/step\n",
      "Score for fold 4: loss of 0.5919020771980286; accuracy of 0.6727415323257446%\n",
      "\n",
      "Training for Fold 5 ...\n",
      "Epoch 1/100\n",
      "798/798 - 3s - loss: 0.6883 - accuracy: 0.5414 - val_loss: 0.6843 - val_accuracy: 0.5486 - 3s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "798/798 - 2s - loss: 0.6826 - accuracy: 0.5551 - val_loss: 0.6817 - val_accuracy: 0.5541 - 2s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "798/798 - 2s - loss: 0.6791 - accuracy: 0.5626 - val_loss: 0.6795 - val_accuracy: 0.5621 - 2s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "798/798 - 2s - loss: 0.6757 - accuracy: 0.5702 - val_loss: 0.6777 - val_accuracy: 0.5641 - 2s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "798/798 - 2s - loss: 0.6715 - accuracy: 0.5765 - val_loss: 0.6738 - val_accuracy: 0.5724 - 2s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "798/798 - 3s - loss: 0.6673 - accuracy: 0.5823 - val_loss: 0.6710 - val_accuracy: 0.5753 - 3s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "798/798 - 3s - loss: 0.6623 - accuracy: 0.5914 - val_loss: 0.6657 - val_accuracy: 0.5876 - 3s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "798/798 - 3s - loss: 0.6581 - accuracy: 0.5980 - val_loss: 0.6633 - val_accuracy: 0.5913 - 3s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "798/798 - 3s - loss: 0.6522 - accuracy: 0.6046 - val_loss: 0.6605 - val_accuracy: 0.5939 - 3s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "798/798 - 2s - loss: 0.6477 - accuracy: 0.6091 - val_loss: 0.6581 - val_accuracy: 0.5976 - 2s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "798/798 - 2s - loss: 0.6427 - accuracy: 0.6171 - val_loss: 0.6527 - val_accuracy: 0.6037 - 2s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "798/798 - 2s - loss: 0.6388 - accuracy: 0.6192 - val_loss: 0.6517 - val_accuracy: 0.6053 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "798/798 - 3s - loss: 0.6341 - accuracy: 0.6253 - val_loss: 0.6495 - val_accuracy: 0.6110 - 3s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "798/798 - 2s - loss: 0.6302 - accuracy: 0.6292 - val_loss: 0.6456 - val_accuracy: 0.6130 - 2s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "798/798 - 3s - loss: 0.6261 - accuracy: 0.6327 - val_loss: 0.6411 - val_accuracy: 0.6184 - 3s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "798/798 - 3s - loss: 0.6230 - accuracy: 0.6359 - val_loss: 0.6393 - val_accuracy: 0.6212 - 3s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "798/798 - 2s - loss: 0.6192 - accuracy: 0.6421 - val_loss: 0.6362 - val_accuracy: 0.6247 - 2s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "798/798 - 2s - loss: 0.6166 - accuracy: 0.6436 - val_loss: 0.6337 - val_accuracy: 0.6263 - 2s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "798/798 - 2s - loss: 0.6121 - accuracy: 0.6472 - val_loss: 0.6336 - val_accuracy: 0.6268 - 2s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "798/798 - 2s - loss: 0.6095 - accuracy: 0.6506 - val_loss: 0.6312 - val_accuracy: 0.6273 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "798/798 - 2s - loss: 0.6062 - accuracy: 0.6526 - val_loss: 0.6301 - val_accuracy: 0.6317 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "798/798 - 2s - loss: 0.6039 - accuracy: 0.6568 - val_loss: 0.6271 - val_accuracy: 0.6337 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "798/798 - 2s - loss: 0.5986 - accuracy: 0.6599 - val_loss: 0.6260 - val_accuracy: 0.6338 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "798/798 - 2s - loss: 0.5961 - accuracy: 0.6642 - val_loss: 0.6246 - val_accuracy: 0.6371 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "798/798 - 2s - loss: 0.5933 - accuracy: 0.6647 - val_loss: 0.6237 - val_accuracy: 0.6377 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "798/798 - 2s - loss: 0.5897 - accuracy: 0.6686 - val_loss: 0.6210 - val_accuracy: 0.6412 - 2s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "798/798 - 2s - loss: 0.5876 - accuracy: 0.6709 - val_loss: 0.6203 - val_accuracy: 0.6424 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "798/798 - 2s - loss: 0.5848 - accuracy: 0.6731 - val_loss: 0.6188 - val_accuracy: 0.6435 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "798/798 - 2s - loss: 0.5817 - accuracy: 0.6764 - val_loss: 0.6171 - val_accuracy: 0.6453 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "798/798 - 2s - loss: 0.5808 - accuracy: 0.6767 - val_loss: 0.6150 - val_accuracy: 0.6460 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "798/798 - 2s - loss: 0.5763 - accuracy: 0.6815 - val_loss: 0.6145 - val_accuracy: 0.6491 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "798/798 - 2s - loss: 0.5755 - accuracy: 0.6813 - val_loss: 0.6144 - val_accuracy: 0.6492 - 2s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "798/798 - 2s - loss: 0.5730 - accuracy: 0.6835 - val_loss: 0.6100 - val_accuracy: 0.6505 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "798/798 - 2s - loss: 0.5724 - accuracy: 0.6834 - val_loss: 0.6106 - val_accuracy: 0.6520 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "798/798 - 2s - loss: 0.5700 - accuracy: 0.6879 - val_loss: 0.6104 - val_accuracy: 0.6526 - 2s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "798/798 - 2s - loss: 0.5680 - accuracy: 0.6863 - val_loss: 0.6084 - val_accuracy: 0.6533 - 2s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "798/798 - 2s - loss: 0.5640 - accuracy: 0.6906 - val_loss: 0.6090 - val_accuracy: 0.6532 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "798/798 - 2s - loss: 0.5644 - accuracy: 0.6901 - val_loss: 0.6077 - val_accuracy: 0.6544 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "798/798 - 2s - loss: 0.5611 - accuracy: 0.6947 - val_loss: 0.6068 - val_accuracy: 0.6561 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "798/798 - 2s - loss: 0.5591 - accuracy: 0.6947 - val_loss: 0.6052 - val_accuracy: 0.6563 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "798/798 - 2s - loss: 0.5584 - accuracy: 0.6955 - val_loss: 0.6040 - val_accuracy: 0.6597 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "798/798 - 2s - loss: 0.5573 - accuracy: 0.6967 - val_loss: 0.6040 - val_accuracy: 0.6597 - 2s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "798/798 - 2s - loss: 0.5562 - accuracy: 0.6966 - val_loss: 0.6039 - val_accuracy: 0.6596 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "798/798 - 2s - loss: 0.5540 - accuracy: 0.6994 - val_loss: 0.6021 - val_accuracy: 0.6597 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "798/798 - 2s - loss: 0.5510 - accuracy: 0.7017 - val_loss: 0.6026 - val_accuracy: 0.6605 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "798/798 - 2s - loss: 0.5496 - accuracy: 0.7022 - val_loss: 0.6015 - val_accuracy: 0.6622 - 2s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "798/798 - 2s - loss: 0.5481 - accuracy: 0.7049 - val_loss: 0.6012 - val_accuracy: 0.6636 - 2s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "798/798 - 2s - loss: 0.5479 - accuracy: 0.7034 - val_loss: 0.6020 - val_accuracy: 0.6629 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "798/798 - 2s - loss: 0.5468 - accuracy: 0.7071 - val_loss: 0.5999 - val_accuracy: 0.6623 - 2s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "798/798 - 2s - loss: 0.5448 - accuracy: 0.7057 - val_loss: 0.6025 - val_accuracy: 0.6600 - 2s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "798/798 - 2s - loss: 0.5438 - accuracy: 0.7064 - val_loss: 0.5985 - val_accuracy: 0.6644 - 2s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "798/798 - 2s - loss: 0.5407 - accuracy: 0.7088 - val_loss: 0.5988 - val_accuracy: 0.6642 - 2s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "798/798 - 2s - loss: 0.5412 - accuracy: 0.7089 - val_loss: 0.5985 - val_accuracy: 0.6629 - 2s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "798/798 - 2s - loss: 0.5393 - accuracy: 0.7100 - val_loss: 0.5968 - val_accuracy: 0.6653 - 2s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "798/798 - 2s - loss: 0.5385 - accuracy: 0.7095 - val_loss: 0.5974 - val_accuracy: 0.6666 - 2s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "798/798 - 2s - loss: 0.5373 - accuracy: 0.7132 - val_loss: 0.5980 - val_accuracy: 0.6650 - 2s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "798/798 - 2s - loss: 0.5363 - accuracy: 0.7130 - val_loss: 0.5960 - val_accuracy: 0.6659 - 2s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "798/798 - 2s - loss: 0.5345 - accuracy: 0.7164 - val_loss: 0.5968 - val_accuracy: 0.6673 - 2s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "798/798 - 2s - loss: 0.5336 - accuracy: 0.7167 - val_loss: 0.5948 - val_accuracy: 0.6708 - 2s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "798/798 - 2s - loss: 0.5309 - accuracy: 0.7178 - val_loss: 0.5956 - val_accuracy: 0.6679 - 2s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "798/798 - 2s - loss: 0.5298 - accuracy: 0.7184 - val_loss: 0.5923 - val_accuracy: 0.6694 - 2s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "798/798 - 2s - loss: 0.5302 - accuracy: 0.7182 - val_loss: 0.5960 - val_accuracy: 0.6674 - 2s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "798/798 - 2s - loss: 0.5290 - accuracy: 0.7191 - val_loss: 0.5947 - val_accuracy: 0.6683 - 2s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "798/798 - 2s - loss: 0.5267 - accuracy: 0.7187 - val_loss: 0.5923 - val_accuracy: 0.6697 - 2s/epoch - 2ms/step\n",
      "Score for fold 5: loss of 0.5902246832847595; accuracy of 0.6716441512107849%\n"
     ]
    }
   ],
   "source": [
    "batch_acc ={}\n",
    "\n",
    "# Experiment on batch sizes\n",
    "# Iterating through all batch sizes\n",
    "for neuron_no in hidden_neurons:\n",
    "    fold_acc = []\n",
    "    fold_no = 1\n",
    "\n",
    "    print(\"\\n------- Batch Size: \" + str(batch_no) + \" -------\")\n",
    "\n",
    "    # Iterating through each split of training data\n",
    "    for train, test in kfold.split(X_train_scaled, y_train):\n",
    "        print(\"\\nTraining for Fold \" + str(fold_no) + \" ...\")\n",
    "        # define the model\n",
    "        model = Sequential([\n",
    "            Dense(neuron_no, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(1, activation='sigmoid'),\n",
    "        ])\n",
    "\n",
    "        # compile the model\n",
    "        model.compile(optimizer= opt,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        # fit the model\n",
    "        history = model.fit(X_train_scaled[train], y_train[train], \n",
    "                            epochs=no_epochs, \n",
    "                            batch_size=batch_size, \n",
    "                            verbose = 2, \n",
    "                            use_multiprocessing=True,\n",
    "                            callbacks=[early_stop],\n",
    "                            validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "        \n",
    "        \n",
    "        # Storing history of every k-fold\n",
    "        acc_ = model.evaluate(X_train_scaled[test], y_train[test], verbose=0)\n",
    "        print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {acc_[0]}; {model.metrics_names[1]} of {acc_[1]}%')\n",
    "        fold_acc.append(acc_[1])\n",
    "        \n",
    "        # increase fold number\n",
    "        fold_no += 1\n",
    "\n",
    "    # Storing history for every batch size\n",
    "    batch_acc[neuron_no] = {\"Accuracy\":fold_acc}               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "NT9wZjzBgCb_"
   },
   "outputs": [],
   "source": [
    "hidden_neurons_plot = []\n",
    "mean_accuracy_plot =[]\n",
    "\n",
    "for hidden_neurons, acc in batch_acc.items():\n",
    "  hidden_neurons_acc = acc[\"Accuracy\"]\n",
    "  mean_fold_acc = sum(hidden_neurons_acc)/len(hidden_neurons_acc)\n",
    "\n",
    "  hidden_neurons_plot.append(hidden_neurons)\n",
    "  mean_accuracy_plot.append(mean_fold_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "TxAgNrGifit0",
    "outputId": "65d62e55-3a8b-4222-fe14-061399a25d91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Number of hidden-layer neurons')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(hidden_neurons_plot,mean_accuracy_plot)\n",
    "plt.title('Mean CV accuracies for hidden-layer neurons')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of hidden-layer neurons')\n",
    "\n",
    "#plt.savefig('Q2(a)mean cross-validation accuracies.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOyQ7nGccFOf"
   },
   "source": [
    "### Part b\n",
    "\n",
    "Select the optimal number of neurons for the hidden layer. State the rationale for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "UrVjdYbQbzDY"
   },
   "outputs": [],
   "source": [
    "# select optimal number of neurons for hidden layer\n",
    "\n",
    "# state rationale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPjckQWQcPRI"
   },
   "source": [
    "### Part c\n",
    "\n",
    "Plot the train and test accuracies against training epochs with the optimal number of neurons using a line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "zcLD4kr4cQca"
   },
   "outputs": [],
   "source": [
    "# optimal number of neurons\n",
    "hidden_units = 64 # to be updated\n",
    "\n",
    "batch_size = 128\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "no_epochs = 100\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6pNN2NviT3l",
    "outputId": "68962ee1-34ae-459b-f44a-337e8fcf0dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "997/997 - 2s - loss: 0.6893 - accuracy: 0.5358 - val_loss: 0.6850 - val_accuracy: 0.5502 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "997/997 - 2s - loss: 0.6840 - accuracy: 0.5499 - val_loss: 0.6827 - val_accuracy: 0.5558 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "997/997 - 2s - loss: 0.6817 - accuracy: 0.5558 - val_loss: 0.6819 - val_accuracy: 0.5565 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "997/997 - 2s - loss: 0.6793 - accuracy: 0.5608 - val_loss: 0.6791 - val_accuracy: 0.5634 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "997/997 - 2s - loss: 0.6768 - accuracy: 0.5675 - val_loss: 0.6777 - val_accuracy: 0.5649 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "997/997 - 2s - loss: 0.6742 - accuracy: 0.5727 - val_loss: 0.6751 - val_accuracy: 0.5719 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "997/997 - 2s - loss: 0.6721 - accuracy: 0.5751 - val_loss: 0.6729 - val_accuracy: 0.5761 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "997/997 - 2s - loss: 0.6700 - accuracy: 0.5790 - val_loss: 0.6703 - val_accuracy: 0.5780 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "997/997 - 2s - loss: 0.6683 - accuracy: 0.5814 - val_loss: 0.6695 - val_accuracy: 0.5842 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "997/997 - 2s - loss: 0.6658 - accuracy: 0.5851 - val_loss: 0.6675 - val_accuracy: 0.5863 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "997/997 - 2s - loss: 0.6639 - accuracy: 0.5893 - val_loss: 0.6645 - val_accuracy: 0.5906 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "997/997 - 2s - loss: 0.6613 - accuracy: 0.5932 - val_loss: 0.6638 - val_accuracy: 0.5900 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "997/997 - 2s - loss: 0.6596 - accuracy: 0.5944 - val_loss: 0.6612 - val_accuracy: 0.5960 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "997/997 - 2s - loss: 0.6580 - accuracy: 0.5979 - val_loss: 0.6609 - val_accuracy: 0.5987 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "997/997 - 2s - loss: 0.6559 - accuracy: 0.6024 - val_loss: 0.6574 - val_accuracy: 0.5993 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "997/997 - 2s - loss: 0.6549 - accuracy: 0.6037 - val_loss: 0.6582 - val_accuracy: 0.6012 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "997/997 - 2s - loss: 0.6538 - accuracy: 0.6051 - val_loss: 0.6558 - val_accuracy: 0.6042 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "997/997 - 2s - loss: 0.6526 - accuracy: 0.6071 - val_loss: 0.6542 - val_accuracy: 0.6061 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "997/997 - 2s - loss: 0.6510 - accuracy: 0.6095 - val_loss: 0.6536 - val_accuracy: 0.6079 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "997/997 - 2s - loss: 0.6499 - accuracy: 0.6096 - val_loss: 0.6520 - val_accuracy: 0.6102 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "997/997 - 2s - loss: 0.6483 - accuracy: 0.6117 - val_loss: 0.6529 - val_accuracy: 0.6088 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "997/997 - 2s - loss: 0.6478 - accuracy: 0.6128 - val_loss: 0.6497 - val_accuracy: 0.6119 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "997/997 - 2s - loss: 0.6466 - accuracy: 0.6130 - val_loss: 0.6483 - val_accuracy: 0.6131 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "997/997 - 2s - loss: 0.6455 - accuracy: 0.6155 - val_loss: 0.6490 - val_accuracy: 0.6140 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "997/997 - 2s - loss: 0.6441 - accuracy: 0.6164 - val_loss: 0.6462 - val_accuracy: 0.6155 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "997/997 - 2s - loss: 0.6435 - accuracy: 0.6177 - val_loss: 0.6472 - val_accuracy: 0.6180 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "997/997 - 2s - loss: 0.6414 - accuracy: 0.6203 - val_loss: 0.6473 - val_accuracy: 0.6139 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "997/997 - 2s - loss: 0.6420 - accuracy: 0.6189 - val_loss: 0.6447 - val_accuracy: 0.6176 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "997/997 - 2s - loss: 0.6398 - accuracy: 0.6214 - val_loss: 0.6437 - val_accuracy: 0.6206 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "997/997 - 2s - loss: 0.6398 - accuracy: 0.6228 - val_loss: 0.6442 - val_accuracy: 0.6190 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "997/997 - 2s - loss: 0.6392 - accuracy: 0.6235 - val_loss: 0.6426 - val_accuracy: 0.6199 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "997/997 - 2s - loss: 0.6392 - accuracy: 0.6238 - val_loss: 0.6423 - val_accuracy: 0.6226 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "997/997 - 2s - loss: 0.6372 - accuracy: 0.6267 - val_loss: 0.6430 - val_accuracy: 0.6232 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "997/997 - 2s - loss: 0.6371 - accuracy: 0.6276 - val_loss: 0.6414 - val_accuracy: 0.6228 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "997/997 - 2s - loss: 0.6362 - accuracy: 0.6260 - val_loss: 0.6403 - val_accuracy: 0.6225 - 2s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "997/997 - 2s - loss: 0.6355 - accuracy: 0.6280 - val_loss: 0.6408 - val_accuracy: 0.6218 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "997/997 - 2s - loss: 0.6347 - accuracy: 0.6287 - val_loss: 0.6381 - val_accuracy: 0.6251 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "997/997 - 2s - loss: 0.6344 - accuracy: 0.6297 - val_loss: 0.6398 - val_accuracy: 0.6260 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "997/997 - 2s - loss: 0.6331 - accuracy: 0.6306 - val_loss: 0.6375 - val_accuracy: 0.6267 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "997/997 - 3s - loss: 0.6340 - accuracy: 0.6290 - val_loss: 0.6361 - val_accuracy: 0.6290 - 3s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "997/997 - 2s - loss: 0.6326 - accuracy: 0.6313 - val_loss: 0.6369 - val_accuracy: 0.6279 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "997/997 - 2s - loss: 0.6320 - accuracy: 0.6322 - val_loss: 0.6380 - val_accuracy: 0.6277 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "997/997 - 2s - loss: 0.6321 - accuracy: 0.6319 - val_loss: 0.6366 - val_accuracy: 0.6269 - 2s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#define the model\n",
    "model = Sequential([\n",
    "    Dense(hidden_units, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer= opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "          epochs=no_epochs, \n",
    "          batch_size=batch_size, \n",
    "          verbose = 2, \n",
    "          use_multiprocessing=True,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(X_test_scaled, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "GKdoeMCLiT-1",
    "outputId": "6619e505-e421-4838-9a74-2960c30e01ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x225bb050310>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test accuracies\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for 64 hidden neurons') # to be updated\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train accuracy', 'Test accuracy'], loc='upper left')\n",
    "\n",
    "#plt.savefig('Q1(e)accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyqToVBScQvT"
   },
   "source": [
    "### Part d\n",
    "\n",
    "How does dropouts work, and what is the purpose of dropouts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "QVtFAAwrcQ8C"
   },
   "outputs": [],
   "source": [
    "# how dropouts work\n",
    "\n",
    "# purpose of dropouts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiwKLilEcRvJ"
   },
   "source": [
    "### Part e\n",
    "\n",
    "Besides early stopping and dropout, what is another approach that you could take to address overfitting in the model, and how does it work? Implement the approach.\n",
    "\n",
    "Note: use this optimal number of neurons for the rest of the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHPF4pYjcR5C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7ONOWXAchI-"
   },
   "source": [
    "## Question 4\n",
    "\n",
    "In this section, we will understand the utility of such a neural network in real world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A167PzhMcmWt"
   },
   "source": [
    "### Part a\n",
    "\n",
    "Record yourself with a wav file using (https://voice-recorder-online.com/) for 5 seconds, either in a positive or a negative manner. Preprocess the data using the provided preprocessing script (data_preprocess.ipynb) and prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbPZArplcsUf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWzT_vG5cvZr"
   },
   "source": [
    "### Part b\n",
    "\n",
    "Do a model prediction on your sample test dataset and obtain the predicted label using a threshold of 0.5. The model used is the optimized pretrained model using the selected optimal batch size and optimal number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcvBH63gcvkB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztzy_PdpcvrP"
   },
   "source": [
    "### Part c\n",
    "\n",
    "Find the most important features on the model prediction for your test sample using SHAP. Plot the local feature importance with a force plot and explain your\n",
    "observations. (Refer to the documentation and these three useful references: https://christophm.github.io/interpretable-ml-book/shap.html#examples-5, https://towardsdatascience.com/deep-learning-model-interpretation-using-shap-a21786e91d16, https://medium.com/mlearning-ai/shap-force-plots-for-classification-d30be430e195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oviGvyGcv0H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEJeRNzfcv9y"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Possible discussion pointers for conclusion:\n",
    "\n",
    "Besides summarising the key findings from each question, take a step back to analyse the entire modelling pipeline and think about ways to improve it. Here are some aspects of the pipeline that you can consider:\n",
    "\n",
    "*   We now have a classifier that predicts the speech polarity. What are some limitations of the current approach (using FFNs to model such engineered features)?\n",
    "*   Out of the parameters that were tuned, which was most impactful in terms of improving the model performance and what could be some reasons for that?\n",
    "*   Considering that audio tracks are originally waveforms, what are some alternative approaches to achieve the goal of genre classification? What kind of neural network architectures will be used instead?\n",
    "*   What other datasets and tasks can this approach of modelling waveform data be used for? What changes to the pipeline, if any, will you have to make when approaching these problems?\n",
    "*   You are encouraged to include your own pointers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bS3SkZW_cwGo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
